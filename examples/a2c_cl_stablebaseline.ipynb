{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDnu5pvf_mo_"
   },
   "source": [
    "# Actor Critic on Crude Oil daily data\n",
    "\n",
    "In this notebook a fully connected DQN model is trained on the crude oil daily dataset, enriched with the various tecnical indicators and the crude oil implied volatility index `OVX`.\n",
    "\n",
    "The importance of **implied volatility** for market participants stems from the fact that it is one of the only data that is **forward-looking**. This is because market participants always trade contracts with an expiration date later in time. \n",
    "\n",
    "The goal of this notebook is to see how (if it is possible) a A2C trading agent can leverage this kind of data to learn a profitable trading strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "928KLlJqtW51",
    "outputId": "f7885214-21cf-41b7-fd0f-fc893b2ab899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.11.0+cu113)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
      "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.21.6)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.5)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (2.8.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (4.1.2.30)\n",
      "Requirement already satisfied: ale-py~=0.7.4 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.7.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (7.1.2)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3[extra]) (4.11.4)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.4->stable-baselines3[extra]) (5.7.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.64.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.23.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (4.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (57.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.46.3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.17.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.5.18.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3[extra]) (2022.1)\n"
     ]
    }
   ],
   "source": [
    "#@title **Install externals libraries** {display-mode:'form'}\n",
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpQM4fyPqZaA"
   },
   "outputs": [],
   "source": [
    "#@title **Imports** {display-mode: 'form'}\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.dqn.policies import DQNPolicy\n",
    "\n",
    "from gym_anytrading.envs.future_env import FuturesEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = 'data/CL_daily_adj.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-_GG_7UrvgI"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "The preprocessing phase consist in the following phases:\n",
    "\n",
    "- addition of cyclical features for the time-related variables\n",
    "- standardization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E10RMnXQsZbR"
   },
   "outputs": [],
   "source": [
    "def add_cyclical_features(df):\n",
    "    df['date'] = pd.to_datetime(df.index.copy(), format='%Y-%m-%d')\n",
    "    df['day_sin'] = df['date'].apply(lambda x: np.sin(x.day * (2. * np.pi / 30)))\n",
    "    df['day_cos'] = df['date'].apply(lambda x: np.cos(x.day * (2. * np.pi / 30)))\n",
    "    df['month_sin'] = df['date'].apply(lambda x: np.sin(x.month * (2. * np.pi / 12)))\n",
    "    df['month_cos'] = df['date'].apply(lambda x: np.cos(x.month * (2. * np.pi / 12)))\n",
    "    df = df.drop('date', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bj2fthlXrcTa"
   },
   "outputs": [],
   "source": [
    "cl_df = pd.read_csv(path, parse_dates=True)\n",
    "cl_df = cl_df.set_index('Date')\n",
    "cl_df = add_cyclical_features(cl_df)\n",
    "sc = StandardScaler()\n",
    "cols, cl_index = cl_df.columns, cl_df.index\n",
    "cl_df = pd.DataFrame(sc.fit_transform(cl_df), columns=cols, index=cl_index)\n",
    "window_size = 21\n",
    "training_portion = 0.8\n",
    "episodes = 300\n",
    "\n",
    "train_cl_df = cl_df[0:int(np.floor(len(cl_df) * training_portion))]\n",
    "test_cl_df = cl_df[int(np.floor(len(cl_df) * training_portion)):]\n",
    "\n",
    "env = FuturesEnv(df=train_cl_df,\n",
    "                 window_size=window_size,\n",
    "                 frame_bound=(window_size, len(train_cl_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Only 80% of the total data is used during the training phase. That's because we want to avoid the model simply memorizing the dataset (overfitting) and obtaining a model that is generalized well in all market situations.\n",
    "\n",
    "The A2C model is a fully connected neural network with 4 layers with 256, 128, 128, 64 neurson respectvely, the neural network will be given as input the daily data of the previous month (21 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttI6n_JMsFZa",
    "outputId": "6c0c6d63-f914-4f32-9349-e250b5a61df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 153700   |\n",
      "|    time_elapsed       | 1607     |\n",
      "|    total_timesteps    | 768500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0932  |\n",
      "|    explained_variance | -0.607   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 153699   |\n",
      "|    policy_loss        | -0.0365  |\n",
      "|    value_loss         | 5.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 153800   |\n",
      "|    time_elapsed       | 1608     |\n",
      "|    total_timesteps    | 769000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.321   |\n",
      "|    explained_variance | 0.777    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 153799   |\n",
      "|    policy_loss        | -1.89    |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 153900   |\n",
      "|    time_elapsed       | 1609     |\n",
      "|    total_timesteps    | 769500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.258   |\n",
      "|    explained_variance | -56.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 153899   |\n",
      "|    policy_loss        | -0.0577  |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154000   |\n",
      "|    time_elapsed       | 1610     |\n",
      "|    total_timesteps    | 770000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0762  |\n",
      "|    explained_variance | -0.654   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 153999   |\n",
      "|    policy_loss        | -4.24    |\n",
      "|    value_loss         | 6.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154100   |\n",
      "|    time_elapsed       | 1611     |\n",
      "|    total_timesteps    | 770500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.77    |\n",
      "|    explained_variance | -0.459   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154099   |\n",
      "|    policy_loss        | 0.226    |\n",
      "|    value_loss         | 0.558    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154200   |\n",
      "|    time_elapsed       | 1612     |\n",
      "|    total_timesteps    | 771000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.577   |\n",
      "|    explained_variance | -3.48    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154199   |\n",
      "|    policy_loss        | -0.239   |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154300   |\n",
      "|    time_elapsed       | 1613     |\n",
      "|    total_timesteps    | 771500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.285   |\n",
      "|    explained_variance | -8.65    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154299   |\n",
      "|    policy_loss        | -0.279   |\n",
      "|    value_loss         | 0.259    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154400   |\n",
      "|    time_elapsed       | 1614     |\n",
      "|    total_timesteps    | 772000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0759  |\n",
      "|    explained_variance | -9.46    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154399   |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    value_loss         | 90.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154500   |\n",
      "|    time_elapsed       | 1615     |\n",
      "|    total_timesteps    | 772500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0889  |\n",
      "|    explained_variance | 0.14     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154499   |\n",
      "|    policy_loss        | 0.032    |\n",
      "|    value_loss         | 3.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154600   |\n",
      "|    time_elapsed       | 1616     |\n",
      "|    total_timesteps    | 773000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0649  |\n",
      "|    explained_variance | -0.392   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154599   |\n",
      "|    policy_loss        | -0.028   |\n",
      "|    value_loss         | 7.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154700   |\n",
      "|    time_elapsed       | 1617     |\n",
      "|    total_timesteps    | 773500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.268   |\n",
      "|    explained_variance | 0.688    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154699   |\n",
      "|    policy_loss        | 0.489    |\n",
      "|    value_loss         | 58.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154800   |\n",
      "|    time_elapsed       | 1618     |\n",
      "|    total_timesteps    | 774000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.227   |\n",
      "|    explained_variance | -23.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154799   |\n",
      "|    policy_loss        | 0.0206   |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 154900   |\n",
      "|    time_elapsed       | 1619     |\n",
      "|    total_timesteps    | 774500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.221   |\n",
      "|    explained_variance | -4.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154899   |\n",
      "|    policy_loss        | 0.173    |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155000   |\n",
      "|    time_elapsed       | 1620     |\n",
      "|    total_timesteps    | 775000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.07    |\n",
      "|    explained_variance | -55.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 154999   |\n",
      "|    policy_loss        | 0.0181   |\n",
      "|    value_loss         | 3.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155100   |\n",
      "|    time_elapsed       | 1621     |\n",
      "|    total_timesteps    | 775500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0601  |\n",
      "|    explained_variance | 0.332    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155099   |\n",
      "|    policy_loss        | -0.465   |\n",
      "|    value_loss         | 0.555    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155200   |\n",
      "|    time_elapsed       | 1622     |\n",
      "|    total_timesteps    | 776000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00253 |\n",
      "|    explained_variance | 0.319    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155199   |\n",
      "|    policy_loss        | 0.00163  |\n",
      "|    value_loss         | 41.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155300   |\n",
      "|    time_elapsed       | 1623     |\n",
      "|    total_timesteps    | 776500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.32    |\n",
      "|    explained_variance | -56.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155299   |\n",
      "|    policy_loss        | 0.0721   |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155400   |\n",
      "|    time_elapsed       | 1624     |\n",
      "|    total_timesteps    | 777000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0484  |\n",
      "|    explained_variance | -0.016   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155399   |\n",
      "|    policy_loss        | -0.0221  |\n",
      "|    value_loss         | 7.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155500   |\n",
      "|    time_elapsed       | 1625     |\n",
      "|    total_timesteps    | 777500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.243   |\n",
      "|    explained_variance | -122     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155499   |\n",
      "|    policy_loss        | -0.0353  |\n",
      "|    value_loss         | 0.336    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155600   |\n",
      "|    time_elapsed       | 1626     |\n",
      "|    total_timesteps    | 778000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0461  |\n",
      "|    explained_variance | 0.356    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155599   |\n",
      "|    policy_loss        | -0.00192 |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155700   |\n",
      "|    time_elapsed       | 1627     |\n",
      "|    total_timesteps    | 778500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0526  |\n",
      "|    explained_variance | 0.0578   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155699   |\n",
      "|    policy_loss        | -0.016   |\n",
      "|    value_loss         | 3.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155800   |\n",
      "|    time_elapsed       | 1628     |\n",
      "|    total_timesteps    | 779000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00189 |\n",
      "|    explained_variance | -0.00973 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155799   |\n",
      "|    policy_loss        | 0.00133  |\n",
      "|    value_loss         | 63.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 155900   |\n",
      "|    time_elapsed       | 1629     |\n",
      "|    total_timesteps    | 779500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0593  |\n",
      "|    explained_variance | -2.52    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155899   |\n",
      "|    policy_loss        | -0.0804  |\n",
      "|    value_loss         | 80.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 156000   |\n",
      "|    time_elapsed       | 1630     |\n",
      "|    total_timesteps    | 780000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.003   |\n",
      "|    explained_variance | -0.248   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 155999   |\n",
      "|    policy_loss        | 0.000828 |\n",
      "|    value_loss         | 8.36     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.04e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 156100    |\n",
      "|    time_elapsed       | 1631      |\n",
      "|    total_timesteps    | 780500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000973 |\n",
      "|    explained_variance | 0.785     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 156099    |\n",
      "|    policy_loss        | 3.19e-05  |\n",
      "|    value_loss         | 0.288     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 156200   |\n",
      "|    time_elapsed       | 1632     |\n",
      "|    total_timesteps    | 781000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.231   |\n",
      "|    explained_variance | 0.366    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 156199   |\n",
      "|    policy_loss        | 0.169    |\n",
      "|    value_loss         | 8.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 156300   |\n",
      "|    time_elapsed       | 1633     |\n",
      "|    total_timesteps    | 781500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.261   |\n",
      "|    explained_variance | 0.532    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 156299   |\n",
      "|    policy_loss        | -0.844   |\n",
      "|    value_loss         | 127      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.08e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 156400    |\n",
      "|    time_elapsed       | 1634      |\n",
      "|    total_timesteps    | 782000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000483 |\n",
      "|    explained_variance | -0.909    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 156399    |\n",
      "|    policy_loss        | 5.95e-05  |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.08e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 156500    |\n",
      "|    time_elapsed       | 1635      |\n",
      "|    total_timesteps    | 782500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000312 |\n",
      "|    explained_variance | -33.7     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 156499    |\n",
      "|    policy_loss        | 0.000493  |\n",
      "|    value_loss         | 196       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.08e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 156600    |\n",
      "|    time_elapsed       | 1636      |\n",
      "|    total_timesteps    | 783000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000254 |\n",
      "|    explained_variance | -0.0809   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 156599    |\n",
      "|    policy_loss        | 1e-05     |\n",
      "|    value_loss         | 0.262     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 156700   |\n",
      "|    time_elapsed       | 1637     |\n",
      "|    total_timesteps    | 783500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00252 |\n",
      "|    explained_variance | -64.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 156699   |\n",
      "|    policy_loss        | -0.00281 |\n",
      "|    value_loss         | 113      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 156800   |\n",
      "|    time_elapsed       | 1638     |\n",
      "|    total_timesteps    | 784000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.207   |\n",
      "|    explained_variance | -1.59    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 156799   |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    value_loss         | 0.0954   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 156900   |\n",
      "|    time_elapsed       | 1639     |\n",
      "|    total_timesteps    | 784500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.66    |\n",
      "|    explained_variance | -127     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 156899   |\n",
      "|    policy_loss        | 4.59     |\n",
      "|    value_loss         | 61.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157000   |\n",
      "|    time_elapsed       | 1640     |\n",
      "|    total_timesteps    | 785000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.51    |\n",
      "|    explained_variance | 0.143    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 156999   |\n",
      "|    policy_loss        | 0.404    |\n",
      "|    value_loss         | 8.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157100   |\n",
      "|    time_elapsed       | 1641     |\n",
      "|    total_timesteps    | 785500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00665 |\n",
      "|    explained_variance | -23.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157099   |\n",
      "|    policy_loss        | 0.0049   |\n",
      "|    value_loss         | 42.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157200   |\n",
      "|    time_elapsed       | 1642     |\n",
      "|    total_timesteps    | 786000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00395 |\n",
      "|    explained_variance | -511     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157199   |\n",
      "|    policy_loss        | -0.00172 |\n",
      "|    value_loss         | 23.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157300   |\n",
      "|    time_elapsed       | 1643     |\n",
      "|    total_timesteps    | 786500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.145   |\n",
      "|    explained_variance | -28.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157299   |\n",
      "|    policy_loss        | -0.863   |\n",
      "|    value_loss         | 656      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157400   |\n",
      "|    time_elapsed       | 1644     |\n",
      "|    total_timesteps    | 787000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.238   |\n",
      "|    explained_variance | -9.3     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157399   |\n",
      "|    policy_loss        | 0.417    |\n",
      "|    value_loss         | 43.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157500   |\n",
      "|    time_elapsed       | 1645     |\n",
      "|    total_timesteps    | 787500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.575   |\n",
      "|    explained_variance | -2.79    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157499   |\n",
      "|    policy_loss        | -0.438   |\n",
      "|    value_loss         | 0.751    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157600   |\n",
      "|    time_elapsed       | 1647     |\n",
      "|    total_timesteps    | 788000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.688   |\n",
      "|    explained_variance | -2.77    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157599   |\n",
      "|    policy_loss        | -0.974   |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157700   |\n",
      "|    time_elapsed       | 1648     |\n",
      "|    total_timesteps    | 788500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00117 |\n",
      "|    explained_variance | 0.0352   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157699   |\n",
      "|    policy_loss        | 0.00106  |\n",
      "|    value_loss         | 109      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.12e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 157800    |\n",
      "|    time_elapsed       | 1649      |\n",
      "|    total_timesteps    | 789000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000634 |\n",
      "|    explained_variance | 0.00186   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 157799    |\n",
      "|    policy_loss        | 0.000467  |\n",
      "|    value_loss         | 86.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 157900   |\n",
      "|    time_elapsed       | 1650     |\n",
      "|    total_timesteps    | 789500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.232   |\n",
      "|    explained_variance | -422     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157899   |\n",
      "|    policy_loss        | 9.72     |\n",
      "|    value_loss         | 192      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 158000   |\n",
      "|    time_elapsed       | 1651     |\n",
      "|    total_timesteps    | 790000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.644   |\n",
      "|    explained_variance | -1.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 157999   |\n",
      "|    policy_loss        | 0.843    |\n",
      "|    value_loss         | 0.883    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 158100   |\n",
      "|    time_elapsed       | 1652     |\n",
      "|    total_timesteps    | 790500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00457 |\n",
      "|    explained_variance | -171     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 158099   |\n",
      "|    policy_loss        | 0.0405   |\n",
      "|    value_loss         | 2.52e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 158200   |\n",
      "|    time_elapsed       | 1653     |\n",
      "|    total_timesteps    | 791000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.37    |\n",
      "|    explained_variance | -0.248   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 158199   |\n",
      "|    policy_loss        | 0.152    |\n",
      "|    value_loss         | 4.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 158300    |\n",
      "|    time_elapsed       | 1654      |\n",
      "|    total_timesteps    | 791500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000713 |\n",
      "|    explained_variance | -571      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 158299    |\n",
      "|    policy_loss        | 0.00142   |\n",
      "|    value_loss         | 556       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 158400    |\n",
      "|    time_elapsed       | 1655      |\n",
      "|    total_timesteps    | 792000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000145 |\n",
      "|    explained_variance | -25.4     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 158399    |\n",
      "|    policy_loss        | -1.89e-05 |\n",
      "|    value_loss         | 4.11      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 158500   |\n",
      "|    time_elapsed       | 1656     |\n",
      "|    total_timesteps    | 792500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.518   |\n",
      "|    explained_variance | -3.01    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 158499   |\n",
      "|    policy_loss        | 0.15     |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 158600   |\n",
      "|    time_elapsed       | 1657     |\n",
      "|    total_timesteps    | 793000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.512   |\n",
      "|    explained_variance | 0.229    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 158599   |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    value_loss         | 7.69     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 158700    |\n",
      "|    time_elapsed       | 1658      |\n",
      "|    total_timesteps    | 793500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000983 |\n",
      "|    explained_variance | 0.147     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 158699    |\n",
      "|    policy_loss        | 0.000516  |\n",
      "|    value_loss         | 39.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 158800    |\n",
      "|    time_elapsed       | 1659      |\n",
      "|    total_timesteps    | 794000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000987 |\n",
      "|    explained_variance | 0.258     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 158799    |\n",
      "|    policy_loss        | -0.000182 |\n",
      "|    value_loss         | 8.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 158900   |\n",
      "|    time_elapsed       | 1660     |\n",
      "|    total_timesteps    | 794500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00109 |\n",
      "|    explained_variance | -16.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 158899   |\n",
      "|    policy_loss        | 0.000376 |\n",
      "|    value_loss         | 28.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 159000   |\n",
      "|    time_elapsed       | 1661     |\n",
      "|    total_timesteps    | 795000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00019 |\n",
      "|    explained_variance | -8.17    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 158999   |\n",
      "|    policy_loss        | 3.36e-05 |\n",
      "|    value_loss         | 5.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 159100   |\n",
      "|    time_elapsed       | 1662     |\n",
      "|    total_timesteps    | 795500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.183   |\n",
      "|    explained_variance | -2       |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 159099   |\n",
      "|    policy_loss        | 0.00469  |\n",
      "|    value_loss         | 0.0621   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 159200   |\n",
      "|    time_elapsed       | 1663     |\n",
      "|    total_timesteps    | 796000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0781  |\n",
      "|    explained_variance | -0.405   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 159199   |\n",
      "|    policy_loss        | -0.0934  |\n",
      "|    value_loss         | 45.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 159300    |\n",
      "|    time_elapsed       | 1664      |\n",
      "|    total_timesteps    | 796500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.36e-05 |\n",
      "|    explained_variance | -2.25     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 159299    |\n",
      "|    policy_loss        | 7.47e-06  |\n",
      "|    value_loss         | 9         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 159400    |\n",
      "|    time_elapsed       | 1665      |\n",
      "|    total_timesteps    | 797000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.9e-05  |\n",
      "|    explained_variance | -7.1      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 159399    |\n",
      "|    policy_loss        | -4.55e-05 |\n",
      "|    value_loss         | 62.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 159500    |\n",
      "|    time_elapsed       | 1666      |\n",
      "|    total_timesteps    | 797500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.79e-05 |\n",
      "|    explained_variance | -15.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 159499    |\n",
      "|    policy_loss        | 1.33e-05  |\n",
      "|    value_loss         | 19.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 159600    |\n",
      "|    time_elapsed       | 1667      |\n",
      "|    total_timesteps    | 798000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000918 |\n",
      "|    explained_variance | -11.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 159599    |\n",
      "|    policy_loss        | -4.89e-05 |\n",
      "|    value_loss         | 2.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 159700   |\n",
      "|    time_elapsed       | 1668     |\n",
      "|    total_timesteps    | 798500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0684  |\n",
      "|    explained_variance | 0.487    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 159699   |\n",
      "|    policy_loss        | -0.00524 |\n",
      "|    value_loss         | 0.233    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 159800   |\n",
      "|    time_elapsed       | 1669     |\n",
      "|    total_timesteps    | 799000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0817  |\n",
      "|    explained_variance | -0.247   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 159799   |\n",
      "|    policy_loss        | 0.0638   |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 159900   |\n",
      "|    time_elapsed       | 1670     |\n",
      "|    total_timesteps    | 799500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.92    |\n",
      "|    explained_variance | -32.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 159899   |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    value_loss         | 188      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 160000    |\n",
      "|    time_elapsed       | 1671      |\n",
      "|    total_timesteps    | 800000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49e-05 |\n",
      "|    explained_variance | -1.97     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 159999    |\n",
      "|    policy_loss        | -2.18e-06 |\n",
      "|    value_loss         | 2.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 160100    |\n",
      "|    time_elapsed       | 1672      |\n",
      "|    total_timesteps    | 800500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03e-05 |\n",
      "|    explained_variance | 0.188     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 160099    |\n",
      "|    policy_loss        | -1.02e-05 |\n",
      "|    value_loss         | 4.23      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160200   |\n",
      "|    time_elapsed       | 1673     |\n",
      "|    total_timesteps    | 801000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0154  |\n",
      "|    explained_variance | -1.55    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160199   |\n",
      "|    policy_loss        | 6.42     |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160300   |\n",
      "|    time_elapsed       | 1674     |\n",
      "|    total_timesteps    | 801500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.033   |\n",
      "|    explained_variance | 0.488    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160299   |\n",
      "|    policy_loss        | -0.00908 |\n",
      "|    value_loss         | 3.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160400   |\n",
      "|    time_elapsed       | 1675     |\n",
      "|    total_timesteps    | 802000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.152   |\n",
      "|    explained_variance | 0.307    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160399   |\n",
      "|    policy_loss        | -0.0704  |\n",
      "|    value_loss         | 4.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160500   |\n",
      "|    time_elapsed       | 1676     |\n",
      "|    total_timesteps    | 802500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.827   |\n",
      "|    explained_variance | -1.85    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160499   |\n",
      "|    policy_loss        | 1.16     |\n",
      "|    value_loss         | 4.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160600   |\n",
      "|    time_elapsed       | 1677     |\n",
      "|    total_timesteps    | 803000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00172 |\n",
      "|    explained_variance | -0.467   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160599   |\n",
      "|    policy_loss        | 0.0011   |\n",
      "|    value_loss         | 53       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160700   |\n",
      "|    time_elapsed       | 1678     |\n",
      "|    total_timesteps    | 803500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00474 |\n",
      "|    explained_variance | 0.0373   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160699   |\n",
      "|    policy_loss        | 0.00181  |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160800   |\n",
      "|    time_elapsed       | 1679     |\n",
      "|    total_timesteps    | 804000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.636   |\n",
      "|    explained_variance | -17.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160799   |\n",
      "|    policy_loss        | 29.5     |\n",
      "|    value_loss         | 2.67e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 160900   |\n",
      "|    time_elapsed       | 1680     |\n",
      "|    total_timesteps    | 804500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.131   |\n",
      "|    explained_variance | 0.31     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 160899   |\n",
      "|    policy_loss        | -0.00589 |\n",
      "|    value_loss         | 0.181    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.32e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 161000    |\n",
      "|    time_elapsed       | 1681      |\n",
      "|    total_timesteps    | 805000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000102 |\n",
      "|    explained_variance | 0.62      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 160999    |\n",
      "|    policy_loss        | 2.47e-05  |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.32e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 161100   |\n",
      "|    time_elapsed       | 1682     |\n",
      "|    total_timesteps    | 805500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.304   |\n",
      "|    explained_variance | 0.411    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161099   |\n",
      "|    policy_loss        | -0.373   |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.32e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 161200    |\n",
      "|    time_elapsed       | 1683      |\n",
      "|    total_timesteps    | 806000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00487  |\n",
      "|    explained_variance | -11.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 161199    |\n",
      "|    policy_loss        | -0.000247 |\n",
      "|    value_loss         | 2.69      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.32e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 161300   |\n",
      "|    time_elapsed       | 1684     |\n",
      "|    total_timesteps    | 806500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0136  |\n",
      "|    explained_variance | 0.815    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161299   |\n",
      "|    policy_loss        | 0.000381 |\n",
      "|    value_loss         | 0.0749   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.32e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 161400   |\n",
      "|    time_elapsed       | 1685     |\n",
      "|    total_timesteps    | 807000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.564   |\n",
      "|    explained_variance | -3.45    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161399   |\n",
      "|    policy_loss        | -0.172   |\n",
      "|    value_loss         | 0.452    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.32e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 161500   |\n",
      "|    time_elapsed       | 1686     |\n",
      "|    total_timesteps    | 807500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.576   |\n",
      "|    explained_variance | -4.08    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161499   |\n",
      "|    policy_loss        | 0.102    |\n",
      "|    value_loss         | 0.334    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.34e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 161600    |\n",
      "|    time_elapsed       | 1688      |\n",
      "|    total_timesteps    | 808000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00339  |\n",
      "|    explained_variance | -0.114    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 161599    |\n",
      "|    policy_loss        | -0.000208 |\n",
      "|    value_loss         | 0.543     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.34e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 161700   |\n",
      "|    time_elapsed       | 1689     |\n",
      "|    total_timesteps    | 808500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00394 |\n",
      "|    explained_variance | -20.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161699   |\n",
      "|    policy_loss        | -0.00336 |\n",
      "|    value_loss         | 62.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.34e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 161800   |\n",
      "|    time_elapsed       | 1690     |\n",
      "|    total_timesteps    | 809000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0123  |\n",
      "|    explained_variance | -6.8     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161799   |\n",
      "|    policy_loss        | -0.00132 |\n",
      "|    value_loss         | 0.743    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.34e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 161900   |\n",
      "|    time_elapsed       | 1691     |\n",
      "|    total_timesteps    | 809500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0249  |\n",
      "|    explained_variance | -27.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161899   |\n",
      "|    policy_loss        | 0.00653  |\n",
      "|    value_loss         | 4.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.34e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162000   |\n",
      "|    time_elapsed       | 1692     |\n",
      "|    total_timesteps    | 810000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.314   |\n",
      "|    explained_variance | -0.721   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 161999   |\n",
      "|    policy_loss        | -0.994   |\n",
      "|    value_loss         | 6.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.34e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162100   |\n",
      "|    time_elapsed       | 1693     |\n",
      "|    total_timesteps    | 810500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.683   |\n",
      "|    explained_variance | -8.55    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162099   |\n",
      "|    policy_loss        | -2.66    |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.4e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162200   |\n",
      "|    time_elapsed       | 1694     |\n",
      "|    total_timesteps    | 811000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.011   |\n",
      "|    explained_variance | 0.418    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162199   |\n",
      "|    policy_loss        | 0.000976 |\n",
      "|    value_loss         | 0.657    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.4e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162300   |\n",
      "|    time_elapsed       | 1695     |\n",
      "|    total_timesteps    | 811500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.643   |\n",
      "|    explained_variance | -18.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162299   |\n",
      "|    policy_loss        | -4.2     |\n",
      "|    value_loss         | 75.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.4e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162400   |\n",
      "|    time_elapsed       | 1696     |\n",
      "|    total_timesteps    | 812000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0123  |\n",
      "|    explained_variance | -1.62    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162399   |\n",
      "|    policy_loss        | -0.00531 |\n",
      "|    value_loss         | 12.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.4e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162500   |\n",
      "|    time_elapsed       | 1697     |\n",
      "|    total_timesteps    | 812500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00893 |\n",
      "|    explained_variance | -255     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162499   |\n",
      "|    policy_loss        | 0.000964 |\n",
      "|    value_loss         | 5.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.4e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162600   |\n",
      "|    time_elapsed       | 1698     |\n",
      "|    total_timesteps    | 813000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.683   |\n",
      "|    explained_variance | -5.54    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162599   |\n",
      "|    policy_loss        | 4.01     |\n",
      "|    value_loss         | 35.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.4e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162700   |\n",
      "|    time_elapsed       | 1699     |\n",
      "|    total_timesteps    | 813500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | 0.166    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162699   |\n",
      "|    policy_loss        | -0.112   |\n",
      "|    value_loss         | 1.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.42e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162800   |\n",
      "|    time_elapsed       | 1700     |\n",
      "|    total_timesteps    | 814000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00402 |\n",
      "|    explained_variance | -14.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162799   |\n",
      "|    policy_loss        | 0.000861 |\n",
      "|    value_loss         | 5.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.42e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 162900   |\n",
      "|    time_elapsed       | 1701     |\n",
      "|    total_timesteps    | 814500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00752 |\n",
      "|    explained_variance | -238     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162899   |\n",
      "|    policy_loss        | 0.00729  |\n",
      "|    value_loss         | 196      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.42e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163000   |\n",
      "|    time_elapsed       | 1702     |\n",
      "|    total_timesteps    | 815000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00904 |\n",
      "|    explained_variance | -0.0528  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 162999   |\n",
      "|    policy_loss        | 0.00134  |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.42e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163100   |\n",
      "|    time_elapsed       | 1703     |\n",
      "|    total_timesteps    | 815500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.629   |\n",
      "|    explained_variance | -0.752   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163099   |\n",
      "|    policy_loss        | 3.73     |\n",
      "|    value_loss         | 29.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.42e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163200   |\n",
      "|    time_elapsed       | 1704     |\n",
      "|    total_timesteps    | 816000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.485   |\n",
      "|    explained_variance | -1.35    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163199   |\n",
      "|    policy_loss        | 0.068    |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.42e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163300   |\n",
      "|    time_elapsed       | 1705     |\n",
      "|    total_timesteps    | 816500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.461   |\n",
      "|    explained_variance | -3.62    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163299   |\n",
      "|    policy_loss        | -0.17    |\n",
      "|    value_loss         | 7.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.44e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163400   |\n",
      "|    time_elapsed       | 1706     |\n",
      "|    total_timesteps    | 817000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.188   |\n",
      "|    explained_variance | -3.61    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163399   |\n",
      "|    policy_loss        | -0.0222  |\n",
      "|    value_loss         | 0.645    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.44e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163500   |\n",
      "|    time_elapsed       | 1707     |\n",
      "|    total_timesteps    | 817500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00513 |\n",
      "|    explained_variance | -0.267   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163499   |\n",
      "|    policy_loss        | 0.00111  |\n",
      "|    value_loss         | 4.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.44e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163600   |\n",
      "|    time_elapsed       | 1708     |\n",
      "|    total_timesteps    | 818000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00444 |\n",
      "|    explained_variance | -348     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163599   |\n",
      "|    policy_loss        | -0.00245 |\n",
      "|    value_loss         | 29.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.44e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163700   |\n",
      "|    time_elapsed       | 1709     |\n",
      "|    total_timesteps    | 818500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.693   |\n",
      "|    explained_variance | -34.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163699   |\n",
      "|    policy_loss        | -4.21    |\n",
      "|    value_loss         | 40.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.44e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163800   |\n",
      "|    time_elapsed       | 1710     |\n",
      "|    total_timesteps    | 819000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.395   |\n",
      "|    explained_variance | -756     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163799   |\n",
      "|    policy_loss        | 0.0206   |\n",
      "|    value_loss         | 0.913    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 163900   |\n",
      "|    time_elapsed       | 1711     |\n",
      "|    total_timesteps    | 819500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.271   |\n",
      "|    explained_variance | -6.45    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163899   |\n",
      "|    policy_loss        | -20      |\n",
      "|    value_loss         | 1.27e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 164000   |\n",
      "|    time_elapsed       | 1712     |\n",
      "|    total_timesteps    | 820000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.308   |\n",
      "|    explained_variance | -0.924   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 163999   |\n",
      "|    policy_loss        | -0.0297  |\n",
      "|    value_loss         | 0.633    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 164100   |\n",
      "|    time_elapsed       | 1713     |\n",
      "|    total_timesteps    | 820500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00757 |\n",
      "|    explained_variance | -11.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 164099   |\n",
      "|    policy_loss        | 0.000288 |\n",
      "|    value_loss         | 0.304    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 164200    |\n",
      "|    time_elapsed       | 1714      |\n",
      "|    total_timesteps    | 821000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00381  |\n",
      "|    explained_variance | 0.664     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 164199    |\n",
      "|    policy_loss        | -7.02e-05 |\n",
      "|    value_loss         | 0.0406    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 164300   |\n",
      "|    time_elapsed       | 1715     |\n",
      "|    total_timesteps    | 821500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.687   |\n",
      "|    explained_variance | 0.199    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 164299   |\n",
      "|    policy_loss        | 1.23     |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 164400   |\n",
      "|    time_elapsed       | 1716     |\n",
      "|    total_timesteps    | 822000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.373   |\n",
      "|    explained_variance | -0.423   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 164399   |\n",
      "|    policy_loss        | -0.0604  |\n",
      "|    value_loss         | 0.262    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 164500    |\n",
      "|    time_elapsed       | 1717      |\n",
      "|    total_timesteps    | 822500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000892 |\n",
      "|    explained_variance | 0.211     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 164499    |\n",
      "|    policy_loss        | 0.000813  |\n",
      "|    value_loss         | 102       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 164600   |\n",
      "|    time_elapsed       | 1718     |\n",
      "|    total_timesteps    | 823000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0212  |\n",
      "|    explained_variance | -82      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 164599   |\n",
      "|    policy_loss        | -0.0144  |\n",
      "|    value_loss         | 26.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 164700   |\n",
      "|    time_elapsed       | 1719     |\n",
      "|    total_timesteps    | 823500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00294 |\n",
      "|    explained_variance | -0.0325  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 164699   |\n",
      "|    policy_loss        | 0.000225 |\n",
      "|    value_loss         | 0.705    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 164800    |\n",
      "|    time_elapsed       | 1720      |\n",
      "|    total_timesteps    | 824000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00166  |\n",
      "|    explained_variance | 0.885     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 164799    |\n",
      "|    policy_loss        | -4.94e-05 |\n",
      "|    value_loss         | 0.1       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 164900   |\n",
      "|    time_elapsed       | 1721     |\n",
      "|    total_timesteps    | 824500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.691   |\n",
      "|    explained_variance | -0.0383  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 164899   |\n",
      "|    policy_loss        | 0.347    |\n",
      "|    value_loss         | 0.347    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 165000   |\n",
      "|    time_elapsed       | 1722     |\n",
      "|    total_timesteps    | 825000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0832  |\n",
      "|    explained_variance | -11.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 164999   |\n",
      "|    policy_loss        | 0.00673  |\n",
      "|    value_loss         | 0.845    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 165100    |\n",
      "|    time_elapsed       | 1723      |\n",
      "|    total_timesteps    | 825500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000218 |\n",
      "|    explained_variance | -0.418    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 165099    |\n",
      "|    policy_loss        | 7.38e-06  |\n",
      "|    value_loss         | 0.273     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 165200    |\n",
      "|    time_elapsed       | 1724      |\n",
      "|    total_timesteps    | 826000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000114 |\n",
      "|    explained_variance | -1.6      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 165199    |\n",
      "|    policy_loss        | -4.24e-05 |\n",
      "|    value_loss         | 27.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 165300    |\n",
      "|    time_elapsed       | 1726      |\n",
      "|    total_timesteps    | 826500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000408 |\n",
      "|    explained_variance | -246      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 165299    |\n",
      "|    policy_loss        | -0.000301 |\n",
      "|    value_loss         | 95.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 165400    |\n",
      "|    time_elapsed       | 1727      |\n",
      "|    total_timesteps    | 827000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000617 |\n",
      "|    explained_variance | -1.47e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 165399    |\n",
      "|    policy_loss        | -8.65e-05 |\n",
      "|    value_loss         | 3.25      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.5e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 165500   |\n",
      "|    time_elapsed       | 1728     |\n",
      "|    total_timesteps    | 827500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.387   |\n",
      "|    explained_variance | -20.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 165499   |\n",
      "|    policy_loss        | -0.164   |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.5e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 165600   |\n",
      "|    time_elapsed       | 1729     |\n",
      "|    total_timesteps    | 828000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0779  |\n",
      "|    explained_variance | 0.441    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 165599   |\n",
      "|    policy_loss        | -0.0456  |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 165700    |\n",
      "|    time_elapsed       | 1730      |\n",
      "|    total_timesteps    | 828500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000583 |\n",
      "|    explained_variance | -34.5     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 165699    |\n",
      "|    policy_loss        | 7.66e-05  |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 165800    |\n",
      "|    time_elapsed       | 1731      |\n",
      "|    total_timesteps    | 829000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.45e-05 |\n",
      "|    explained_variance | -0.0338   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 165799    |\n",
      "|    policy_loss        | -5.06e-06 |\n",
      "|    value_loss         | 11.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 165900    |\n",
      "|    time_elapsed       | 1732      |\n",
      "|    total_timesteps    | 829500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000765 |\n",
      "|    explained_variance | -280      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 165899    |\n",
      "|    policy_loss        | -0.00019  |\n",
      "|    value_loss         | 9.12      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166000   |\n",
      "|    time_elapsed       | 1733     |\n",
      "|    total_timesteps    | 830000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.451   |\n",
      "|    explained_variance | -25      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 165999   |\n",
      "|    policy_loss        | -0.892   |\n",
      "|    value_loss         | 27.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166100   |\n",
      "|    time_elapsed       | 1734     |\n",
      "|    total_timesteps    | 830500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.546   |\n",
      "|    explained_variance | -104     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 166099   |\n",
      "|    policy_loss        | -1.33    |\n",
      "|    value_loss         | 3.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166200   |\n",
      "|    time_elapsed       | 1735     |\n",
      "|    total_timesteps    | 831000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.488   |\n",
      "|    explained_variance | -17.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 166199   |\n",
      "|    policy_loss        | 7.85     |\n",
      "|    value_loss         | 144      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166300   |\n",
      "|    time_elapsed       | 1736     |\n",
      "|    total_timesteps    | 831500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0208  |\n",
      "|    explained_variance | -1.32    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 166299   |\n",
      "|    policy_loss        | 0.00239  |\n",
      "|    value_loss         | 0.813    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 166400    |\n",
      "|    time_elapsed       | 1737      |\n",
      "|    total_timesteps    | 832000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000567 |\n",
      "|    explained_variance | -10.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 166399    |\n",
      "|    policy_loss        | -0.000225 |\n",
      "|    value_loss         | 23.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 166500    |\n",
      "|    time_elapsed       | 1738      |\n",
      "|    total_timesteps    | 832500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000891 |\n",
      "|    explained_variance | -5.06     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 166499    |\n",
      "|    policy_loss        | -2.66e-06 |\n",
      "|    value_loss         | 0.0402    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166600   |\n",
      "|    time_elapsed       | 1739     |\n",
      "|    total_timesteps    | 833000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.66    |\n",
      "|    explained_variance | -2.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 166599   |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    value_loss         | 237      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166700   |\n",
      "|    time_elapsed       | 1740     |\n",
      "|    total_timesteps    | 833500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.573   |\n",
      "|    explained_variance | -3.28    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 166699   |\n",
      "|    policy_loss        | 0.58     |\n",
      "|    value_loss         | 0.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166800   |\n",
      "|    time_elapsed       | 1741     |\n",
      "|    total_timesteps    | 834000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.658   |\n",
      "|    explained_variance | -1.58    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 166799   |\n",
      "|    policy_loss        | -2.4     |\n",
      "|    value_loss         | 6.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.46e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 166900   |\n",
      "|    time_elapsed       | 1742     |\n",
      "|    total_timesteps    | 834500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.546   |\n",
      "|    explained_variance | 0.507    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 166899   |\n",
      "|    policy_loss        | -0.695   |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.46e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 167000    |\n",
      "|    time_elapsed       | 1743      |\n",
      "|    total_timesteps    | 835000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000552 |\n",
      "|    explained_variance | -0.428    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 166999    |\n",
      "|    policy_loss        | 7.92e-05  |\n",
      "|    value_loss         | 3.25      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.46e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 167100    |\n",
      "|    time_elapsed       | 1744      |\n",
      "|    total_timesteps    | 835500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.85e-05 |\n",
      "|    explained_variance | -1.14     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 167099    |\n",
      "|    policy_loss        | 2.64e-06  |\n",
      "|    value_loss         | 1.01      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.46e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 167200   |\n",
      "|    time_elapsed       | 1745     |\n",
      "|    total_timesteps    | 836000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.112   |\n",
      "|    explained_variance | -4.28    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 167199   |\n",
      "|    policy_loss        | 0.181    |\n",
      "|    value_loss         | 85       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.46e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 167300   |\n",
      "|    time_elapsed       | 1746     |\n",
      "|    total_timesteps    | 836500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0128  |\n",
      "|    explained_variance | -3.42    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 167299   |\n",
      "|    policy_loss        | 0.00114  |\n",
      "|    value_loss         | 0.722    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.47e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 167400    |\n",
      "|    time_elapsed       | 1747      |\n",
      "|    total_timesteps    | 837000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000111 |\n",
      "|    explained_variance | -86.7     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 167399    |\n",
      "|    policy_loss        | 8.24e-05  |\n",
      "|    value_loss         | 336       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.47e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 167500   |\n",
      "|    time_elapsed       | 1748     |\n",
      "|    total_timesteps    | 837500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00883 |\n",
      "|    explained_variance | -43.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 167499   |\n",
      "|    policy_loss        | 0.0177   |\n",
      "|    value_loss         | 240      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.47e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 167600   |\n",
      "|    time_elapsed       | 1749     |\n",
      "|    total_timesteps    | 838000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00023 |\n",
      "|    explained_variance | -196     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 167599   |\n",
      "|    policy_loss        | 0.000194 |\n",
      "|    value_loss         | 139      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.47e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 167700    |\n",
      "|    time_elapsed       | 1750      |\n",
      "|    total_timesteps    | 838500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000317 |\n",
      "|    explained_variance | -2.29     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 167699    |\n",
      "|    policy_loss        | 1.52e-05  |\n",
      "|    value_loss         | 0.356     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.47e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 167800   |\n",
      "|    time_elapsed       | 1752     |\n",
      "|    total_timesteps    | 839000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0326  |\n",
      "|    explained_variance | -0.832   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 167799   |\n",
      "|    policy_loss        | 0.00056  |\n",
      "|    value_loss         | 0.0293   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.47e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 167900   |\n",
      "|    time_elapsed       | 1753     |\n",
      "|    total_timesteps    | 839500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.144   |\n",
      "|    explained_variance | -948     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 167899   |\n",
      "|    policy_loss        | -0.131   |\n",
      "|    value_loss         | 40.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168000    |\n",
      "|    time_elapsed       | 1754      |\n",
      "|    total_timesteps    | 840000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000116 |\n",
      "|    explained_variance | -0.221    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 167999    |\n",
      "|    policy_loss        | -2.21e-05 |\n",
      "|    value_loss         | 6.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168100    |\n",
      "|    time_elapsed       | 1755      |\n",
      "|    total_timesteps    | 840500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000138 |\n",
      "|    explained_variance | -15.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 168099    |\n",
      "|    policy_loss        | -8.92e-05 |\n",
      "|    value_loss         | 81        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168200    |\n",
      "|    time_elapsed       | 1756      |\n",
      "|    total_timesteps    | 841000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.13e-05 |\n",
      "|    explained_variance | 0.0695    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 168199    |\n",
      "|    policy_loss        | 3.19e-06  |\n",
      "|    value_loss         | 0.335     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168300    |\n",
      "|    time_elapsed       | 1757      |\n",
      "|    total_timesteps    | 841500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.37e-05 |\n",
      "|    explained_variance | 0.278     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 168299    |\n",
      "|    policy_loss        | 1.18e-07  |\n",
      "|    value_loss         | 0.0364    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 168400   |\n",
      "|    time_elapsed       | 1758     |\n",
      "|    total_timesteps    | 842000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.684   |\n",
      "|    explained_variance | -118     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 168399   |\n",
      "|    policy_loss        | -0.241   |\n",
      "|    value_loss         | 0.497    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 168500   |\n",
      "|    time_elapsed       | 1759     |\n",
      "|    total_timesteps    | 842500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | -0.643   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 168499   |\n",
      "|    policy_loss        | 2.92     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168600    |\n",
      "|    time_elapsed       | 1760      |\n",
      "|    total_timesteps    | 843000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.12e-05 |\n",
      "|    explained_variance | -1.23     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 168599    |\n",
      "|    policy_loss        | -1.24e-05 |\n",
      "|    value_loss         | 11.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168700    |\n",
      "|    time_elapsed       | 1761      |\n",
      "|    total_timesteps    | 843500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000374 |\n",
      "|    explained_variance | -0.178    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 168699    |\n",
      "|    policy_loss        | -7.38e-05 |\n",
      "|    value_loss         | 11        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168800    |\n",
      "|    time_elapsed       | 1762      |\n",
      "|    total_timesteps    | 844000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000247 |\n",
      "|    explained_variance | -0.357    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 168799    |\n",
      "|    policy_loss        | 1.16e-05  |\n",
      "|    value_loss         | 0.348     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 168900    |\n",
      "|    time_elapsed       | 1763      |\n",
      "|    total_timesteps    | 844500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000532 |\n",
      "|    explained_variance | -112      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 168899    |\n",
      "|    policy_loss        | 0.000643  |\n",
      "|    value_loss         | 206       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 169000   |\n",
      "|    time_elapsed       | 1764     |\n",
      "|    total_timesteps    | 845000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.237   |\n",
      "|    explained_variance | 0.359    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 168999   |\n",
      "|    policy_loss        | 0.0314   |\n",
      "|    value_loss         | 0.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.49e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 169100   |\n",
      "|    time_elapsed       | 1765     |\n",
      "|    total_timesteps    | 845500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.297   |\n",
      "|    explained_variance | -10.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 169099   |\n",
      "|    policy_loss        | -0.291   |\n",
      "|    value_loss         | 170      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.51e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 169200    |\n",
      "|    time_elapsed       | 1766      |\n",
      "|    total_timesteps    | 846000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.683    |\n",
      "|    explained_variance | -1.49e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 169199    |\n",
      "|    policy_loss        | 11.5      |\n",
      "|    value_loss         | 2.26e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.51e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 169300    |\n",
      "|    time_elapsed       | 1767      |\n",
      "|    total_timesteps    | 846500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000324 |\n",
      "|    explained_variance | -54.2     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 169299    |\n",
      "|    policy_loss        | -0.000314 |\n",
      "|    value_loss         | 291       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.51e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 169400    |\n",
      "|    time_elapsed       | 1768      |\n",
      "|    total_timesteps    | 847000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000474 |\n",
      "|    explained_variance | 0.753     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 169399    |\n",
      "|    policy_loss        | 1.25e-05  |\n",
      "|    value_loss         | 0.0938    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.51e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 169500   |\n",
      "|    time_elapsed       | 1769     |\n",
      "|    total_timesteps    | 847500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.483   |\n",
      "|    explained_variance | -19.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 169499   |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    value_loss         | 31.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.51e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 169600   |\n",
      "|    time_elapsed       | 1770     |\n",
      "|    total_timesteps    | 848000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.49    |\n",
      "|    explained_variance | -499     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 169599   |\n",
      "|    policy_loss        | -0.189   |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.51e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 169700   |\n",
      "|    time_elapsed       | 1771     |\n",
      "|    total_timesteps    | 848500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.448   |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 169699   |\n",
      "|    policy_loss        | 1.35     |\n",
      "|    value_loss         | 5.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 169800   |\n",
      "|    time_elapsed       | 1772     |\n",
      "|    total_timesteps    | 849000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.934   |\n",
      "|    explained_variance | -47.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 169799   |\n",
      "|    policy_loss        | -0.532   |\n",
      "|    value_loss         | 0.855    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 169900   |\n",
      "|    time_elapsed       | 1773     |\n",
      "|    total_timesteps    | 849500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00126 |\n",
      "|    explained_variance | 0.475    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 169899   |\n",
      "|    policy_loss        | 0.000375 |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 170000    |\n",
      "|    time_elapsed       | 1774      |\n",
      "|    total_timesteps    | 850000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000657 |\n",
      "|    explained_variance | -15.7     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 169999    |\n",
      "|    policy_loss        | 5.52e-05  |\n",
      "|    value_loss         | 1.5       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 170100   |\n",
      "|    time_elapsed       | 1775     |\n",
      "|    total_timesteps    | 850500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.63    |\n",
      "|    explained_variance | -11.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 170099   |\n",
      "|    policy_loss        | -0.0811  |\n",
      "|    value_loss         | 3.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 170200   |\n",
      "|    time_elapsed       | 1776     |\n",
      "|    total_timesteps    | 851000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.272   |\n",
      "|    explained_variance | -0.0579  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 170199   |\n",
      "|    policy_loss        | 0.24     |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 170300    |\n",
      "|    time_elapsed       | 1777      |\n",
      "|    total_timesteps    | 851500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000298 |\n",
      "|    explained_variance | -3.75     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 170299    |\n",
      "|    policy_loss        | -0.000162 |\n",
      "|    value_loss         | 84.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.5e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 170400   |\n",
      "|    time_elapsed       | 1778     |\n",
      "|    total_timesteps    | 852000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.26    |\n",
      "|    explained_variance | 0.446    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 170399   |\n",
      "|    policy_loss        | 3.46     |\n",
      "|    value_loss         | 51.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 170500    |\n",
      "|    time_elapsed       | 1779      |\n",
      "|    total_timesteps    | 852500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000669 |\n",
      "|    explained_variance | -1.13     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 170499    |\n",
      "|    policy_loss        | 0.000215  |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.5e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 170600   |\n",
      "|    time_elapsed       | 1780     |\n",
      "|    total_timesteps    | 853000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00146 |\n",
      "|    explained_variance | -0.036   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 170599   |\n",
      "|    policy_loss        | 0.00043  |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.5e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 170700   |\n",
      "|    time_elapsed       | 1781     |\n",
      "|    total_timesteps    | 853500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.385   |\n",
      "|    explained_variance | -9.92    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 170699   |\n",
      "|    policy_loss        | -1.15    |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.5e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 170800   |\n",
      "|    time_elapsed       | 1782     |\n",
      "|    total_timesteps    | 854000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.68    |\n",
      "|    explained_variance | -4.18    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 170799   |\n",
      "|    policy_loss        | -0.439   |\n",
      "|    value_loss         | 0.743    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.54e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 170900    |\n",
      "|    time_elapsed       | 1783      |\n",
      "|    total_timesteps    | 854500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000654 |\n",
      "|    explained_variance | 0.484     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 170899    |\n",
      "|    policy_loss        | 9.63e-05  |\n",
      "|    value_loss         | 5.53      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.54e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 171000    |\n",
      "|    time_elapsed       | 1784      |\n",
      "|    total_timesteps    | 855000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000294 |\n",
      "|    explained_variance | -0.797    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 170999    |\n",
      "|    policy_loss        | -6.2e-06  |\n",
      "|    value_loss         | 0.327     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.54e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 171100    |\n",
      "|    time_elapsed       | 1785      |\n",
      "|    total_timesteps    | 855500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00123  |\n",
      "|    explained_variance | 0.59      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 171099    |\n",
      "|    policy_loss        | -5.76e-05 |\n",
      "|    value_loss         | 0.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.54e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 171200   |\n",
      "|    time_elapsed       | 1786     |\n",
      "|    total_timesteps    | 856000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.001   |\n",
      "|    explained_variance | -51      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 171199   |\n",
      "|    policy_loss        | 0.000179 |\n",
      "|    value_loss         | 4.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.54e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 171300   |\n",
      "|    time_elapsed       | 1787     |\n",
      "|    total_timesteps    | 856500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.302   |\n",
      "|    explained_variance | -0.803   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 171299   |\n",
      "|    policy_loss        | 3.43     |\n",
      "|    value_loss         | 42.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.54e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 171400   |\n",
      "|    time_elapsed       | 1788     |\n",
      "|    total_timesteps    | 857000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.639   |\n",
      "|    explained_variance | -5.15    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 171399   |\n",
      "|    policy_loss        | -1.9     |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.52e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 171500   |\n",
      "|    time_elapsed       | 1789     |\n",
      "|    total_timesteps    | 857500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00039 |\n",
      "|    explained_variance | -2.64    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 171499   |\n",
      "|    policy_loss        | 3.68e-05 |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.52e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 171600   |\n",
      "|    time_elapsed       | 1790     |\n",
      "|    total_timesteps    | 858000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.289   |\n",
      "|    explained_variance | -46.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 171599   |\n",
      "|    policy_loss        | 9.86     |\n",
      "|    value_loss         | 2.14e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.52e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 171700    |\n",
      "|    time_elapsed       | 1791      |\n",
      "|    total_timesteps    | 858500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000117 |\n",
      "|    explained_variance | -15.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 171699    |\n",
      "|    policy_loss        | -3.14e-05 |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.52e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 171800    |\n",
      "|    time_elapsed       | 1792      |\n",
      "|    total_timesteps    | 859000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000128 |\n",
      "|    explained_variance | -61.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 171799    |\n",
      "|    policy_loss        | -2.17e-05 |\n",
      "|    value_loss         | 19.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.52e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 171900   |\n",
      "|    time_elapsed       | 1793     |\n",
      "|    total_timesteps    | 859500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.272   |\n",
      "|    explained_variance | -0.591   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 171899   |\n",
      "|    policy_loss        | 0.941    |\n",
      "|    value_loss         | 3.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.52e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 172000   |\n",
      "|    time_elapsed       | 1794     |\n",
      "|    total_timesteps    | 860000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.303   |\n",
      "|    explained_variance | -0.623   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 171999   |\n",
      "|    policy_loss        | -0.501   |\n",
      "|    value_loss         | 30.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.57e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 172100    |\n",
      "|    time_elapsed       | 1795      |\n",
      "|    total_timesteps    | 860500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000909 |\n",
      "|    explained_variance | -152      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 172099    |\n",
      "|    policy_loss        | 0.00042   |\n",
      "|    value_loss         | 32        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.57e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 172200    |\n",
      "|    time_elapsed       | 1796      |\n",
      "|    total_timesteps    | 861000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000443 |\n",
      "|    explained_variance | -45.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 172199    |\n",
      "|    policy_loss        | 3.8e-05   |\n",
      "|    value_loss         | 45.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.57e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 172300    |\n",
      "|    time_elapsed       | 1797      |\n",
      "|    total_timesteps    | 861500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000786 |\n",
      "|    explained_variance | -257      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 172299    |\n",
      "|    policy_loss        | 0.000577  |\n",
      "|    value_loss         | 202       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.57e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 172400   |\n",
      "|    time_elapsed       | 1798     |\n",
      "|    total_timesteps    | 862000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.617   |\n",
      "|    explained_variance | -2.68    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 172399   |\n",
      "|    policy_loss        | -4.59    |\n",
      "|    value_loss         | 58.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.57e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 172500   |\n",
      "|    time_elapsed       | 1799     |\n",
      "|    total_timesteps    | 862500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.106   |\n",
      "|    explained_variance | -26.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 172499   |\n",
      "|    policy_loss        | -0.0221  |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.57e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 172600   |\n",
      "|    time_elapsed       | 1800     |\n",
      "|    total_timesteps    | 863000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.221   |\n",
      "|    explained_variance | -5.97    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 172599   |\n",
      "|    policy_loss        | -0.0317  |\n",
      "|    value_loss         | 3.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 172700   |\n",
      "|    time_elapsed       | 1801     |\n",
      "|    total_timesteps    | 863500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.775    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 172699   |\n",
      "|    policy_loss        | -0.0642  |\n",
      "|    value_loss         | 0.00477  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 172800   |\n",
      "|    time_elapsed       | 1802     |\n",
      "|    total_timesteps    | 864000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00112 |\n",
      "|    explained_variance | -2.45    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 172799   |\n",
      "|    policy_loss        | 0.000484 |\n",
      "|    value_loss         | 26.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 172900   |\n",
      "|    time_elapsed       | 1803     |\n",
      "|    total_timesteps    | 864500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00213 |\n",
      "|    explained_variance | -8.02    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 172899   |\n",
      "|    policy_loss        | 1.07e-05 |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 173000   |\n",
      "|    time_elapsed       | 1805     |\n",
      "|    total_timesteps    | 865000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.286   |\n",
      "|    explained_variance | -0.258   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 172999   |\n",
      "|    policy_loss        | 0.00192  |\n",
      "|    value_loss         | 0.0758   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 173100   |\n",
      "|    time_elapsed       | 1806     |\n",
      "|    total_timesteps    | 865500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.252   |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 173099   |\n",
      "|    policy_loss        | 0.00173  |\n",
      "|    value_loss         | 0.0186   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.63e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 173200    |\n",
      "|    time_elapsed       | 1807      |\n",
      "|    total_timesteps    | 866000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00183  |\n",
      "|    explained_variance | 0.0423    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 173199    |\n",
      "|    policy_loss        | -0.000918 |\n",
      "|    value_loss         | 34.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 173300   |\n",
      "|    time_elapsed       | 1808     |\n",
      "|    total_timesteps    | 866500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0551  |\n",
      "|    explained_variance | -20.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 173299   |\n",
      "|    policy_loss        | 0.0316   |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 173400   |\n",
      "|    time_elapsed       | 1809     |\n",
      "|    total_timesteps    | 867000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00123 |\n",
      "|    explained_variance | 0.255    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 173399   |\n",
      "|    policy_loss        | 6.63e-05 |\n",
      "|    value_loss         | 0.479    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.63e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 173500    |\n",
      "|    time_elapsed       | 1810      |\n",
      "|    total_timesteps    | 867500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000309 |\n",
      "|    explained_variance | -0.267    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 173499    |\n",
      "|    policy_loss        | 1.85e-05  |\n",
      "|    value_loss         | 0.535     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 173600   |\n",
      "|    time_elapsed       | 1811     |\n",
      "|    total_timesteps    | 868000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0474  |\n",
      "|    explained_variance | -0.097   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 173599   |\n",
      "|    policy_loss        | -0.00113 |\n",
      "|    value_loss         | 0.0257   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 173700   |\n",
      "|    time_elapsed       | 1812     |\n",
      "|    total_timesteps    | 868500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0552  |\n",
      "|    explained_variance | -10.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 173699   |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.62e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 173800    |\n",
      "|    time_elapsed       | 1813      |\n",
      "|    total_timesteps    | 869000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000299 |\n",
      "|    explained_variance | 0.444     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 173799    |\n",
      "|    policy_loss        | -1.13e-05 |\n",
      "|    value_loss         | 0.885     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.62e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 173900   |\n",
      "|    time_elapsed       | 1814     |\n",
      "|    total_timesteps    | 869500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0158  |\n",
      "|    explained_variance | 0.161    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 173899   |\n",
      "|    policy_loss        | -0.00193 |\n",
      "|    value_loss         | 0.949    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.62e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 174000    |\n",
      "|    time_elapsed       | 1815      |\n",
      "|    total_timesteps    | 870000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00137  |\n",
      "|    explained_variance | -127      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 173999    |\n",
      "|    policy_loss        | -0.000231 |\n",
      "|    value_loss         | 6.05      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.62e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 174100   |\n",
      "|    time_elapsed       | 1816     |\n",
      "|    total_timesteps    | 870500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00313 |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 174099   |\n",
      "|    policy_loss        | -0.00185 |\n",
      "|    value_loss         | 43.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.62e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 174200   |\n",
      "|    time_elapsed       | 1817     |\n",
      "|    total_timesteps    | 871000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.306   |\n",
      "|    explained_variance | -0.219   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 174199   |\n",
      "|    policy_loss        | 0.297    |\n",
      "|    value_loss         | 0.641    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.62e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 174300   |\n",
      "|    time_elapsed       | 1818     |\n",
      "|    total_timesteps    | 871500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.35    |\n",
      "|    explained_variance | 0.834    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 174299   |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 0.0353   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 174400   |\n",
      "|    time_elapsed       | 1819     |\n",
      "|    total_timesteps    | 872000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00238 |\n",
      "|    explained_variance | -0.0603  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 174399   |\n",
      "|    policy_loss        | 7.75e-05 |\n",
      "|    value_loss         | 0.195    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 174500   |\n",
      "|    time_elapsed       | 1820     |\n",
      "|    total_timesteps    | 872500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00469 |\n",
      "|    explained_variance | 0.475    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 174499   |\n",
      "|    policy_loss        | 0.00407  |\n",
      "|    value_loss         | 81.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.59e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 174600    |\n",
      "|    time_elapsed       | 1821      |\n",
      "|    total_timesteps    | 873000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000362 |\n",
      "|    explained_variance | -1.75e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 174599    |\n",
      "|    policy_loss        | -0.000303 |\n",
      "|    value_loss         | 165       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.59e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 174700    |\n",
      "|    time_elapsed       | 1822      |\n",
      "|    total_timesteps    | 873500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000376 |\n",
      "|    explained_variance | -11.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 174699    |\n",
      "|    policy_loss        | 1.04e-06  |\n",
      "|    value_loss         | 0.00668   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 174800   |\n",
      "|    time_elapsed       | 1823     |\n",
      "|    total_timesteps    | 874000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.084   |\n",
      "|    explained_variance | -116     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 174799   |\n",
      "|    policy_loss        | -0.0482  |\n",
      "|    value_loss         | 8.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 174900   |\n",
      "|    time_elapsed       | 1824     |\n",
      "|    total_timesteps    | 874500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.373   |\n",
      "|    explained_variance | 0.103    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 174899   |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    value_loss         | 3.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.59e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 175000    |\n",
      "|    time_elapsed       | 1825      |\n",
      "|    total_timesteps    | 875000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000162 |\n",
      "|    explained_variance | -0.231    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 174999    |\n",
      "|    policy_loss        | -9.39e-06 |\n",
      "|    value_loss         | 0.709     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 175100   |\n",
      "|    time_elapsed       | 1826     |\n",
      "|    total_timesteps    | 875500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.471   |\n",
      "|    explained_variance | -9.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 175099   |\n",
      "|    policy_loss        | 5.95     |\n",
      "|    value_loss         | 434      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.59e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 175200    |\n",
      "|    time_elapsed       | 1827      |\n",
      "|    total_timesteps    | 876000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000731 |\n",
      "|    explained_variance | -12.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 175199    |\n",
      "|    policy_loss        | -2.46e-05 |\n",
      "|    value_loss         | 0.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 175300   |\n",
      "|    time_elapsed       | 1828     |\n",
      "|    total_timesteps    | 876500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.67    |\n",
      "|    explained_variance | -322     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 175299   |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    value_loss         | 1.55e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 175400   |\n",
      "|    time_elapsed       | 1829     |\n",
      "|    total_timesteps    | 877000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0158  |\n",
      "|    explained_variance | -3.57    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 175399   |\n",
      "|    policy_loss        | -0.00195 |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.59e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 175500    |\n",
      "|    time_elapsed       | 1830      |\n",
      "|    total_timesteps    | 877500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00281  |\n",
      "|    explained_variance | 0.293     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 175499    |\n",
      "|    policy_loss        | -0.000514 |\n",
      "|    value_loss         | 3.34      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 175600   |\n",
      "|    time_elapsed       | 1831     |\n",
      "|    total_timesteps    | 878000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.178   |\n",
      "|    explained_variance | -0.00425 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 175599   |\n",
      "|    policy_loss        | 0.0765   |\n",
      "|    value_loss         | 3.98     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.61e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 175700    |\n",
      "|    time_elapsed       | 1832      |\n",
      "|    total_timesteps    | 878500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.22e-05 |\n",
      "|    explained_variance | -70.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 175699    |\n",
      "|    policy_loss        | -1.09e-05 |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.61e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 175800    |\n",
      "|    time_elapsed       | 1833      |\n",
      "|    total_timesteps    | 879000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.23e-05 |\n",
      "|    explained_variance | -3.81     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 175799    |\n",
      "|    policy_loss        | -4.89e-06 |\n",
      "|    value_loss         | 1.38      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 175900   |\n",
      "|    time_elapsed       | 1834     |\n",
      "|    total_timesteps    | 879500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0142  |\n",
      "|    explained_variance | -4.73    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 175899   |\n",
      "|    policy_loss        | -0.00213 |\n",
      "|    value_loss         | 1.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176000   |\n",
      "|    time_elapsed       | 1835     |\n",
      "|    total_timesteps    | 880000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0186  |\n",
      "|    explained_variance | -11.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 175999   |\n",
      "|    policy_loss        | 0.00301  |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176100   |\n",
      "|    time_elapsed       | 1836     |\n",
      "|    total_timesteps    | 880500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00921 |\n",
      "|    explained_variance | -19.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176099   |\n",
      "|    policy_loss        | -1.17    |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176200   |\n",
      "|    time_elapsed       | 1837     |\n",
      "|    total_timesteps    | 881000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.135   |\n",
      "|    explained_variance | -14.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176199   |\n",
      "|    policy_loss        | -0.0542  |\n",
      "|    value_loss         | 9.46     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.63e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 176300    |\n",
      "|    time_elapsed       | 1838      |\n",
      "|    total_timesteps    | 881500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000561 |\n",
      "|    explained_variance | -1.25     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 176299    |\n",
      "|    policy_loss        | -2.24e-05 |\n",
      "|    value_loss         | 0.918     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176400   |\n",
      "|    time_elapsed       | 1839     |\n",
      "|    total_timesteps    | 882000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00414 |\n",
      "|    explained_variance | 0.13     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176399   |\n",
      "|    policy_loss        | 0.000439 |\n",
      "|    value_loss         | 0.985    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.63e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 176500    |\n",
      "|    time_elapsed       | 1840      |\n",
      "|    total_timesteps    | 882500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00592  |\n",
      "|    explained_variance | -6.67     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 176499    |\n",
      "|    policy_loss        | -0.000962 |\n",
      "|    value_loss         | 3.04      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176600   |\n",
      "|    time_elapsed       | 1841     |\n",
      "|    total_timesteps    | 883000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00824 |\n",
      "|    explained_variance | -1.67    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176599   |\n",
      "|    policy_loss        | 0.000544 |\n",
      "|    value_loss         | 0.322    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.66e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176700   |\n",
      "|    time_elapsed       | 1842     |\n",
      "|    total_timesteps    | 883500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00733 |\n",
      "|    explained_variance | -23.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176699   |\n",
      "|    policy_loss        | 0.00191  |\n",
      "|    value_loss         | 16       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.66e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176800   |\n",
      "|    time_elapsed       | 1843     |\n",
      "|    total_timesteps    | 884000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.181   |\n",
      "|    explained_variance | 0.424    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176799   |\n",
      "|    policy_loss        | 0.00599  |\n",
      "|    value_loss         | 3.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.66e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 176900   |\n",
      "|    time_elapsed       | 1844     |\n",
      "|    total_timesteps    | 884500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00965 |\n",
      "|    explained_variance | -291     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176899   |\n",
      "|    policy_loss        | 0.00202  |\n",
      "|    value_loss         | 17       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.66e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177000   |\n",
      "|    time_elapsed       | 1845     |\n",
      "|    total_timesteps    | 885000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0215  |\n",
      "|    explained_variance | 0.956    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 176999   |\n",
      "|    policy_loss        | -0.00184 |\n",
      "|    value_loss         | 0.339    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.66e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177100   |\n",
      "|    time_elapsed       | 1846     |\n",
      "|    total_timesteps    | 885500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0276  |\n",
      "|    explained_variance | -0.373   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177099   |\n",
      "|    policy_loss        | -0.0022  |\n",
      "|    value_loss         | 0.33     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.66e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 177200    |\n",
      "|    time_elapsed       | 1847      |\n",
      "|    total_timesteps    | 886000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00533  |\n",
      "|    explained_variance | -317      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 177199    |\n",
      "|    policy_loss        | -0.000386 |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177300   |\n",
      "|    time_elapsed       | 1849     |\n",
      "|    total_timesteps    | 886500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00484 |\n",
      "|    explained_variance | 0.353    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177299   |\n",
      "|    policy_loss        | -0.00311 |\n",
      "|    value_loss         | 32       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177400   |\n",
      "|    time_elapsed       | 1850     |\n",
      "|    total_timesteps    | 887000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00411 |\n",
      "|    explained_variance | -329     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177399   |\n",
      "|    policy_loss        | 0.000317 |\n",
      "|    value_loss         | 76.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177500   |\n",
      "|    time_elapsed       | 1851     |\n",
      "|    total_timesteps    | 887500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00232 |\n",
      "|    explained_variance | 0.644    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177499   |\n",
      "|    policy_loss        | 6.77e-06 |\n",
      "|    value_loss         | 0.0155   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177600   |\n",
      "|    time_elapsed       | 1852     |\n",
      "|    total_timesteps    | 888000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0068  |\n",
      "|    explained_variance | -71.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177599   |\n",
      "|    policy_loss        | 0.000303 |\n",
      "|    value_loss         | 0.545    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177700   |\n",
      "|    time_elapsed       | 1853     |\n",
      "|    total_timesteps    | 888500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00503 |\n",
      "|    explained_variance | -14      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177699   |\n",
      "|    policy_loss        | 0.000575 |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 177800   |\n",
      "|    time_elapsed       | 1854     |\n",
      "|    total_timesteps    | 889000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00163 |\n",
      "|    explained_variance | -133     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177799   |\n",
      "|    policy_loss        | 0.000176 |\n",
      "|    value_loss         | 4.97     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.71e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 177900    |\n",
      "|    time_elapsed       | 1855      |\n",
      "|    total_timesteps    | 889500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00714  |\n",
      "|    explained_variance | 0.916     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 177899    |\n",
      "|    policy_loss        | -3.76e-05 |\n",
      "|    value_loss         | 0.00763   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.71e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 178000   |\n",
      "|    time_elapsed       | 1856     |\n",
      "|    total_timesteps    | 890000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0386  |\n",
      "|    explained_variance | -101     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 177999   |\n",
      "|    policy_loss        | 0.0125   |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.71e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 178100   |\n",
      "|    time_elapsed       | 1857     |\n",
      "|    total_timesteps    | 890500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.07    |\n",
      "|    explained_variance | -98.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 178099   |\n",
      "|    policy_loss        | -0.0637  |\n",
      "|    value_loss         | 26.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.71e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 178200    |\n",
      "|    time_elapsed       | 1858      |\n",
      "|    total_timesteps    | 891000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00862  |\n",
      "|    explained_variance | -3.29     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 178199    |\n",
      "|    policy_loss        | -0.000851 |\n",
      "|    value_loss         | 0.665     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.71e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 178300   |\n",
      "|    time_elapsed       | 1859     |\n",
      "|    total_timesteps    | 891500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0217  |\n",
      "|    explained_variance | -12.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 178299   |\n",
      "|    policy_loss        | 0.0054   |\n",
      "|    value_loss         | 2.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.71e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 178400   |\n",
      "|    time_elapsed       | 1860     |\n",
      "|    total_timesteps    | 892000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00415 |\n",
      "|    explained_variance | -5.26    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 178399   |\n",
      "|    policy_loss        | 0.00219  |\n",
      "|    value_loss         | 34.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.73e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 178500   |\n",
      "|    time_elapsed       | 1861     |\n",
      "|    total_timesteps    | 892500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.319   |\n",
      "|    explained_variance | 0.142    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 178499   |\n",
      "|    policy_loss        | -0.11    |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.73e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 178600   |\n",
      "|    time_elapsed       | 1862     |\n",
      "|    total_timesteps    | 893000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.121   |\n",
      "|    explained_variance | 0.58     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 178599   |\n",
      "|    policy_loss        | 2.63     |\n",
      "|    value_loss         | 7.19     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.73e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 178700    |\n",
      "|    time_elapsed       | 1863      |\n",
      "|    total_timesteps    | 893500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00201  |\n",
      "|    explained_variance | 0.522     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 178699    |\n",
      "|    policy_loss        | -6.17e-05 |\n",
      "|    value_loss         | 0.118     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.73e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 178800   |\n",
      "|    time_elapsed       | 1864     |\n",
      "|    total_timesteps    | 894000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0845  |\n",
      "|    explained_variance | -4.29    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 178799   |\n",
      "|    policy_loss        | 0.00864  |\n",
      "|    value_loss         | 0.504    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.73e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 178900    |\n",
      "|    time_elapsed       | 1865      |\n",
      "|    total_timesteps    | 894500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00346  |\n",
      "|    explained_variance | -27.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 178899    |\n",
      "|    policy_loss        | -0.000138 |\n",
      "|    value_loss         | 0.175     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.73e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 179000    |\n",
      "|    time_elapsed       | 1866      |\n",
      "|    total_timesteps    | 895000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00386  |\n",
      "|    explained_variance | -3.69e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 178999    |\n",
      "|    policy_loss        | 0.00453   |\n",
      "|    value_loss         | 210       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.75e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179100   |\n",
      "|    time_elapsed       | 1867     |\n",
      "|    total_timesteps    | 895500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0864  |\n",
      "|    explained_variance | -0.0187  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179099   |\n",
      "|    policy_loss        | -0.00724 |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.75e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179200   |\n",
      "|    time_elapsed       | 1868     |\n",
      "|    total_timesteps    | 896000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00345 |\n",
      "|    explained_variance | -0.00615 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179199   |\n",
      "|    policy_loss        | 0.00119  |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.75e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179300   |\n",
      "|    time_elapsed       | 1869     |\n",
      "|    total_timesteps    | 896500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00317 |\n",
      "|    explained_variance | -133     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179299   |\n",
      "|    policy_loss        | 0.00295  |\n",
      "|    value_loss         | 82.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.75e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179400   |\n",
      "|    time_elapsed       | 1870     |\n",
      "|    total_timesteps    | 897000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.153   |\n",
      "|    explained_variance | -172     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179399   |\n",
      "|    policy_loss        | -0.0304  |\n",
      "|    value_loss         | 3.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.75e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179500   |\n",
      "|    time_elapsed       | 1871     |\n",
      "|    total_timesteps    | 897500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.07    |\n",
      "|    explained_variance | -2.51    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179499   |\n",
      "|    policy_loss        | 0.0076   |\n",
      "|    value_loss         | 0.374    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.79e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 179600    |\n",
      "|    time_elapsed       | 1872      |\n",
      "|    total_timesteps    | 898000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000372 |\n",
      "|    explained_variance | 0.154     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 179599    |\n",
      "|    policy_loss        | 0.000136  |\n",
      "|    value_loss         | 42.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.79e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179700   |\n",
      "|    time_elapsed       | 1873     |\n",
      "|    total_timesteps    | 898500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0445  |\n",
      "|    explained_variance | 0.537    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179699   |\n",
      "|    policy_loss        | -0.0195  |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.79e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179800   |\n",
      "|    time_elapsed       | 1874     |\n",
      "|    total_timesteps    | 899000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00273 |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179799   |\n",
      "|    policy_loss        | -0.00242 |\n",
      "|    value_loss         | 68       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.79e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 179900   |\n",
      "|    time_elapsed       | 1875     |\n",
      "|    total_timesteps    | 899500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.003   |\n",
      "|    explained_variance | -60.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179899   |\n",
      "|    policy_loss        | 0.000301 |\n",
      "|    value_loss         | 0.997    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.79e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 180000   |\n",
      "|    time_elapsed       | 1876     |\n",
      "|    total_timesteps    | 900000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0293  |\n",
      "|    explained_variance | -2.96    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 179999   |\n",
      "|    policy_loss        | -0.00116 |\n",
      "|    value_loss         | 0.0776   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.79e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 180100   |\n",
      "|    time_elapsed       | 1877     |\n",
      "|    total_timesteps    | 900500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00321 |\n",
      "|    explained_variance | -1.87    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 180099   |\n",
      "|    policy_loss        | 0.000307 |\n",
      "|    value_loss         | 0.916    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.82e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 180200   |\n",
      "|    time_elapsed       | 1878     |\n",
      "|    total_timesteps    | 901000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00362 |\n",
      "|    explained_variance | -3.89    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 180199   |\n",
      "|    policy_loss        | 0.000826 |\n",
      "|    value_loss         | 40.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.82e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 180300   |\n",
      "|    time_elapsed       | 1879     |\n",
      "|    total_timesteps    | 901500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00385 |\n",
      "|    explained_variance | -379     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 180299   |\n",
      "|    policy_loss        | -0.00962 |\n",
      "|    value_loss         | 918      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.82e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 180400    |\n",
      "|    time_elapsed       | 1880      |\n",
      "|    total_timesteps    | 902000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000845 |\n",
      "|    explained_variance | 0.479     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 180399    |\n",
      "|    policy_loss        | -6.43e-05 |\n",
      "|    value_loss         | 0.657     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.82e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 180500    |\n",
      "|    time_elapsed       | 1881      |\n",
      "|    total_timesteps    | 902500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000835 |\n",
      "|    explained_variance | -1.46     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 180499    |\n",
      "|    policy_loss        | 0.00013   |\n",
      "|    value_loss         | 2.8       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.82e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 180600   |\n",
      "|    time_elapsed       | 1882     |\n",
      "|    total_timesteps    | 903000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.237   |\n",
      "|    explained_variance | -7.9     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 180599   |\n",
      "|    policy_loss        | -2.6     |\n",
      "|    value_loss         | 4.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.82e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 180700   |\n",
      "|    time_elapsed       | 1883     |\n",
      "|    total_timesteps    | 903500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0164  |\n",
      "|    explained_variance | -2.19    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 180699   |\n",
      "|    policy_loss        | 0.00762  |\n",
      "|    value_loss         | 15       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.84e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 180800   |\n",
      "|    time_elapsed       | 1884     |\n",
      "|    total_timesteps    | 904000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00461 |\n",
      "|    explained_variance | -5.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 180799   |\n",
      "|    policy_loss        | 0.000583 |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.84e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 180900    |\n",
      "|    time_elapsed       | 1885      |\n",
      "|    total_timesteps    | 904500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.79e-05 |\n",
      "|    explained_variance | -1.23e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 180899    |\n",
      "|    policy_loss        | -1.2e-06  |\n",
      "|    value_loss         | 345       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.84e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 181000   |\n",
      "|    time_elapsed       | 1886     |\n",
      "|    total_timesteps    | 905000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00177 |\n",
      "|    explained_variance | -98      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 180999   |\n",
      "|    policy_loss        | 0.00387  |\n",
      "|    value_loss         | 765      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.84e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 181100    |\n",
      "|    time_elapsed       | 1888      |\n",
      "|    total_timesteps    | 905500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.285    |\n",
      "|    explained_variance | -4.74e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 181099    |\n",
      "|    policy_loss        | -16.5     |\n",
      "|    value_loss         | 3.6e+03   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.84e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 181200   |\n",
      "|    time_elapsed       | 1889     |\n",
      "|    total_timesteps    | 906000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.276   |\n",
      "|    explained_variance | -2.47    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 181199   |\n",
      "|    policy_loss        | 0.33     |\n",
      "|    value_loss         | 0.617    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.84e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 181300   |\n",
      "|    time_elapsed       | 1890     |\n",
      "|    total_timesteps    | 906500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0246  |\n",
      "|    explained_variance | 0.071    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 181299   |\n",
      "|    policy_loss        | 0.00284  |\n",
      "|    value_loss         | 0.6      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.86e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 181400    |\n",
      "|    time_elapsed       | 1891      |\n",
      "|    total_timesteps    | 907000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.101    |\n",
      "|    explained_variance | -1.02e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 181399    |\n",
      "|    policy_loss        | -0.443    |\n",
      "|    value_loss         | 4.87e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.86e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 181500   |\n",
      "|    time_elapsed       | 1892     |\n",
      "|    total_timesteps    | 907500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00376 |\n",
      "|    explained_variance | -41.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 181499   |\n",
      "|    policy_loss        | 0.000696 |\n",
      "|    value_loss         | 24.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.86e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 181600    |\n",
      "|    time_elapsed       | 1893      |\n",
      "|    total_timesteps    | 908000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000715 |\n",
      "|    explained_variance | -0.448    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 181599    |\n",
      "|    policy_loss        | -8.91e-05 |\n",
      "|    value_loss         | 2.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.86e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 181700   |\n",
      "|    time_elapsed       | 1894     |\n",
      "|    total_timesteps    | 908500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.582   |\n",
      "|    explained_variance | 0.0428   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 181699   |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    value_loss         | 3.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.86e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 181800   |\n",
      "|    time_elapsed       | 1895     |\n",
      "|    total_timesteps    | 909000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0319  |\n",
      "|    explained_variance | -91.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 181799   |\n",
      "|    policy_loss        | 0.004    |\n",
      "|    value_loss         | 0.736    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.86e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 181900   |\n",
      "|    time_elapsed       | 1896     |\n",
      "|    total_timesteps    | 909500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0104  |\n",
      "|    explained_variance | 0.754    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 181899   |\n",
      "|    policy_loss        | -0.00259 |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.9e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 182000   |\n",
      "|    time_elapsed       | 1897     |\n",
      "|    total_timesteps    | 910000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00862 |\n",
      "|    explained_variance | 0.834    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 181999   |\n",
      "|    policy_loss        | 0.000279 |\n",
      "|    value_loss         | 0.0708   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.9e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 182100    |\n",
      "|    time_elapsed       | 1898      |\n",
      "|    total_timesteps    | 910500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00105  |\n",
      "|    explained_variance | 0.44      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 182099    |\n",
      "|    policy_loss        | -0.000102 |\n",
      "|    value_loss         | 1.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.9e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 182200    |\n",
      "|    time_elapsed       | 1899      |\n",
      "|    total_timesteps    | 911000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000254 |\n",
      "|    explained_variance | -10.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 182199    |\n",
      "|    policy_loss        | -4.68e-05 |\n",
      "|    value_loss         | 6.45      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.9e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 182300    |\n",
      "|    time_elapsed       | 1900      |\n",
      "|    total_timesteps    | 911500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0353   |\n",
      "|    explained_variance | -1.45e+05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 182299    |\n",
      "|    policy_loss        | -0.126    |\n",
      "|    value_loss         | 459       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.9e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 182400   |\n",
      "|    time_elapsed       | 1901     |\n",
      "|    total_timesteps    | 912000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0227  |\n",
      "|    explained_variance | 0.267    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 182399   |\n",
      "|    policy_loss        | 0.000164 |\n",
      "|    value_loss         | 0.0104   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.92e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 182500    |\n",
      "|    time_elapsed       | 1902      |\n",
      "|    total_timesteps    | 912500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000309 |\n",
      "|    explained_variance | -2.62     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 182499    |\n",
      "|    policy_loss        | 3.91e-05  |\n",
      "|    value_loss         | 8.47      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.92e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 182600   |\n",
      "|    time_elapsed       | 1903     |\n",
      "|    total_timesteps    | 913000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.013   |\n",
      "|    explained_variance | 0.66     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 182599   |\n",
      "|    policy_loss        | 0.00324  |\n",
      "|    value_loss         | 4.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.92e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 182700    |\n",
      "|    time_elapsed       | 1904      |\n",
      "|    total_timesteps    | 913500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000654 |\n",
      "|    explained_variance | -1.2e+03  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 182699    |\n",
      "|    policy_loss        | -0.000913 |\n",
      "|    value_loss         | 340       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.91e+03  |\n",
      "|    ep_rew_mean        | 1.92e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 182800    |\n",
      "|    time_elapsed       | 1905      |\n",
      "|    total_timesteps    | 914000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000484 |\n",
      "|    explained_variance | 0.692     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 182799    |\n",
      "|    policy_loss        | -2.96e-06 |\n",
      "|    value_loss         | 0.0911    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.92e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 182900   |\n",
      "|    time_elapsed       | 1906     |\n",
      "|    total_timesteps    | 914500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0146  |\n",
      "|    explained_variance | -4.67    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 182899   |\n",
      "|    policy_loss        | 0.000551 |\n",
      "|    value_loss         | 0.0888   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91e+03 |\n",
      "|    ep_rew_mean        | 1.92e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 183000   |\n",
      "|    time_elapsed       | 1907     |\n",
      "|    total_timesteps    | 915000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00283 |\n",
      "|    explained_variance | -0.761   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 182999   |\n",
      "|    policy_loss        | 0.000408 |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f7a3bf73650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_kwargs = {'net_arch':[256, 128, 128, 64]}\n",
    "model = A2C(\"MlpPolicy\", \n",
    "            env, \n",
    "            verbose=1,\n",
    "            seed=0,\n",
    "            policy_kwargs=policy_kwargs\n",
    "            )\n",
    "model.learn(total_timesteps=episodes*len(train_cl_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2Ys_CPu9JiK"
   },
   "source": [
    "# Testing Results\n",
    "\n",
    "Now that the model has been trained, let's test its performance on the testing data (out of sample data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "MVJUULjWRuYu",
    "outputId": "c687ee4c-4b24-4344-d384-702e5221dcd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-15974fe3-5ecf-421b-aa9f-c2e99478fe6d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>MA</th>\n",
       "      <th>Smoothing Line</th>\n",
       "      <th>MA.1</th>\n",
       "      <th>Smoothing Line.1</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume MA</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI-based MA</th>\n",
       "      <th>open_ovx</th>\n",
       "      <th>high_ovx</th>\n",
       "      <th>low_ovx</th>\n",
       "      <th>close_ovx</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-10</th>\n",
       "      <td>-0.766621</td>\n",
       "      <td>-0.781867</td>\n",
       "      <td>-0.772128</td>\n",
       "      <td>-0.805764</td>\n",
       "      <td>-0.557000</td>\n",
       "      <td>-0.549930</td>\n",
       "      <td>-0.471244</td>\n",
       "      <td>-0.459655</td>\n",
       "      <td>1.406739</td>\n",
       "      <td>2.431131</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.559446</td>\n",
       "      <td>-1.757536</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>-0.041668</td>\n",
       "      <td>0.066581</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>1.208730</td>\n",
       "      <td>-0.700735</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11</th>\n",
       "      <td>-0.801041</td>\n",
       "      <td>-0.815611</td>\n",
       "      <td>-0.778118</td>\n",
       "      <td>-0.805340</td>\n",
       "      <td>-0.560543</td>\n",
       "      <td>-0.553209</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>-0.465408</td>\n",
       "      <td>1.180781</td>\n",
       "      <td>2.326137</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.555212</td>\n",
       "      <td>-1.905771</td>\n",
       "      <td>-0.058059</td>\n",
       "      <td>-0.068138</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>1.034021</td>\n",
       "      <td>-0.938723</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12</th>\n",
       "      <td>-0.817613</td>\n",
       "      <td>-0.857370</td>\n",
       "      <td>-0.871809</td>\n",
       "      <td>-0.895611</td>\n",
       "      <td>-0.564819</td>\n",
       "      <td>-0.556685</td>\n",
       "      <td>-0.486411</td>\n",
       "      <td>-0.471740</td>\n",
       "      <td>1.912568</td>\n",
       "      <td>2.336176</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.942565</td>\n",
       "      <td>-2.014049</td>\n",
       "      <td>0.080010</td>\n",
       "      <td>0.161411</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.248979</td>\n",
       "      <td>0.813134</td>\n",
       "      <td>-1.135560</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-13</th>\n",
       "      <td>-0.901326</td>\n",
       "      <td>-0.840498</td>\n",
       "      <td>-0.863252</td>\n",
       "      <td>-0.847297</td>\n",
       "      <td>-0.568856</td>\n",
       "      <td>-0.560344</td>\n",
       "      <td>-0.495430</td>\n",
       "      <td>-0.478589</td>\n",
       "      <td>2.724882</td>\n",
       "      <td>2.400899</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.475328</td>\n",
       "      <td>-1.996319</td>\n",
       "      <td>0.100381</td>\n",
       "      <td>0.046419</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.166914</td>\n",
       "      <td>0.555723</td>\n",
       "      <td>-1.282645</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-14</th>\n",
       "      <td>-0.854158</td>\n",
       "      <td>-0.860322</td>\n",
       "      <td>-0.829883</td>\n",
       "      <td>-0.837549</td>\n",
       "      <td>-0.572753</td>\n",
       "      <td>-0.564205</td>\n",
       "      <td>-0.504142</td>\n",
       "      <td>-0.486233</td>\n",
       "      <td>0.829564</td>\n",
       "      <td>2.409222</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.383611</td>\n",
       "      <td>-1.999970</td>\n",
       "      <td>0.158099</td>\n",
       "      <td>0.095019</td>\n",
       "      <td>0.262676</td>\n",
       "      <td>0.239678</td>\n",
       "      <td>0.273038</td>\n",
       "      <td>-1.373548</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-07</th>\n",
       "      <td>1.989538</td>\n",
       "      <td>1.981769</td>\n",
       "      <td>1.969726</td>\n",
       "      <td>1.997738</td>\n",
       "      <td>0.836642</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>1.512815</td>\n",
       "      <td>1.505220</td>\n",
       "      <td>-0.502093</td>\n",
       "      <td>-0.753493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147665</td>\n",
       "      <td>0.698856</td>\n",
       "      <td>0.719996</td>\n",
       "      <td>0.467330</td>\n",
       "      <td>0.527836</td>\n",
       "      <td>0.403261</td>\n",
       "      <td>1.391423</td>\n",
       "      <td>0.149912</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>2.018859</td>\n",
       "      <td>2.100717</td>\n",
       "      <td>2.062134</td>\n",
       "      <td>2.112167</td>\n",
       "      <td>0.850380</td>\n",
       "      <td>0.823929</td>\n",
       "      <td>1.526957</td>\n",
       "      <td>1.512118</td>\n",
       "      <td>-0.540445</td>\n",
       "      <td>-0.777848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412969</td>\n",
       "      <td>0.814407</td>\n",
       "      <td>0.617010</td>\n",
       "      <td>0.384016</td>\n",
       "      <td>0.447671</td>\n",
       "      <td>0.320649</td>\n",
       "      <td>1.391423</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-09</th>\n",
       "      <td>2.131043</td>\n",
       "      <td>2.081314</td>\n",
       "      <td>2.125878</td>\n",
       "      <td>2.086739</td>\n",
       "      <td>0.863510</td>\n",
       "      <td>0.837379</td>\n",
       "      <td>1.542079</td>\n",
       "      <td>1.520712</td>\n",
       "      <td>-0.802194</td>\n",
       "      <td>-0.815076</td>\n",
       "      <td>...</td>\n",
       "      <td>1.286316</td>\n",
       "      <td>0.899154</td>\n",
       "      <td>0.504970</td>\n",
       "      <td>0.295061</td>\n",
       "      <td>0.364424</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>1.329625</td>\n",
       "      <td>-0.431998</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10</th>\n",
       "      <td>2.089823</td>\n",
       "      <td>2.082579</td>\n",
       "      <td>2.020636</td>\n",
       "      <td>2.051139</td>\n",
       "      <td>0.876237</td>\n",
       "      <td>0.850764</td>\n",
       "      <td>1.553332</td>\n",
       "      <td>1.530866</td>\n",
       "      <td>-0.301727</td>\n",
       "      <td>-0.806518</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105998</td>\n",
       "      <td>0.966328</td>\n",
       "      <td>0.616444</td>\n",
       "      <td>0.383582</td>\n",
       "      <td>0.353324</td>\n",
       "      <td>0.241319</td>\n",
       "      <td>1.208730</td>\n",
       "      <td>-0.700735</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-13</th>\n",
       "      <td>2.035856</td>\n",
       "      <td>2.061489</td>\n",
       "      <td>1.983844</td>\n",
       "      <td>2.058767</td>\n",
       "      <td>0.889235</td>\n",
       "      <td>0.864072</td>\n",
       "      <td>1.571344</td>\n",
       "      <td>1.543547</td>\n",
       "      <td>-0.408568</td>\n",
       "      <td>-0.779985</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127017</td>\n",
       "      <td>1.035149</td>\n",
       "      <td>1.004623</td>\n",
       "      <td>0.678220</td>\n",
       "      <td>0.585801</td>\n",
       "      <td>0.495174</td>\n",
       "      <td>0.555723</td>\n",
       "      <td>-1.282645</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.379204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows × 21 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15974fe3-5ecf-421b-aa9f-c2e99478fe6d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-15974fe3-5ecf-421b-aa9f-c2e99478fe6d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-15974fe3-5ecf-421b-aa9f-c2e99478fe6d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                open      high       low     close        MA  Smoothing Line  \\\n",
       "Date                                                                           \n",
       "2019-06-10 -0.766621 -0.781867 -0.772128 -0.805764 -0.557000       -0.549930   \n",
       "2019-06-11 -0.801041 -0.815611 -0.778118 -0.805340 -0.560543       -0.553209   \n",
       "2019-06-12 -0.817613 -0.857370 -0.871809 -0.895611 -0.564819       -0.556685   \n",
       "2019-06-13 -0.901326 -0.840498 -0.863252 -0.847297 -0.568856       -0.560344   \n",
       "2019-06-14 -0.854158 -0.860322 -0.829883 -0.837549 -0.572753       -0.564205   \n",
       "...              ...       ...       ...       ...       ...             ...   \n",
       "2022-06-07  1.989538  1.981769  1.969726  1.997738  0.836642        0.810659   \n",
       "2022-06-08  2.018859  2.100717  2.062134  2.112167  0.850380        0.823929   \n",
       "2022-06-09  2.131043  2.081314  2.125878  2.086739  0.863510        0.837379   \n",
       "2022-06-10  2.089823  2.082579  2.020636  2.051139  0.876237        0.850764   \n",
       "2022-06-13  2.035856  2.061489  1.983844  2.058767  0.889235        0.864072   \n",
       "\n",
       "                MA.1  Smoothing Line.1    Volume  Volume MA  ...       RSI  \\\n",
       "Date                                                         ...             \n",
       "2019-06-10 -0.471244         -0.459655  1.406739   2.431131  ... -1.559446   \n",
       "2019-06-11 -0.477260         -0.465408  1.180781   2.326137  ... -1.555212   \n",
       "2019-06-12 -0.486411         -0.471740  1.912568   2.336176  ... -1.942565   \n",
       "2019-06-13 -0.495430         -0.478589  2.724882   2.400899  ... -1.475328   \n",
       "2019-06-14 -0.504142         -0.486233  0.829564   2.409222  ... -1.383611   \n",
       "...              ...               ...       ...        ...  ...       ...   \n",
       "2022-06-07  1.512815          1.505220 -0.502093  -0.753493  ...  1.147665   \n",
       "2022-06-08  1.526957          1.512118 -0.540445  -0.777848  ...  1.412969   \n",
       "2022-06-09  1.542079          1.520712 -0.802194  -0.815076  ...  1.286316   \n",
       "2022-06-10  1.553332          1.530866 -0.301727  -0.806518  ...  1.105998   \n",
       "2022-06-13  1.571344          1.543547 -0.408568  -0.779985  ...  1.127017   \n",
       "\n",
       "            RSI-based MA  open_ovx  high_ovx   low_ovx  close_ovx   day_sin  \\\n",
       "Date                                                                          \n",
       "2019-06-10     -1.757536  0.009844 -0.041668  0.066581   0.033422  1.208730   \n",
       "2019-06-11     -1.905771 -0.058059 -0.068138  0.025882   0.009896  1.034021   \n",
       "2019-06-12     -2.014049  0.080010  0.161411  0.158462   0.248979  0.813134   \n",
       "2019-06-13     -1.996319  0.100381  0.046419  0.158462   0.166914  0.555723   \n",
       "2019-06-14     -1.999970  0.158099  0.095019  0.262676   0.239678  0.273038   \n",
       "...                  ...       ...       ...       ...        ...       ...   \n",
       "2022-06-07      0.698856  0.719996  0.467330  0.527836   0.403261  1.391423   \n",
       "2022-06-08      0.814407  0.617010  0.384016  0.447671   0.320649  1.391423   \n",
       "2022-06-09      0.899154  0.504970  0.295061  0.364424   0.293294  1.329625   \n",
       "2022-06-10      0.966328  0.616444  0.383582  0.353324   0.241319  1.208730   \n",
       "2022-06-13      1.035149  1.004623  0.678220  0.585801   0.495174  0.555723   \n",
       "\n",
       "             day_cos  month_sin  month_cos  \n",
       "Date                                        \n",
       "2019-06-10 -0.700735   0.020215  -1.379204  \n",
       "2019-06-11 -0.938723   0.020215  -1.379204  \n",
       "2019-06-12 -1.135560   0.020215  -1.379204  \n",
       "2019-06-13 -1.282645   0.020215  -1.379204  \n",
       "2019-06-14 -1.373548   0.020215  -1.379204  \n",
       "...              ...        ...        ...  \n",
       "2022-06-07  0.149912   0.020215  -1.379204  \n",
       "2022-06-08 -0.144257   0.020215  -1.379204  \n",
       "2022-06-09 -0.431998   0.020215  -1.379204  \n",
       "2022-06-10 -0.700735   0.020215  -1.379204  \n",
       "2022-06-13 -1.282645   0.020215  -1.379204  \n",
       "\n",
       "[732 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e3FIxPFO-ftc"
   },
   "outputs": [],
   "source": [
    "testing_env = FuturesEnv(df=test_cl_df,\n",
    "                 window_size=window_size,\n",
    "                 frame_bound=(window_size, len(test_cl_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkdrEsqOwswg",
    "outputId": "462b40e0-8b0c-49dc-c646-45ecb3d4ed85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, reward: 0, account_value: 1000000, action: 1, position: -1\n",
      "step: 1, reward: -0.05091026213379323, account_value: 1000000, action: 1, position: -1\n",
      "step: 2, reward: -0.19451114426483523, account_value: 1000000, action: 1, position: -1\n",
      "step: 3, reward: -0.2502566252767778, account_value: 1000000, action: 1, position: -1\n",
      "step: 4, reward: -0.3344001866922833, account_value: 1000000, action: 1, position: -1\n",
      "step: 5, reward: -0.31401870592553166, account_value: 1000000, action: 1, position: -1\n",
      "step: 6, reward: -0.2857654423578625, account_value: 1000000, action: 1, position: -1\n",
      "step: 7, reward: -0.25090189532880725, account_value: 1000000, action: 1, position: -1\n",
      "step: 8, reward: -0.30672489957018245, account_value: 1000000, action: 1, position: -1\n",
      "step: 9, reward: -0.2981476706445037, account_value: 1000000, action: 1, position: -1\n",
      "step: 10, reward: -0.2870105873892981, account_value: 1000000, action: 1, position: -1\n",
      "step: 11, reward: -0.24443038107836637, account_value: 1000000, action: 1, position: -1\n",
      "step: 12, reward: -0.16472516139276466, account_value: 1000000, action: 1, position: -1\n",
      "step: 13, reward: -0.12674787654969952, account_value: 1000000, action: 1, position: -1\n",
      "step: 14, reward: -0.41803151906742964, account_value: 1000000, action: 1, position: -1\n",
      "step: 15, reward: -0.320056500953833, account_value: 1000000, action: 1, position: -1\n",
      "step: 16, reward: -0.3768055381306036, account_value: 1000000, action: 1, position: -1\n",
      "step: 17, reward: -0.43534573163152185, account_value: 1000000, action: 1, position: -1\n",
      "step: 18, reward: -0.5630779008253268, account_value: 1000000, action: 1, position: -1\n",
      "step: 19, reward: -0.49216916572539415, account_value: 1000000, action: 1, position: -1\n",
      "step: 20, reward: -0.38755383586506315, account_value: 1000000, action: 1, position: -1\n",
      "step: 21, reward: -0.36306149703714974, account_value: 1000000, action: 1, position: -1\n",
      "step: 22, reward: -0.22938501564791688, account_value: 1000000, action: 1, position: -1\n",
      "step: 23, reward: -0.34561147130903486, account_value: 1000000, action: 1, position: -1\n",
      "step: 24, reward: -0.3892404245394832, account_value: 1000000, action: 1, position: -1\n",
      "step: 25, reward: -0.3699571297312285, account_value: 1000000, action: 1, position: -1\n",
      "step: 26, reward: -0.2907367471056558, account_value: 1000000, action: 1, position: -1\n",
      "step: 27, reward: -0.2913564260979156, account_value: 1000000, action: 1, position: -1\n",
      "step: 28, reward: -0.318851854824315, account_value: 1000000, action: 1, position: -1\n",
      "step: 29, reward: -0.33854529784378873, account_value: 1000000, action: 1, position: -1\n",
      "step: 30, reward: -0.4059516822276589, account_value: 1000000, action: 1, position: -1\n",
      "step: 31, reward: -0.43480917574441796, account_value: 1000000, action: 1, position: -1\n",
      "step: 32, reward: -0.36306149703714974, account_value: 1000000, action: 1, position: -1\n",
      "step: 33, reward: -0.31280675996507334, account_value: 1000000, action: 1, position: -1\n",
      "step: 34, reward: -0.25476479617151304, account_value: 1000000, action: 1, position: -1\n",
      "step: 35, reward: -0.3532105639203335, account_value: 1000000, action: 1, position: -1\n",
      "step: 36, reward: -0.2832704914619762, account_value: 1000000, action: 1, position: -1\n",
      "step: 37, reward: -0.28076930021349833, account_value: 1000000, action: 1, position: -1\n",
      "step: 38, reward: -0.2668997916028282, account_value: 1000000, action: 1, position: -1\n",
      "step: 39, reward: -0.17868954012340804, account_value: 1000000, action: 1, position: -1\n",
      "step: 40, reward: -0.20941415806861263, account_value: 1000000, action: 1, position: -1\n",
      "step: 41, reward: -0.3146241285455415, account_value: 1000000, action: 1, position: -1\n",
      "step: 42, reward: -0.35379272462457734, account_value: 1000000, action: 1, position: -1\n",
      "step: 43, reward: -0.36766386475051965, account_value: 1000000, action: 1, position: -1\n",
      "step: 44, reward: 0.25232426246475864, account_value: 1000000, action: 1, position: -1\n",
      "step: 45, reward: -0.06964268098020328, account_value: 1000000, action: 1, position: -1\n",
      "step: 46, reward: -0.1654280311273252, account_value: 1000000, action: 1, position: -1\n",
      "step: 47, reward: -0.1548327572338057, account_value: 1000000, action: 1, position: -1\n",
      "step: 48, reward: -0.16190873175413742, account_value: 1000000, action: 1, position: -1\n",
      "step: 49, reward: -0.12235625068401242, account_value: 1000000, action: 1, position: -1\n",
      "step: 50, reward: -0.21678319663956977, account_value: 1000000, action: 1, position: -1\n",
      "step: 51, reward: -0.26880245354606797, account_value: 1000000, action: 1, position: -1\n",
      "step: 52, reward: -0.2738585911240764, account_value: 1000000, action: 1, position: -1\n",
      "step: 53, reward: -0.3048931051211098, account_value: 1000000, action: 1, position: -1\n",
      "step: 54, reward: -0.4114606132301783, account_value: 1000000, action: 1, position: -1\n",
      "step: 55, reward: -0.43588199978078634, account_value: 1000000, action: 1, position: -1\n",
      "step: 56, reward: -0.48708847047524645, account_value: 1000000, action: 1, position: -1\n",
      "step: 57, reward: -0.4967198250648966, account_value: 1000000, action: 1, position: -1\n",
      "step: 58, reward: -0.4783916015282504, account_value: 1000000, action: 1, position: -1\n",
      "step: 59, reward: -0.48146972861260817, account_value: 1000000, action: 1, position: -1\n",
      "step: 60, reward: -0.48759770318110457, account_value: 1000000, action: 1, position: -1\n",
      "step: 61, reward: -0.4896320447798777, account_value: 1000000, action: 1, position: -1\n",
      "step: 62, reward: -0.4396278460130947, account_value: 1000000, action: 1, position: -1\n",
      "step: 63, reward: -0.37623662537279445, account_value: 1000000, action: 1, position: -1\n",
      "step: 64, reward: -0.437489080883504, account_value: 1000000, action: 1, position: -1\n",
      "step: 65, reward: -0.4783916015282504, account_value: 1000000, action: 1, position: -1\n",
      "step: 66, reward: -0.44972497609610756, account_value: 1000000, action: 1, position: -1\n",
      "step: 67, reward: -0.4191224845219862, account_value: 1000000, action: 1, position: -1\n",
      "step: 68, reward: -0.42238825777899286, account_value: 1000000, action: 1, position: -1\n",
      "step: 69, reward: -0.44176204658718116, account_value: 1000000, action: 1, position: -1\n",
      "step: 70, reward: -0.3886785443200168, account_value: 1000000, action: 1, position: -1\n",
      "step: 71, reward: -0.30121941897306226, account_value: 1000000, action: 1, position: -1\n",
      "step: 72, reward: -0.28514228796431146, account_value: 1000000, action: 1, position: -1\n",
      "step: 73, reward: -0.2579725204511042, account_value: 1000000, action: 1, position: -1\n",
      "step: 74, reward: -0.32725406126766554, account_value: 1000000, action: 1, position: -1\n",
      "step: 75, reward: -0.35553717602882, account_value: 1000000, action: 1, position: -1\n",
      "step: 76, reward: -0.40539911628463365, account_value: 1000000, action: 1, position: -1\n",
      "step: 77, reward: -0.2870105873892981, account_value: 1000000, action: 1, position: -1\n",
      "step: 78, reward: -0.26562933614728607, account_value: 1000000, action: 1, position: -1\n",
      "step: 79, reward: -0.22077990122484795, account_value: 1000000, action: 1, position: -1\n",
      "step: 80, reward: -0.27763398795875016, account_value: 1000000, action: 1, position: -1\n",
      "step: 81, reward: -0.22608411350743227, account_value: 1000000, action: 1, position: -1\n",
      "step: 82, reward: -0.22011489209007867, account_value: 1000000, action: 1, position: -1\n",
      "step: 83, reward: -0.24507942038114924, account_value: 1000000, action: 1, position: -1\n",
      "step: 84, reward: -0.24896483470742667, account_value: 1000000, action: 1, position: -1\n",
      "step: 85, reward: -0.2280659620180623, account_value: 1000000, action: 1, position: -1\n",
      "step: 86, reward: -0.25090189532880725, account_value: 1000000, action: 1, position: -1\n",
      "step: 87, reward: -0.18766292252417036, account_value: 1000000, action: 1, position: -1\n",
      "step: 88, reward: -0.22674516618741952, account_value: 1000000, action: 1, position: -1\n",
      "step: 89, reward: -0.33854529784378873, account_value: 1000000, action: 1, position: -1\n",
      "step: 90, reward: -0.23529931989458447, account_value: 1000000, action: 1, position: -1\n",
      "step: 91, reward: -0.12674787654969952, account_value: 1000000, action: 1, position: -1\n",
      "step: 92, reward: -0.1842211441788213, account_value: 1000000, action: 1, position: -1\n",
      "step: 93, reward: -0.16753368102823543, account_value: 1000000, action: 1, position: -1\n",
      "step: 94, reward: -0.13908709188046967, account_value: 1000000, action: 1, position: -1\n",
      "step: 95, reward: -0.16049753673534722, account_value: 1000000, action: 1, position: -1\n",
      "step: 96, reward: -0.3018326379831678, account_value: 1000000, action: 1, position: -1\n",
      "step: 97, reward: -0.29321316238841366, account_value: 1000000, action: 1, position: -1\n",
      "step: 98, reward: -0.13764329724334265, account_value: 1000000, action: 1, position: -1\n",
      "step: 99, reward: -0.13764329724334265, account_value: 1000000, action: 1, position: -1\n",
      "step: 100, reward: -0.08041003793179743, account_value: 1000000, action: 1, position: -1\n",
      "step: 101, reward: -0.09408558112330621, account_value: 1000000, action: 1, position: -1\n",
      "step: 102, reward: -0.07734546221029756, account_value: 1000000, action: 1, position: -1\n",
      "step: 103, reward: -0.11351471285587583, account_value: 1000000, action: 1, position: -1\n",
      "step: 104, reward: -0.0819388111136251, account_value: 1000000, action: 1, position: -1\n",
      "step: 105, reward: -0.011539488662888649, account_value: 1000000, action: 1, position: -1\n",
      "step: 106, reward: 0.0, account_value: 1000000, action: 1, position: -1\n",
      "step: 107, reward: 0.05626937460468108, account_value: 1000000, action: 1, position: -1\n",
      "step: 108, reward: 0.05451689255123553, account_value: 1000000, action: 1, position: -1\n",
      "step: 109, reward: 0.08383307449874111, account_value: 1000000, action: 1, position: -1\n",
      "step: 110, reward: 0.019251664384973867, account_value: 1000000, action: 1, position: -1\n",
      "step: 111, reward: 0.026035727712222824, account_value: 1000000, action: 1, position: -1\n",
      "step: 112, reward: 0.07754226923635323, account_value: 1000000, action: 1, position: -1\n",
      "step: 113, reward: 0.129956551955705, account_value: 1000000, action: 1, position: -1\n",
      "step: 114, reward: 0.1337399968876861, account_value: 1000000, action: 1, position: -1\n",
      "step: 115, reward: 0.129956551955705, account_value: 1000000, action: 1, position: -1\n",
      "step: 116, reward: 0.07307294330197932, account_value: 1000000, action: 1, position: -1\n",
      "step: 117, reward: 0.08383307449874111, account_value: 1000000, action: 1, position: -1\n",
      "step: 118, reward: 0.2684581760034979, account_value: 1000000, action: 1, position: -1\n",
      "step: 119, reward: 0.292602306788958, account_value: 1000000, action: 1, position: -1\n",
      "step: 120, reward: 0.23120947800121844, account_value: 1000000, action: 1, position: -1\n",
      "step: 121, reward: -0.04854384295883583, account_value: 1000000, action: 1, position: -1\n",
      "step: 122, reward: -0.05248476955446089, account_value: 1000000, action: 1, position: -1\n",
      "step: 123, reward: -0.09257527921743434, account_value: 1000000, action: 1, position: -1\n",
      "step: 124, reward: -0.16261358316367272, account_value: 1000000, action: 1, position: -1\n",
      "step: 125, reward: -0.15198828821245725, account_value: 1000000, action: 1, position: -1\n",
      "step: 126, reward: -0.18145916697666636, account_value: 1000000, action: 1, position: -1\n",
      "step: 127, reward: -0.13039288939314206, account_value: 1000000, action: 1, position: -1\n",
      "step: 128, reward: -0.12674787654969952, account_value: 1000000, action: 1, position: -1\n",
      "step: 129, reward: -0.2528352109993655, account_value: 1000000, action: 1, position: -1\n",
      "step: 130, reward: -0.3242613710049571, account_value: 1000000, action: 1, position: -1\n",
      "step: 131, reward: -0.4048462448436713, account_value: 1000000, action: 1, position: -1\n",
      "step: 132, reward: -0.4612904247930181, account_value: 1000000, action: 1, position: -1\n",
      "step: 133, reward: -0.4433597132283705, account_value: 1000000, action: 1, position: -1\n",
      "step: 134, reward: -0.45130998118583515, account_value: 1000000, action: 1, position: -1\n",
      "step: 135, reward: -0.5122376806063772, account_value: 1000000, action: 1, position: -1\n",
      "step: 136, reward: -0.5406397944842186, account_value: 1000000, action: 1, position: -1\n",
      "step: 137, reward: -0.6083044369839624, account_value: 1000000, action: 1, position: -1\n",
      "step: 138, reward: -0.6306144531834809, account_value: 1000000, action: 1, position: -1\n",
      "step: 139, reward: -0.5790015148285811, account_value: 1000000, action: 1, position: -1\n",
      "step: 140, reward: -0.5696654196690136, account_value: 1000000, action: 1, position: -1\n",
      "step: 141, reward: -0.5987837454828596, account_value: 1000000, action: 1, position: -1\n",
      "step: 142, reward: -0.6323779363936607, account_value: 1000000, action: 1, position: -1\n",
      "step: 143, reward: -0.6159458206541907, account_value: 1000000, action: 1, position: -1\n",
      "step: 144, reward: -0.5592940285619882, account_value: 1000000, action: 1, position: -1\n",
      "step: 145, reward: -0.5473762931765258, account_value: 1000000, action: 1, position: -1\n",
      "step: 146, reward: -0.5166981265924624, account_value: 1000000, action: 1, position: -1\n",
      "step: 147, reward: -0.4428274412463509, account_value: 1000000, action: 1, position: -1\n",
      "step: 148, reward: -0.4218447023428571, account_value: 1000000, action: 1, position: -1\n",
      "step: 149, reward: -0.44866690862394604, account_value: 1000000, action: 1, position: -1\n",
      "step: 150, reward: -0.5468966167680364, account_value: 1000000, action: 1, position: -1\n",
      "step: 151, reward: -0.6177353391035708, account_value: 1000000, action: 1, position: -1\n",
      "step: 152, reward: -0.6687103602727614, account_value: 1000000, action: 1, position: -1\n",
      "step: 153, reward: -0.7360526805879832, account_value: 1000000, action: 1, position: -1\n",
      "step: 154, reward: -0.8245441953371123, account_value: 1000000, action: 1, position: -1\n",
      "step: 155, reward: -0.7494638470743046, account_value: 1000000, action: 1, position: -1\n",
      "step: 156, reward: -0.732472352503822, account_value: 1000000, action: 1, position: -1\n",
      "step: 157, reward: -0.7482877171042774, account_value: 1000000, action: 1, position: -1\n",
      "step: 158, reward: -0.782225373052116, account_value: 1000000, action: 1, position: -1\n",
      "step: 159, reward: -0.9436494454050088, account_value: 1000000, action: 1, position: -1\n",
      "step: 160, reward: -1.1451857384271782, account_value: 1000000, action: 1, position: -1\n",
      "step: 161, reward: -1.1809386301554181, account_value: 1000000, action: 1, position: -1\n",
      "step: 162, reward: -1.2179129072236978, account_value: 1000000, action: 1, position: -1\n",
      "step: 163, reward: -1.212255863699463, account_value: 1000000, action: 1, position: -1\n",
      "step: 164, reward: -1.3237089464217502, account_value: 1000000, action: 1, position: -1\n",
      "step: 165, reward: -1.4503703216082235, account_value: 1000000, action: 1, position: -1\n",
      "step: 166, reward: -1.3463963467600173, account_value: 1000000, action: 1, position: -1\n",
      "step: 167, reward: -1.414752885269027, account_value: 1000000, action: 1, position: -1\n",
      "step: 168, reward: -1.386560360656612, account_value: 1000000, action: 1, position: -1\n",
      "step: 169, reward: -1.3765649394262132, account_value: 1000000, action: 1, position: -1\n",
      "step: 170, reward: -1.4153570249979566, account_value: 1000000, action: 1, position: -1\n",
      "step: 171, reward: -1.4370635063904424, account_value: 1000000, action: 1, position: -1\n",
      "step: 172, reward: -1.4646528630674944, account_value: 1000000, action: 1, position: -1\n",
      "step: 173, reward: -1.4571510084024453, account_value: 1000000, action: 1, position: -1\n",
      "step: 174, reward: -1.460427968919423, account_value: 1000000, action: 1, position: -1\n",
      "step: 175, reward: -1.3590418866792555, account_value: 1000000, action: 1, position: -1\n",
      "step: 176, reward: -1.2925596353847433, account_value: 1000000, action: 1, position: -1\n",
      "step: 177, reward: -1.3427228422991726, account_value: 1000000, action: 1, position: -1\n",
      "step: 178, reward: -1.3944031515623176, account_value: 1000000, action: 1, position: -1\n",
      "step: 179, reward: -1.3639285070667855, account_value: 1000000, action: 1, position: -1\n",
      "step: 180, reward: -1.4121307206131444, account_value: 1000000, action: 1, position: -1\n",
      "step: 181, reward: -1.419174790777819, account_value: 1000000, action: 1, position: -1\n",
      "step: 182, reward: -1.4642695185241452, account_value: 1000000, action: 1, position: -1\n",
      "step: 183, reward: -1.468859982554736, account_value: 1000000, action: 1, position: -1\n",
      "step: 184, reward: -1.468859982554736, account_value: 1000000, action: 1, position: -1\n",
      "step: 185, reward: -1.4989360875681328, account_value: 1000000, action: 1, position: -1\n",
      "step: 186, reward: -2.209500409983195, account_value: 1000000, action: 1, position: -1\n",
      "step: 187, reward: -1.6158908581171165, account_value: 1000000, action: 1, position: -1\n",
      "step: 188, reward: -1.578804445903874, account_value: 1000000, action: 1, position: -1\n",
      "step: 189, reward: -1.5311867279767641, account_value: 1000000, action: 1, position: -1\n",
      "step: 190, reward: -1.523266234974284, account_value: 1000000, action: 1, position: -1\n",
      "step: 191, reward: -1.5957561913911407, account_value: 1000000, action: 1, position: -1\n",
      "step: 192, reward: -1.603124879963271, account_value: 1000000, action: 1, position: -1\n",
      "step: 193, reward: -1.556678268145806, account_value: 1000000, action: 1, position: -1\n",
      "step: 194, reward: -1.4883248987181643, account_value: 1000000, action: 1, position: -1\n",
      "step: 195, reward: -1.4705759883570189, account_value: 1000000, action: 1, position: -1\n",
      "step: 196, reward: -1.458887207430179, account_value: 1000000, action: 1, position: -1\n",
      "step: 197, reward: -1.375098890381402, account_value: 1000000, action: 1, position: -1\n",
      "step: 198, reward: -1.3869746761923414, account_value: 1000000, action: 1, position: -1\n",
      "step: 199, reward: -1.396046456694328, account_value: 1000000, action: 1, position: -1\n",
      "step: 200, reward: -1.3713191510205995, account_value: 1000000, action: 1, position: -1\n",
      "step: 201, reward: -1.3838631174186016, account_value: 1000000, action: 1, position: -1\n",
      "step: 202, reward: -1.3491964199624764, account_value: 1000000, action: 1, position: -1\n",
      "step: 203, reward: -1.359680627778376, account_value: 1000000, action: 1, position: -1\n",
      "step: 204, reward: -1.310158419364943, account_value: 1000000, action: 1, position: -1\n",
      "step: 205, reward: -1.2653328731247002, account_value: 1000000, action: 1, position: -1\n",
      "step: 206, reward: -1.2142271628243417, account_value: 1000000, action: 1, position: -1\n",
      "step: 207, reward: -1.2065666358795128, account_value: 1059863.1427702513, action: 2, position: 0\n",
      "step: 208, reward: 0, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 209, reward: -0.011149431604491073, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 210, reward: 0.006169306659047773, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 211, reward: 0.01738178970061344, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 212, reward: -0.005688828769548087, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 213, reward: -0.05294708242328037, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 214, reward: -0.05158865927957625, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 215, reward: -0.08949358424026482, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 216, reward: -0.10312149127112473, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 217, reward: -0.10655768578764568, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 218, reward: -0.16990673419957408, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 219, reward: -0.12918545620059743, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 220, reward: -0.15143668922603115, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 221, reward: -0.17143590863322178, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 222, reward: -0.0763271646134217, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 223, reward: -0.0741032357204883, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 224, reward: -0.09827367274978115, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 225, reward: -0.13477577973298518, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 226, reward: -0.12245977097728483, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 227, reward: -0.15474224013745932, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 228, reward: -0.1785003868002543, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 229, reward: -0.2066339341324598, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 230, reward: -0.19528536025007617, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 231, reward: -0.12391803338247019, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 232, reward: -0.14485818790761418, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 233, reward: -0.1380266245364996, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 234, reward: -0.17450129055350636, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 235, reward: -0.16138630366569545, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 236, reward: -0.17819219558049007, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 237, reward: -0.2041008754279922, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 238, reward: -0.20315263019773977, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 239, reward: -0.21203808319445352, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 240, reward: -0.17204823375281456, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 241, reward: -0.20094354851151192, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 242, reward: -0.18685765702185408, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 243, reward: -0.192780849883729, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 244, reward: -0.22164664703393155, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 245, reward: -0.2072682026402671, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 246, reward: -0.2072682026402671, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 247, reward: -0.21267578975849846, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 248, reward: -0.24509102975517155, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 249, reward: -0.24443232001410756, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 250, reward: -0.2174715958405685, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 251, reward: -0.2245473121871609, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 252, reward: -0.23460339000353367, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 253, reward: -0.2165105928786993, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 254, reward: -0.22390199241676548, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 255, reward: -0.1812783903214176, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 256, reward: -0.19215570115569364, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 257, reward: -0.21555051255693364, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 258, reward: -0.23786897755139405, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 259, reward: -0.25402634198627905, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 260, reward: -0.246079908641723, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 261, reward: -0.22229051255724577, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 262, reward: -0.2457501736807755, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 263, reward: -0.23492946929322528, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 264, reward: -0.27011119247490517, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 265, reward: -0.25568982690274233, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 266, reward: -0.24806060490307683, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 267, reward: -0.2775707790071432, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 268, reward: -0.28542939569896414, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 269, reward: -0.28508642944610507, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 270, reward: -0.27519123283255614, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 271, reward: -0.2590251213687623, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 272, reward: -0.26842356439564513, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 273, reward: -0.2933502597481072, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 274, reward: -0.29473422865804005, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 275, reward: -0.282688953562928, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 276, reward: -0.28029721182562506, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 277, reward: -0.26808638028145043, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 278, reward: -0.27315611882642715, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 279, reward: -0.23167345128452235, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 280, reward: -0.22713276372439323, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 281, reward: -0.17665266260113457, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 282, reward: -0.12508617634534033, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 283, reward: -0.10340739026605161, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 284, reward: -0.10426557800765218, account_value: 1059863.1427702513, action: 2, position: 1\n",
      "step: 285, reward: -0.1022642843888356, account_value: 1068171.5112719717, action: 1, position: 0\n",
      "step: 286, reward: 0, account_value: 1068171.5112719717, action: 1, position: -1\n",
      "step: 287, reward: 0.056894742543970284, account_value: 1068171.5112719717, action: 0, position: -1\n",
      "step: 288, reward: 0.08244222868749784, account_value: 1062129.2540933844, action: 2, position: 0\n",
      "step: 289, reward: 0, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 290, reward: 0.05591489361807349, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 291, reward: 0.047939975395575964, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 292, reward: 0.04392853903996659, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 293, reward: 0.03210968366856414, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 294, reward: 0.0339851303413009, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 295, reward: 0.022995107454628877, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 296, reward: 0.06352356921478602, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 297, reward: 0.03492153633708952, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 298, reward: 0.0806578854281273, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 299, reward: 0.1292317503816592, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 300, reward: 0.06564366503417798, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 301, reward: 0.020782534513862687, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 302, reward: 0.04330996423345226, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 303, reward: 0.004191203669113934, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 304, reward: 0.022995107454628877, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 305, reward: 0.05926984532238655, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 306, reward: 0.03554532021314202, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 307, reward: 0.009005480457042298, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 308, reward: 0.011563649141956567, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 309, reward: 0.006440750757337735, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 310, reward: 0.008364914440827138, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 311, reward: -0.012352904215652548, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 312, reward: 0.04083183154403956, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 313, reward: 0.021731379569358895, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 314, reward: 0.04639901900402815, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 315, reward: 0.05499794993901192, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 316, reward: 0.11953190722104584, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 317, reward: 0.15390885997773004, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 318, reward: 0.16437947083850085, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 319, reward: 0.13602248909547673, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 320, reward: 0.11176149988276897, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 321, reward: 0.06775927555487328, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 322, reward: 0.07856941643737797, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 323, reward: 0.12667328728175747, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 324, reward: 0.032735223452012525, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 325, reward: -0.0012931431482862325, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 326, reward: -0.004208843816692355, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 327, reward: 0.006440750757337735, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 328, reward: 0.037725504654638066, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 329, reward: -0.0006463625467576576, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 330, reward: -0.0035601752570119365, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 331, reward: -0.022544531567335286, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 332, reward: -0.018916246678366003, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 333, reward: -0.0361853162457812, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 334, reward: -0.05785728701815963, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 335, reward: -0.12328078330382844, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 336, reward: -0.15295392277009479, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 337, reward: -0.13912057573089356, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 338, reward: -0.11020983514342621, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 339, reward: -0.13689525263232555, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 340, reward: -0.1503220838668707, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 341, reward: -0.17387726690446517, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 342, reward: -0.15483805751736898, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 343, reward: -0.14882127997864697, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 344, reward: -0.14582641258377668, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 345, reward: -0.19407025521225332, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 346, reward: -0.18586624713031158, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 347, reward: -0.2023421261741973, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 348, reward: -0.22757638097476307, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 349, reward: -0.23572227318300068, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 350, reward: -0.2656094555775269, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 351, reward: -0.29554875380626333, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 352, reward: -0.24187553592867425, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 353, reward: -0.20352942751101, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 354, reward: -0.24806689585970548, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 355, reward: -0.2526317138852404, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 356, reward: -0.22757638097476307, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 357, reward: -0.24311074507678648, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 358, reward: -0.2597276758275055, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 359, reward: -0.2647670802780806, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 360, reward: -0.22757638097476307, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 361, reward: -0.3259644717376865, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 362, reward: -0.3577963540708085, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 363, reward: -0.3670804425744839, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 364, reward: -0.4350997895037964, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 365, reward: -0.43559910575106114, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 366, reward: -0.484732974358481, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 367, reward: -0.46911773193200856, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 368, reward: -0.5037989370788055, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 369, reward: -0.44412585108892083, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 370, reward: -0.48999271504205333, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 371, reward: -0.48054501016162415, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 372, reward: -0.43659848681875046, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 373, reward: -0.46191323366278436, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 374, reward: -0.45374258101791115, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 375, reward: -0.4660237319598651, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 376, reward: -0.440104206834243, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 377, reward: -0.43310501395350465, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 378, reward: -0.502730126303436, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 379, reward: -0.5695416371896636, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 380, reward: -0.6241089851839856, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 381, reward: -0.6572156843522193, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 382, reward: -0.6966299336113979, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 383, reward: -0.7720236373495595, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 384, reward: -0.7996704874686816, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 385, reward: -0.8229402235946186, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 386, reward: -0.7910820673792588, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 387, reward: -0.8828184378347425, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 388, reward: -1.0225914565859857, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 389, reward: -0.9692449531432727, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 390, reward: -0.8665483270366447, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 391, reward: -1.0742044574323495, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 392, reward: -1.0713708954494867, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 393, reward: -1.2294215642586974, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 394, reward: -1.2642667757600954, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 395, reward: -1.0554639605714398, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 396, reward: -0.9786568775379679, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 397, reward: -0.9049320715892113, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 398, reward: -1.0352471208849685, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 399, reward: -1.2991849477644584, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 400, reward: -1.6107455510875452, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 401, reward: -1.4552645090366398, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 402, reward: -1.3207365049312703, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 403, reward: -1.3741827105946538, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 404, reward: -1.5994866848739615, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 405, reward: -1.5359721765890602, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 406, reward: -1.4212355283042906, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 407, reward: -1.3948222451848538, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 408, reward: -0.929999307546754, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 409, reward: -1.0499096188485828, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 410, reward: -0.7574475241492161, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 411, reward: -1.0261910468152717, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 412, reward: -0.8141504959085717, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 413, reward: -1.0074361232608577, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 414, reward: -1.0610493253994007, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 415, reward: -0.9709496363569969, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 416, reward: -0.8588927216014582, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 417, reward: -1.0508332027019585, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 418, reward: -0.8207355380076575, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 419, reward: -0.8719423377451714, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 420, reward: -0.906530487838225, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 421, reward: -0.8930247005870137, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 422, reward: -0.8711699811498493, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 423, reward: -0.9009471731983023, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 424, reward: -0.9398739902270499, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 425, reward: -1.2217185426315964, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 426, reward: -1.256291695794961, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 427, reward: -1.2261130009283543, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 428, reward: -1.2528931787082445, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 429, reward: -1.1704383368880258, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 430, reward: -1.0416355264254011, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 431, reward: -1.048986887215306, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 432, reward: -1.1167131283909482, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 433, reward: -1.0942674420613647, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 434, reward: -1.1989592238314568, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 435, reward: -1.3027447733899906, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 436, reward: -1.449741454789741, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 437, reward: -1.2700024545207904, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 438, reward: -1.3805869229933798, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 439, reward: -1.5480525580414592, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 440, reward: -1.5389786180549205, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 441, reward: -1.4092631417127732, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 442, reward: -1.43470848511567, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 443, reward: -1.4374249967092494, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 444, reward: -1.4876280264738668, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 445, reward: -1.6091293598591851, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 446, reward: -1.2980011497438528, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 447, reward: -1.5005827166336252, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 448, reward: -1.640292765746838, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 449, reward: -1.519596398007203, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 450, reward: -1.2438865308344778, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 451, reward: -1.0971667265066756, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 452, reward: -1.2700024545207904, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 453, reward: -1.6042963997639927, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 454, reward: -1.6075157764906782, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 455, reward: -1.6303463738917137, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 456, reward: -1.7419138473574092, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 457, reward: -1.6486576722463129, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 458, reward: -2.1962847419058704, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 459, reward: -2.1904916340454306, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 460, reward: -2.4569897940953687, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 461, reward: -2.3198074259672326, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 462, reward: -2.6338678685523687, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 463, reward: -2.594169404805776, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 464, reward: -2.7481479845727748, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 465, reward: -3.1232111258545574, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 466, reward: -3.101429909145671, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 467, reward: -5.313775674575716, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 468, reward: -5.5330092836736045, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 469, reward: -3.223496419293988, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 470, reward: -3.450219111049744, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 471, reward: -3.5977824214313827, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 472, reward: -3.9813030303065333, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 473, reward: -3.646123658900303, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 474, reward: -3.405212467000744, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 475, reward: -2.8571792493006174, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 476, reward: -3.882475448977505, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 477, reward: -3.778309479369193, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 478, reward: -3.252120559787934, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 479, reward: -2.3480679587861144, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 480, reward: -2.3720202816083393, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 481, reward: -6.058165193291873, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 482, reward: -3.8364982319326573, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 483, reward: -2.604941663879862, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 484, reward: -2.829439943518927, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 485, reward: -2.341328507822525, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 486, reward: -3.586053622891574, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 487, reward: -3.9066417737813173, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 488, reward: -3.771582755012893, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 489, reward: -1.6537104099039852, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 490, reward: -1.8086384438297807, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 491, reward: -2.7532051718436295, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 492, reward: -4.447490030413076, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 493, reward: -5.030018892016507, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 494, reward: -4.447490030413076, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 495, reward: -3.9066417737813173, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 496, reward: -5.5728141742116275, account_value: 1062129.2540933844, action: 2, position: 1\n",
      "step: 497, reward: -3.134115998702488, account_value: 1134681.2640816274, action: 1, position: 0\n",
      "step: 498, reward: 0, account_value: 1134681.2640816274, action: 1, position: -1\n",
      "step: 499, reward: -0.505059491679426, account_value: 1141065.5358174932, action: 2, position: 0\n",
      "step: 500, reward: 0, account_value: 1141065.5358174932, action: 2, position: 1\n",
      "step: 501, reward: 0.8785437270086884, account_value: 1141065.5358174932, action: 2, position: 1\n",
      "step: 502, reward: 0.6197429767119629, account_value: 1137514.4329978689, action: 1, position: 0\n",
      "step: 503, reward: 0, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 504, reward: -0.3721550953764456, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 505, reward: 0.0025079087603616258, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 506, reward: 0.278342302469491, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 507, reward: 0.22675769113703503, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 508, reward: 0.04090144075098197, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 509, reward: -0.2215197471497346, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 510, reward: -0.3529820204288449, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 511, reward: -0.570393692204733, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 512, reward: -0.7872195160919001, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 513, reward: -0.9313474811213907, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 514, reward: -0.5075753744079833, account_value: 1137514.4329978689, action: 1, position: -1\n",
      "step: 515, reward: -0.17004039042406768, account_value: 1137514.4329978689, action: 0, position: -1\n",
      "step: 516, reward: 0.020241618968425346, account_value: 1137324.5661804453, action: 2, position: 0\n",
      "step: 517, reward: 0, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 518, reward: -0.3174968271088371, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 519, reward: -0.46027595376796737, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 520, reward: -0.2517627335144372, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 521, reward: -0.275909501568464, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 522, reward: -0.7542486967009497, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 523, reward: -0.4867466358370629, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 524, reward: -0.4901052876062828, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 525, reward: -0.16061550758595086, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 526, reward: -0.6424415674241145, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 527, reward: -0.9793232334324058, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 528, reward: -0.9848256497302669, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 529, reward: -2.665328857529521, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 530, reward: -2.665328857529521, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 531, reward: -2.372686059011634, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 532, reward: -0.8222284821657758, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 533, reward: -1.001516924434578, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 534, reward: -4.740361441737005, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 535, reward: -1.5522332652523274, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 536, reward: -1.0443750343197846, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 537, reward: -0.4233409722285834, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 538, reward: -0.47500515304119284, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 539, reward: -0.6403969312065757, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 540, reward: -0.5651058546563988, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 541, reward: -0.2964248867301044, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 542, reward: 0.09717915980509474, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 543, reward: 0.316289914575454, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 544, reward: 0.061002735509182004, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 545, reward: 0.2168799656243617, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 546, reward: 0.37746561535997236, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 547, reward: 0.53045275614735, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 548, reward: 0.5448975913430301, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 549, reward: 0.5207056295577338, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 550, reward: 0.6219240322304448, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 551, reward: 0.7238750552084467, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 552, reward: 0.6631106051832122, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 553, reward: 0.739736425974921, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 554, reward: 0.8317543561216114, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 555, reward: 0.7456201733624185, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 556, reward: 0.8617982888610364, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 557, reward: 0.8617982888610364, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 558, reward: 0.9364184082515167, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 559, reward: 0.7611429940138564, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 560, reward: 0.7754800036488206, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 561, reward: 0.8451204274826715, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 562, reward: 0.8747713180912935, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 563, reward: 0.5708497518172782, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 564, reward: 0.29810101411492496, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 565, reward: 0.6174882608211271, account_value: 1137324.5661804453, action: 2, position: 1\n",
      "step: 566, reward: 0.6882754645546383, account_value: 1171761.6601906368, action: 1, position: 0\n",
      "step: 567, reward: 0, account_value: 1171761.6601906368, action: 1, position: -1\n",
      "step: 568, reward: 0.26994633915342636, account_value: 1178668.9132941382, action: 2, position: 0\n",
      "step: 569, reward: 0, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 570, reward: 0.08977035260560662, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 571, reward: 0.07925944444316216, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 572, reward: 0.09329868378732761, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 573, reward: 0.5684326482102691, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 574, reward: 0.4174706300486899, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 575, reward: 0.9323655999942403, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 576, reward: 0.7328165015564678, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 577, reward: 0.4029134187892423, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 578, reward: 0.42073454716418446, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 579, reward: -1.389310417802096, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 580, reward: -0.42486625553424223, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 581, reward: -0.3294424974922639, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 582, reward: -0.4788205191036676, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 583, reward: -0.43808437127237493, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 584, reward: -1.2085968311073394, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 585, reward: -3.7352381482199903, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 586, reward: 4.666743429671228, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 587, reward: -1.9449335704493058, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 588, reward: -2.738759934335713, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 589, reward: -2.2496753339340234, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 590, reward: -1.7985745244472433, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 591, reward: -1.8937298927944328, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 592, reward: -4.3324655065578845, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 593, reward: -1.7921119986006087, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 594, reward: -0.9337909873340375, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 595, reward: -2.090070082881164, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 596, reward: 2.9501416015516493, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 597, reward: 1.8147683138044541, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 598, reward: 1.0387077982506043, account_value: 1178668.9132941382, action: 1, position: -1\n",
      "step: 599, reward: 0.9215183655318141, account_value: 1178668.9132941382, action: 0, position: -1\n",
      "step: 600, reward: 0.7761764353388608, account_value: 1191033.1421591244, action: 2, position: 0\n",
      "step: 601, reward: 0, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 602, reward: -0.47370573015673023, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 603, reward: -0.21430051727826493, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 604, reward: 0.0, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 605, reward: 0.16745798772265935, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 606, reward: 0.4210562476513579, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 607, reward: 0.3399418176190986, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 608, reward: 0.23336698931464456, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 609, reward: 0.6400839394851039, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 610, reward: 0.7873839741779963, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 611, reward: 0.7359262474624473, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 612, reward: 0.895175920237048, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 613, reward: 1.0534301875466148, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 614, reward: 1.0347765662475248, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 615, reward: 1.0034107143045912, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 616, reward: 0.8500059710838231, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 617, reward: 1.0385352309956708, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 618, reward: 1.161908252051838, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 619, reward: 1.111583551631691, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 620, reward: 1.1261241139384464, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 621, reward: 1.2136073240535536, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 622, reward: 1.216751464218788, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 623, reward: 1.220511429720174, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 624, reward: 1.3389363396425336, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 625, reward: 1.4463083645300914, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 626, reward: 1.3956389965315774, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 627, reward: 1.287051013806204, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 628, reward: 1.304455255894517, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 629, reward: 1.3170285657838758, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 630, reward: 1.4849768634071845, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 631, reward: 1.5923154274868685, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 632, reward: 1.434258581470002, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 633, reward: 1.511509132929818, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 634, reward: 1.3260745065730977, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 635, reward: 1.335596994620884, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 636, reward: 1.4357727687815394, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 637, reward: 1.4709551938511816, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 638, reward: 1.4097144757915316, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 639, reward: 1.6034659129499351, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 640, reward: 1.88711373423237, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 641, reward: 2.0948678329518504, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 642, reward: 2.015341616854285, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 643, reward: 2.2193320739351976, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 644, reward: 2.301556327751204, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 645, reward: 2.388872483089838, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 646, reward: 2.0440243151009625, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 647, reward: 1.9676069159069245, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 648, reward: 2.061171039320855, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 649, reward: 1.6337106465728155, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 650, reward: 1.574036256700179, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 651, reward: 1.8732078284532454, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 652, reward: 1.8767836014444403, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 653, reward: 2.059550626611192, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 654, reward: 2.2019029904918717, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 655, reward: 2.1392655837097183, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 656, reward: 2.1774609536072407, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 657, reward: 1.965827429987401, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 658, reward: 1.9134205219386478, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 659, reward: 2.0195702376116995, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 660, reward: 1.7811735871515775, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 661, reward: 1.744445674457614, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 662, reward: 1.8829299794346388, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 663, reward: 1.8394271111551321, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 664, reward: 1.6249833590819722, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 665, reward: 1.6166002413125526, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 666, reward: 1.70631721977979, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 667, reward: 1.5405399355395557, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 668, reward: 1.7925342747911108, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 669, reward: 1.9137332896310306, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 670, reward: 1.994791548039887, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 671, reward: 2.0136451490703435, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 672, reward: 1.8424540927285458, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 673, reward: 1.8471445938169877, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 674, reward: 1.8992437573913774, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 675, reward: 1.8431255128053436, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 676, reward: 1.7170339542274908, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 677, reward: 1.8306306740033804, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 678, reward: 1.8414461165966791, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 679, reward: 1.9478562091717542, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 680, reward: 1.9273991120327785, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 681, reward: 1.9420973282143525, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 682, reward: 1.8544712165254904, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 683, reward: 2.019288885187184, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 684, reward: 2.031872024732104, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 685, reward: 2.0729745075311685, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 686, reward: 1.8767836014444403, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 687, reward: 1.7624326872466705, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 688, reward: 1.958378630836564, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 689, reward: 1.9708611051690303, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 690, reward: 2.0919937130548596, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 691, reward: 2.18464186401875, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 692, reward: 2.1407619324489544, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 693, reward: 1.9973835203929675, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 694, reward: 2.0761696015647404, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 695, reward: 2.0864837120299695, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 696, reward: 2.0867467826143304, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 697, reward: 2.0729745075311685, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 698, reward: 2.0877983734361507, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 699, reward: 2.18201484702722, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 700, reward: 2.2051795631489357, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 701, reward: 2.2096092376715557, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 702, reward: 2.246377571481325, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 703, reward: 2.29024655165198, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 704, reward: 2.2822745383687284, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 705, reward: 2.3017684950724817, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 706, reward: 2.3574672164468136, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 707, reward: 2.3453550594269177, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 708, reward: 2.3281477301135878, account_value: 1191033.1421591244, action: 2, position: 1\n",
      "step: 709, reward: 2.3318600227840447, account_value: 1300704.1149536662, action: 2, position: 1\n"
     ]
    }
   ],
   "source": [
    "obs = testing_env.reset()\n",
    "i = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=False)\n",
    "    obs, rewards, dones, info = testing_env.step(action)\n",
    "\n",
    "    print(f'step: {i}, reward: {rewards}, account_value: {testing_env.get_account_value()}, action: {action}, position: {info[\"position\"]}')\n",
    "\n",
    "    if dones:\n",
    "      break\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "G2Uaaj3k_Tpm",
    "outputId": "8aa4b186-ea45-4a3b-fa2b-9230e2033faa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.cla()\n",
    "testing_env.render_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As we can see the model performance are positive, though it doesn't outperform the buy and hold strategy in terms of returns. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vwggb7yqqT2x"
   ],
   "name": "a2c-cl.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
