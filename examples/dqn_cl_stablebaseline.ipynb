{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "dqn-cl.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "vwggb7yqqT2x"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DQN trade\n",
    "\n",
    "{{ badge }}\n",
    "\n",
    "In this notebook a fully connected DQN model is trained on the crude oil daily dataset, enriched with the various tecnical indicators and the crude oil implied volatility index `OVX`.\n",
    "\n",
    "The importance of **implied volatility** for market participants stems from the fact that it is one of the only data that is **forward-looking**. This is because market participants always trade contracts with an expiration date later in time.\n",
    "\n",
    "The goal of this notebook is to see how (if it is possible) a A2C trading agent can leverage this kind of data to learn a profitable trading strategy."
   ],
   "metadata": {
    "id": "RDnu5pvf_mo_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title **Install externals libraries** {display-mode:'form'}\n",
    "!pip install stable-baselines3[extra]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "928KLlJqtW51",
    "outputId": "6caccb10-e0f9-46eb-83da-04a76a4c18da",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
      "\u001B[K     |████████████████████████████████| 177 kB 7.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.21.6)\n",
      "Collecting gym==0.21\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.5 MB 59.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.11.0+cu113)\n",
      "Collecting autorom[accept-rom-license]~=0.4.2\n",
      "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (7.1.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (2.8.0)\n",
      "Collecting ale-py~=0.7.4\n",
      "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.6 MB 42.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (4.1.2.30)\n",
      "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3[extra]) (4.11.4)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.4->stable-baselines3[extra]) (5.7.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.64.0)\n",
      "Collecting AutoROM.accept-rom-license\n",
      "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "    Preparing wheel metadata ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (4.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (57.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.17.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.46.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.5.18.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
      "  Building wheel for gym (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616827 sha256=834c31508f9cbcae5850ca30f71352d7fd5662bec72ecd2d0b5e170dfb046a12\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=6384af3e9e9bddcbf9f93f84de607f936669a034890322169eaafeb036ab71d7\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
      "Successfully built gym AutoROM.accept-rom-license\n",
      "Installing collected packages: gym, AutoROM.accept-rom-license, autorom, stable-baselines3, ale-py\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.17.3\n",
      "    Uninstalling gym-0.17.3:\n",
      "      Successfully uninstalled gym-0.17.3\n",
      "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2 gym-0.21.0 stable-baselines3-1.5.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title **Imports** {display-mode: 'form'}\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.dqn.policies import DQNPolicy"
   ],
   "metadata": {
    "id": "gpQM4fyPqZaA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "\n",
    "The preprocessing phase consist in the following phases:\n",
    "\n",
    "- addition of cyclical features for the time-related variables\n",
    "- standardization of the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def add_cyclical_features(df):\n",
    "    df['date'] = pd.to_datetime(df.index.copy(), format='%Y-%m-%d')\n",
    "    df['day_sin'] = df['date'].apply(lambda x: np.sin(x.day * (2. * np.pi / 30)))\n",
    "    df['day_cos'] = df['date'].apply(lambda x: np.cos(x.day * (2. * np.pi / 30)))\n",
    "    df['month_sin'] = df['date'].apply(lambda x: np.sin(x.month * (2. * np.pi / 12)))\n",
    "    df['month_cos'] = df['date'].apply(lambda x: np.cos(x.month * (2. * np.pi / 12)))\n",
    "    df = df.drop('date', axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "id": "E10RMnXQsZbR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cl_df = pd.read_csv('/content/mydrive/MyDrive/Datasets/trading/CL_daily_adj.csv', parse_dates=True)\n",
    "cl_df = cl_df.set_index('Date')\n",
    "cl_df = add_cyclical_features(cl_df)\n",
    "cl_df = cl_df.sort_index()"
   ],
   "metadata": {
    "id": "bj2fthlXrcTa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cl_df.close.plot();"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "82fhHj6zTgfz",
    "outputId": "ae23e33b-23d4-4e78-8f02-cc7ed74844c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sc = StandardScaler()\n",
    "cols, cl_index = cl_df.columns, cl_df.index\n",
    "cl_df = pd.DataFrame(sc.fit_transform(cl_df), columns=cols, index=cl_index)\n",
    "window_size = 21\n",
    "training_portion = 0.8\n",
    "episodes = 300\n",
    "\n",
    "train_cl_df = cl_df[0:int(np.floor(len(cl_df) * training_portion))]\n",
    "test_cl_df = cl_df[int(np.floor(len(cl_df) * training_portion)):]\n",
    "\n",
    "env = FuturesEnv(df=train_cl_df,\n",
    "                 window_size=window_size,\n",
    "                 frame_bound=(window_size, len(train_cl_df)))"
   ],
   "metadata": {
    "id": "UYc9NaZSTdFd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "\n",
    "Only 80% of the total data is used during the training phase. That's because we want to avoid the model simply memorizing the dataset (overfitting) and obtaining a model that is generalized well in all market situations.\n",
    "\n",
    "The A2C model is a fully connected neural network with 4 layers with 256, 128, 128, 64 neurson respectvely, the neural network will be given as input the daily data of the previous month (21 days)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "policy_kwargs = {'net_arch':[256, 128, 128, 64]}\n",
    "model = DQN(\"MlpPolicy\", \n",
    "            env, \n",
    "            verbose=1,\n",
    "            seed=0,\n",
    "            train_freq=5,\n",
    "            exploration_final_eps=0.1,\n",
    "            exploration_fraction=0.35,\n",
    "            policy_kwargs=policy_kwargs\n",
    "            )\n",
    "model.learn(total_timesteps=episodes*len(cl_df))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttI6n_JMsFZa",
    "outputId": "a3155382-e739-4248-8054-ab82009855a8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | -6.32    |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 5221     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | -6.48    |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 6801     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 23248    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 7.5      |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 7552     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 34872    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 7970     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 46496    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 4.53     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 4190     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 58120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0441   |\n",
      "|    n_updates        | 1623     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 1.92     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 2803     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 69744    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 3948     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 4.83     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 2258     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 81368    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 6273     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 7.37     |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1959     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 92992    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 8598     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 5.81     |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1771     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 104616   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0952   |\n",
      "|    n_updates        | 10923    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 2.45     |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1642     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 116240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00658  |\n",
      "|    n_updates        | 13247    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 1.17     |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1547     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 127864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0549   |\n",
      "|    n_updates        | 15572    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 0.595    |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1437     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 139488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 17897    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 2.49     |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1383     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 151112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 20222    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 4.79     |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1336     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 162736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0828   |\n",
      "|    n_updates        | 22547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 5.42     |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 1296     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 174360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 24871    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 9.12     |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 1263     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 185984   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0664   |\n",
      "|    n_updates        | 27196    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.537    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 1234     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 197608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0664   |\n",
      "|    n_updates        | 29521    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 1206     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 209232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 31846    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 1182     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 220856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0724   |\n",
      "|    n_updates        | 34171    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 25.9     |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 1160     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 232480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 36495    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 30.2     |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 1140     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 244104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 38820    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 1121     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 255728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0644   |\n",
      "|    n_updates        | 41145    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 42.8     |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 1104     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 267352   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0897   |\n",
      "|    n_updates        | 43470    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 51.9     |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 1088     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 278976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0441   |\n",
      "|    n_updates        | 45795    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1074     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 290600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.036    |\n",
      "|    n_updates        | 48119    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 73.4     |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 1059     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 302224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0476   |\n",
      "|    n_updates        | 50444    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 86.7     |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 1046     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 313848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0542   |\n",
      "|    n_updates        | 52769    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 101      |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 1033     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 325472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 55094    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 1022     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 337096   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.061    |\n",
      "|    n_updates        | 57419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 143      |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1008     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 348720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 59743    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 998      |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 360344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 62068    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 192      |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 376      |\n",
      "|    total_timesteps  | 371968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 64393    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 221      |\n",
      "|    exploration_rate | 0.102    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 977      |\n",
      "|    time_elapsed     | 392      |\n",
      "|    total_timesteps  | 383592   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0641   |\n",
      "|    n_updates        | 66718    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 254      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 968      |\n",
      "|    time_elapsed     | 408      |\n",
      "|    total_timesteps  | 395216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.276    |\n",
      "|    n_updates        | 69043    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 286      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 423      |\n",
      "|    total_timesteps  | 406840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0774   |\n",
      "|    n_updates        | 71367    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 319      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 439      |\n",
      "|    total_timesteps  | 418464   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0508   |\n",
      "|    n_updates        | 73692    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 352      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 944      |\n",
      "|    time_elapsed     | 455      |\n",
      "|    total_timesteps  | 430088   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.095    |\n",
      "|    n_updates        | 76017    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 385      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 937      |\n",
      "|    time_elapsed     | 471      |\n",
      "|    total_timesteps  | 441712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0456   |\n",
      "|    n_updates        | 78342    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 415      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 930      |\n",
      "|    time_elapsed     | 487      |\n",
      "|    total_timesteps  | 453336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 80667    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 450      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 503      |\n",
      "|    total_timesteps  | 464960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0488   |\n",
      "|    n_updates        | 82991    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 478      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 918      |\n",
      "|    time_elapsed     | 518      |\n",
      "|    total_timesteps  | 476584   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0612   |\n",
      "|    n_updates        | 85316    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 509      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 912      |\n",
      "|    time_elapsed     | 534      |\n",
      "|    total_timesteps  | 488208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0845   |\n",
      "|    n_updates        | 87641    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 535      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 907      |\n",
      "|    time_elapsed     | 550      |\n",
      "|    total_timesteps  | 499832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.055    |\n",
      "|    n_updates        | 89966    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 557      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 566      |\n",
      "|    total_timesteps  | 511456   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 92291    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 586      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 582      |\n",
      "|    total_timesteps  | 523080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0317   |\n",
      "|    n_updates        | 94615    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 613      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 597      |\n",
      "|    total_timesteps  | 534704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.233    |\n",
      "|    n_updates        | 96940    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 642      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 890      |\n",
      "|    time_elapsed     | 613      |\n",
      "|    total_timesteps  | 546328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 99265    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 674      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 885      |\n",
      "|    time_elapsed     | 630      |\n",
      "|    total_timesteps  | 557952   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0554   |\n",
      "|    n_updates        | 101590   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 695      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 645      |\n",
      "|    total_timesteps  | 569576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0983   |\n",
      "|    n_updates        | 103915   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 721      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 878      |\n",
      "|    time_elapsed     | 661      |\n",
      "|    total_timesteps  | 581200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 106239   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 741      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 875      |\n",
      "|    time_elapsed     | 677      |\n",
      "|    total_timesteps  | 592824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 108564   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 764      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 693      |\n",
      "|    total_timesteps  | 604448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 110889   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 777      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 868      |\n",
      "|    time_elapsed     | 708      |\n",
      "|    total_timesteps  | 616072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 113214   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 791      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 866      |\n",
      "|    time_elapsed     | 724      |\n",
      "|    total_timesteps  | 627696   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 115539   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 795      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 863      |\n",
      "|    time_elapsed     | 740      |\n",
      "|    total_timesteps  | 639320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 117863   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 809      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 860      |\n",
      "|    time_elapsed     | 756      |\n",
      "|    total_timesteps  | 650944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0477   |\n",
      "|    n_updates        | 120188   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 816      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 858      |\n",
      "|    time_elapsed     | 771      |\n",
      "|    total_timesteps  | 662568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 122513   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 820      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 855      |\n",
      "|    time_elapsed     | 787      |\n",
      "|    total_timesteps  | 674192   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 124838   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 826      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 803      |\n",
      "|    total_timesteps  | 685816   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 127163   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 832      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 851      |\n",
      "|    time_elapsed     | 819      |\n",
      "|    total_timesteps  | 697440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.343    |\n",
      "|    n_updates        | 129487   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 829      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 849      |\n",
      "|    time_elapsed     | 834      |\n",
      "|    total_timesteps  | 709064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0879   |\n",
      "|    n_updates        | 131812   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 825      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 847      |\n",
      "|    time_elapsed     | 850      |\n",
      "|    total_timesteps  | 720688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.346    |\n",
      "|    n_updates        | 134137   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 819      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 845      |\n",
      "|    time_elapsed     | 866      |\n",
      "|    total_timesteps  | 732312   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 136462   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 817      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 843      |\n",
      "|    time_elapsed     | 882      |\n",
      "|    total_timesteps  | 743936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 138787   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 808      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 841      |\n",
      "|    time_elapsed     | 897      |\n",
      "|    total_timesteps  | 755560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.218    |\n",
      "|    n_updates        | 141111   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 806      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 914      |\n",
      "|    total_timesteps  | 767184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 143436   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 801      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 837      |\n",
      "|    time_elapsed     | 930      |\n",
      "|    total_timesteps  | 778808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 145761   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 806      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 945      |\n",
      "|    total_timesteps  | 790432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0517   |\n",
      "|    n_updates        | 148086   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 818      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 961      |\n",
      "|    total_timesteps  | 802056   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 150411   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 815      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 832      |\n",
      "|    time_elapsed     | 977      |\n",
      "|    total_timesteps  | 813680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.068    |\n",
      "|    n_updates        | 152735   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 822      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 831      |\n",
      "|    time_elapsed     | 992      |\n",
      "|    total_timesteps  | 825304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 155060   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 822      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 1008     |\n",
      "|    total_timesteps  | 836928   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 157385   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 812      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 1024     |\n",
      "|    total_timesteps  | 848552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.227    |\n",
      "|    n_updates        | 159710   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 816      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 827      |\n",
      "|    time_elapsed     | 1040     |\n",
      "|    total_timesteps  | 860176   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0851   |\n",
      "|    n_updates        | 162035   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 811      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 825      |\n",
      "|    time_elapsed     | 1055     |\n",
      "|    total_timesteps  | 871800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 164359   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 807      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 1071     |\n",
      "|    total_timesteps  | 883424   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0513   |\n",
      "|    n_updates        | 166684   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 799      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 823      |\n",
      "|    time_elapsed     | 1087     |\n",
      "|    total_timesteps  | 895048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.25     |\n",
      "|    n_updates        | 169009   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 806      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 822      |\n",
      "|    time_elapsed     | 1102     |\n",
      "|    total_timesteps  | 906672   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 171334   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 807      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 819      |\n",
      "|    time_elapsed     | 1134     |\n",
      "|    total_timesteps  | 929920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 175983   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 812      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 818      |\n",
      "|    time_elapsed     | 1149     |\n",
      "|    total_timesteps  | 941544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 178308   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 811      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 817      |\n",
      "|    time_elapsed     | 1165     |\n",
      "|    total_timesteps  | 953168   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 180633   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 815      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 816      |\n",
      "|    time_elapsed     | 1181     |\n",
      "|    total_timesteps  | 964792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0526   |\n",
      "|    n_updates        | 182958   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 810      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 815      |\n",
      "|    time_elapsed     | 1196     |\n",
      "|    total_timesteps  | 976416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 185283   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 811      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 814      |\n",
      "|    time_elapsed     | 1212     |\n",
      "|    total_timesteps  | 988040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 187607   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 809      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 813      |\n",
      "|    time_elapsed     | 1228     |\n",
      "|    total_timesteps  | 999664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 189932   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 814      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 813      |\n",
      "|    time_elapsed     | 1243     |\n",
      "|    total_timesteps  | 1011288  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 192257   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 823      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 812      |\n",
      "|    time_elapsed     | 1259     |\n",
      "|    total_timesteps  | 1022912  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.234    |\n",
      "|    n_updates        | 194582   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 827      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 811      |\n",
      "|    time_elapsed     | 1275     |\n",
      "|    total_timesteps  | 1034536  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0746   |\n",
      "|    n_updates        | 196907   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 835      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 810      |\n",
      "|    time_elapsed     | 1290     |\n",
      "|    total_timesteps  | 1046160  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0561   |\n",
      "|    n_updates        | 199231   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 839      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 809      |\n",
      "|    time_elapsed     | 1306     |\n",
      "|    total_timesteps  | 1057784  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 201556   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 853      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 1321     |\n",
      "|    total_timesteps  | 1069408  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 203881   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 855      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 808      |\n",
      "|    time_elapsed     | 1337     |\n",
      "|    total_timesteps  | 1081032  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 206206   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91e+03 |\n",
      "|    ep_rew_mean      | 848      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 807      |\n",
      "|    time_elapsed     | 1353     |\n",
      "|    total_timesteps  | 1092656  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.199    |\n",
      "|    n_updates        | 208531   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7fbddeb6c110>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing Results\n",
    "\n",
    "Now that the model has been trained, let's test its performance on the testing data (out of sample data)."
   ],
   "metadata": {
    "id": "B2Ys_CPu9JiK",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "testing_env = FuturesEnv(df=test_cl_df,\n",
    "                 window_size=window_size,\n",
    "                 frame_bound=(window_size, len(test_cl_df)))"
   ],
   "metadata": {
    "id": "e3FIxPFO-ftc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "obs = testing_env.reset()\n",
    "i = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=False)\n",
    "    obs, rewards, dones, info = testing_env.step(action)\n",
    "\n",
    "    print(f'step: {i}, reward: {rewards}, account_value: {testing_env.get_account_value()}, action: {action}, position: {info[\"position\"]}')\n",
    "\n",
    "    if dones:\n",
    "      break\n",
    "\n",
    "    i += 1"
   ],
   "metadata": {
    "id": "hkdrEsqOwswg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "52b3871b-3384-4b9b-f025-435180e47754",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step: 0, reward: 0, account_value: 1000000, action: 1, position: -1\n",
      "step: 1, reward: -0.05091026213379323, account_value: 1000000, action: 1, position: -1\n",
      "step: 2, reward: -0.19451114426483523, account_value: 1000000, action: 1, position: -1\n",
      "step: 3, reward: -0.2502566252767778, account_value: 1000000, action: 1, position: -1\n",
      "step: 4, reward: -0.3344001866922833, account_value: 1000000, action: 1, position: -1\n",
      "step: 5, reward: -0.31401870592553166, account_value: 1000000, action: 1, position: -1\n",
      "step: 6, reward: -0.2857654423578625, account_value: 1000000, action: 1, position: -1\n",
      "step: 7, reward: -0.25090189532880725, account_value: 1000000, action: 1, position: -1\n",
      "step: 8, reward: -0.30672489957018245, account_value: 1000000, action: 1, position: -1\n",
      "step: 9, reward: -0.2981476706445037, account_value: 1000000, action: 1, position: -1\n",
      "step: 10, reward: -0.2870105873892981, account_value: 1000000, action: 1, position: -1\n",
      "step: 11, reward: -0.24443038107836637, account_value: 1000000, action: 1, position: -1\n",
      "step: 12, reward: -0.16472516139276466, account_value: 1000000, action: 1, position: -1\n",
      "step: 13, reward: -0.12674787654969952, account_value: 1003454.050361611, action: 2, position: 0\n",
      "step: 14, reward: 0, account_value: 1003454.050361611, action: 1, position: -1\n",
      "step: 15, reward: 0.0979750181135968, account_value: 1003454.050361611, action: 1, position: -1\n",
      "step: 16, reward: 0.041225980936826015, account_value: 1001885.9538784256, action: 2, position: 0\n",
      "step: 17, reward: 0, account_value: 1001885.9538784256, action: 1, position: -1\n",
      "step: 18, reward: -0.12773216919380515, account_value: 1001885.9538784256, action: 1, position: -1\n",
      "step: 19, reward: -0.05682343409387234, account_value: 1001885.9538784256, action: 1, position: -1\n",
      "step: 20, reward: 0.04779189576645868, account_value: 1001885.9538784256, action: 1, position: -1\n",
      "step: 21, reward: 0.07228423459437198, account_value: 1001885.9538784256, action: 1, position: -1\n",
      "step: 22, reward: 0.20596071598360483, account_value: 994532.8528018673, action: 2, position: 0\n",
      "step: 23, reward: 0, account_value: 994532.8528018673, action: 1, position: -1\n",
      "step: 24, reward: -0.043628953230448374, account_value: 996111.1207217004, action: 2, position: 0\n",
      "step: 25, reward: 0, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 26, reward: 0.0792203826255729, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 27, reward: 0.0786007036333131, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 28, reward: 0.05110527490691353, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 29, reward: 0.031411831887439866, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 30, reward: -0.03599455249643041, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 31, reward: -0.06485204601318938, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 32, reward: 0.006895632694078957, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 33, reward: 0.057150369766155264, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 34, reward: 0.11519233355971552, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 35, reward: 0.01674656581089521, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 36, reward: 0.08668663826925249, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 37, reward: 0.08918782951773023, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 38, reward: 0.10305733812840029, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 39, reward: 0.19126758960782053, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 40, reward: 0.16054297166261583, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 41, reward: 0.05533300118568709, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 42, reward: 0.01616440510665131, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 43, reward: 0.00229326498070879, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 44, reward: 0.6222813921959872, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 45, reward: 0.3003144487510252, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 46, reward: 0.20452909860390336, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 47, reward: 0.21512437249742283, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 48, reward: 0.20804839797709102, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 49, reward: 0.24760087904721623, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 50, reward: 0.1531739330916588, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 51, reward: 0.1011546761851605, account_value: 996111.1207217004, action: 1, position: -1\n",
      "step: 52, reward: 0.09609853860715223, account_value: 992788.4514167887, action: 2, position: 0\n",
      "step: 53, reward: 0, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 54, reward: 0.10656750810906866, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 55, reward: 0.13098889465967664, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 56, reward: 0.1821953653541367, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 57, reward: 0.19182671994378686, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 58, reward: 0.17349849640714077, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 59, reward: 0.17657662349149836, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 60, reward: 0.1827045980599947, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 61, reward: 0.1847389396587679, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 62, reward: 0.13473474089198495, account_value: 992788.4514167887, action: 2, position: 1\n",
      "step: 63, reward: 0.07134352025168487, account_value: 992788.4514167887, action: 0, position: 1\n",
      "step: 64, reward: 0.13259597576239418, account_value: 987970.5809246668, action: 1, position: 0\n",
      "step: 65, reward: 0, account_value: 987970.5809246668, action: 1, position: -1\n",
      "step: 66, reward: 0.02866662543214293, account_value: 987970.5809246668, action: 1, position: -1\n",
      "step: 67, reward: 0.059269117006264305, account_value: 987970.5809246668, action: 1, position: -1\n",
      "step: 68, reward: 0.05600334374925746, account_value: 985769.3125101628, action: 2, position: 0\n",
      "step: 69, reward: 0, account_value: 985769.3125101628, action: 1, position: -1\n",
      "step: 70, reward: 0.053083502267164365, account_value: 983754.9442440601, action: 2, position: 0\n",
      "step: 71, reward: 0, account_value: 983754.9442440601, action: 1, position: -1\n",
      "step: 72, reward: 0.01607713100875094, account_value: 983754.9442440601, action: 1, position: -1\n",
      "step: 73, reward: 0.04324689852195805, account_value: 983754.9442440601, action: 1, position: -1\n",
      "step: 74, reward: -0.02603464229460334, account_value: 983754.9442440601, action: 1, position: -1\n",
      "step: 75, reward: -0.054317757055757816, account_value: 983754.9442440601, action: 1, position: -1\n",
      "step: 76, reward: -0.10417969731157141, account_value: 987472.18052893, action: 2, position: 0\n",
      "step: 77, reward: 0, account_value: 987472.18052893, action: 2, position: 1\n",
      "step: 78, reward: -0.021381251242011963, account_value: 987472.18052893, action: 2, position: 1\n",
      "step: 79, reward: -0.06623068616445003, account_value: 989611.1488939669, action: 1, position: 0\n",
      "step: 80, reward: 0, account_value: 989611.1488939669, action: 1, position: -1\n",
      "step: 81, reward: 0.05154987445131783, account_value: 987949.814241511, action: 2, position: 0\n",
      "step: 82, reward: 0, account_value: 987949.814241511, action: 2, position: 1\n",
      "step: 83, reward: 0.024964528291070598, account_value: 987160.6802815945, action: 1, position: 0\n",
      "step: 84, reward: 0, account_value: 987160.6802815945, action: 2, position: 1\n",
      "step: 85, reward: -0.020898872689364235, account_value: 987825.2141425768, action: 1, position: 0\n",
      "step: 86, reward: 0, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 87, reward: -0.06323897280463689, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 88, reward: -0.024156729141387712, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 89, reward: 0.0876434025149815, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 90, reward: -0.015602575434222804, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 91, reward: -0.12415401877910774, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 92, reward: -0.06668075114998595, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 93, reward: -0.08336821430057173, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 94, reward: -0.11181480344833757, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 95, reward: -0.09040435859345994, account_value: 987825.2141425768, action: 0, position: 1\n",
      "step: 96, reward: 0.050930742654360636, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 97, reward: 0.042311267059606576, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 98, reward: -0.11325859808546461, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 99, reward: -0.11325859808546461, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 100, reward: -0.17049185739700987, account_value: 987825.2141425768, action: 0, position: 1\n",
      "step: 101, reward: -0.15681631420550105, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 102, reward: -0.17355643311850957, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 103, reward: -0.13738718247293136, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 104, reward: -0.16896308421518216, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 105, reward: -0.2393624066659186, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 106, reward: -0.25090189532880725, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 107, reward: -0.30717126993348837, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 108, reward: -0.30541878788004284, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 109, reward: -0.3347349698275483, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 110, reward: -0.2701535597137812, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 111, reward: -0.27693762304103015, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 112, reward: -0.3284441645651605, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 113, reward: -0.3808584472845121, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 114, reward: -0.38464189221649325, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 115, reward: -0.3808584472845121, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 116, reward: -0.3239748386307867, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 117, reward: -0.3347349698275483, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 118, reward: -0.5193600713323051, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 119, reward: -0.5435042021177653, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 120, reward: -0.4821113733300257, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 121, reward: -0.2023580523699714, account_value: 987825.2141425768, action: 0, position: 1\n",
      "step: 122, reward: -0.19841712577434645, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 123, reward: -0.1583266161113729, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 124, reward: -0.0882883121651345, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 125, reward: -0.09891360711634992, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 126, reward: -0.06944272835214091, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 127, reward: -0.12050900593566516, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 128, reward: -0.12415401877910774, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 129, reward: 0.0019333156705582557, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 130, reward: 0.07335947567614985, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 131, reward: 0.15394434951486394, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 132, reward: 0.21038852946421094, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 133, reward: 0.19245781789956337, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 134, reward: 0.2004080858570279, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 135, reward: 0.2613357852775698, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 136, reward: 0.2897378991554114, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 137, reward: 0.35740254165515517, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 138, reward: 0.3797125578546738, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 139, reward: 0.32809961949977384, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 140, reward: 0.31876352434020644, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 141, reward: 0.3478818501540525, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 142, reward: 0.38147604106485344, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 143, reward: 0.36504392532538354, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 144, reward: 0.3083921332331809, account_value: 987825.2141425768, action: 2, position: 1\n",
      "step: 145, reward: 0.29647439784771845, account_value: 976715.0386542785, action: 1, position: 0\n",
      "step: 146, reward: 0, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 147, reward: -0.0738706853461116, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 148, reward: -0.09485342424960524, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 149, reward: -0.0680312179685164, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 150, reward: 0.030198490175574043, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 151, reward: 0.10103721251110852, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 152, reward: 0.152012233680299, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 153, reward: 0.2193545539955207, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 154, reward: 0.3078460687446497, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 155, reward: 0.23276572048184216, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 156, reward: 0.2157742259113597, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 157, reward: 0.23158959051181496, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 158, reward: 0.2655272464596536, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 159, reward: 0.4269513188125464, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 160, reward: 0.6284876118347159, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 161, reward: 0.6642405035629556, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 162, reward: 0.7012147806312353, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 163, reward: 0.6955577371070006, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 164, reward: 0.8070108198292877, account_value: 976715.0386542785, action: 2, position: 1\n",
      "step: 165, reward: 0.9336721950157613, account_value: 913204.5882261101, action: 1, position: 0\n",
      "step: 166, reward: 0, account_value: 913204.5882261101, action: 2, position: 1\n",
      "step: 167, reward: 0.06835653850900947, account_value: 906949.1546877815, action: 1, position: 0\n",
      "step: 168, reward: 0, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 169, reward: -0.009995421230398678, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 170, reward: 0.0287966643413445, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 171, reward: 0.05050314573383052, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 172, reward: 0.07809250241088248, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 173, reward: 0.07059064774583333, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 174, reward: 0.0738676082628111, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 175, reward: -0.027518473977356375, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 176, reward: -0.0940007252718687, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 177, reward: -0.043837518357439334, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 178, reward: 0.00784279090570596, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 179, reward: -0.022631853589826438, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 180, reward: 0.0255703599565325, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 181, reward: 0.032614430121207134, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 182, reward: 0.07770915786753341, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 183, reward: 0.08229962189812402, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 184, reward: 0.08229962189812402, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 185, reward: 0.11237572691152108, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 186, reward: 0.8229400493265834, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 187, reward: 0.22933049746050474, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 188, reward: 0.19224408524726214, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 189, reward: 0.14462636732015222, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 190, reward: 0.1367058743176721, account_value: 906949.1546877815, action: 2, position: 1\n",
      "step: 191, reward: 0.20919583073452885, account_value: 885531.9233964919, action: 1, position: 0\n",
      "step: 192, reward: 0, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 193, reward: -0.046446611817464935, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 194, reward: -0.11479998124510664, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 195, reward: -0.13254889160625213, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 196, reward: -0.14423767253309194, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 197, reward: -0.22802598958186904, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 198, reward: -0.21615020377092958, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 199, reward: -0.20707842326894282, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 200, reward: -0.23180572894267146, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 201, reward: -0.21926176254466953, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 202, reward: -0.25392846000079466, account_value: 885531.9233964919, action: 0, position: 1\n",
      "step: 203, reward: -0.2434442521848951, account_value: 885531.9233964919, action: 0, position: 1\n",
      "step: 204, reward: -0.29296646059832804, account_value: 885531.9233964919, action: 0, position: 1\n",
      "step: 205, reward: -0.3377920068385707, account_value: 885531.9233964919, action: 0, position: 1\n",
      "step: 206, reward: -0.3888977171389293, account_value: 885531.9233964919, action: 0, position: 1\n",
      "step: 207, reward: -0.39655824408375817, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 208, reward: -0.43525083431099876, account_value: 885531.9233964919, action: 2, position: 1\n",
      "step: 209, reward: -0.44640026591548976, account_value: 925773.517253631, action: 1, position: 0\n",
      "step: 210, reward: 0, account_value: 925773.517253631, action: 1, position: -1\n",
      "step: 211, reward: -0.011212483041565663, account_value: 925773.517253631, action: 1, position: -1\n",
      "step: 212, reward: 0.011858135428595843, account_value: 924876.7355891932, action: 2, position: 0\n",
      "step: 213, reward: 0, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 214, reward: -0.0013584231437041554, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 215, reward: 0.03654650181698431, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 216, reward: 0.05017440884784444, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 217, reward: 0.05361060336436521, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 218, reward: 0.11695965177629361, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 219, reward: 0.07623837377731696, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 220, reward: 0.09848960680275079, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 221, reward: 0.11848882620994132, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 222, reward: 0.023380082190141396, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 223, reward: 0.02115615329720798, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 224, reward: 0.04532659032650076, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 225, reward: 0.08182869730970492, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 226, reward: 0.06951268855400448, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 227, reward: 0.10179515771417881, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 228, reward: 0.12555330437697385, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 229, reward: 0.15368685170917942, account_value: 924876.7355891932, action: 0, position: -1\n",
      "step: 230, reward: 0.14233827782679573, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 231, reward: 0.07097095095918987, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 232, reward: 0.09191110548433376, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 233, reward: 0.08507954211321916, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 234, reward: 0.12155420813022598, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 235, reward: 0.10843922124241506, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 236, reward: 0.12524511315720965, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 237, reward: 0.15115379300471177, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 238, reward: 0.15020554777445927, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 239, reward: 0.15909100077117316, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 240, reward: 0.11910115132953417, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 241, reward: 0.14799646608823153, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 242, reward: 0.13391057459857364, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 243, reward: 0.1398337674604487, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 244, reward: 0.16869956461065114, account_value: 924876.7355891932, action: 0, position: -1\n",
      "step: 245, reward: 0.15432112021698674, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 246, reward: 0.15432112021698674, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 247, reward: 0.15972870733521802, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 248, reward: 0.19214394733189108, account_value: 924876.7355891932, action: 0, position: -1\n",
      "step: 249, reward: 0.19148523759082708, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 250, reward: 0.1645245134172882, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 251, reward: 0.17160022976388048, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 252, reward: 0.18165630758025317, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 253, reward: 0.16356351045541895, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 254, reward: 0.17095490999348517, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 255, reward: 0.12833130789813713, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 256, reward: 0.1392086187324132, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 257, reward: 0.1626034301336532, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 258, reward: 0.1849218951281137, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 259, reward: 0.20107925956299852, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 260, reward: 0.1931328262184425, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 261, reward: 0.16934343013396527, account_value: 924876.7355891932, action: 0, position: -1\n",
      "step: 262, reward: 0.192803091257495, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 263, reward: 0.18198238686994475, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 264, reward: 0.21716411005162473, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 265, reward: 0.20274274447946197, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 266, reward: 0.19511352247979633, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 267, reward: 0.22462369658386278, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 268, reward: 0.2324823132756838, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 269, reward: 0.23213934702282463, account_value: 924876.7355891932, action: 1, position: -1\n",
      "step: 270, reward: 0.22224415040927573, account_value: 910586.7147189112, action: 2, position: 0\n",
      "step: 271, reward: 0, account_value: 910586.7147189112, action: 2, position: 1\n",
      "step: 272, reward: -0.009398443026882754, account_value: 911120.7151429149, action: 1, position: 0\n",
      "step: 273, reward: 0, account_value: 911120.7151429149, action: 1, position: -1\n",
      "step: 274, reward: 0.0013839689099329649, account_value: 911044.4293680573, action: 2, position: 0\n",
      "step: 275, reward: 0, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 276, reward: -0.0023917417373029598, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 277, reward: -0.014602573281477672, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 278, reward: -0.009532834736500852, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 279, reward: -0.05101550227840562, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 280, reward: -0.055556189838534775, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 281, reward: -0.10603629096179339, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 282, reward: -0.15760277721758778, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 283, reward: -0.17928156329687636, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 284, reward: -0.17842337555527593, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 285, reward: -0.18042466917409242, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 286, reward: -0.15085934462962472, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 287, reward: -0.09396460208565448, account_value: 911044.4293680573, action: 1, position: -1\n",
      "step: 288, reward: -0.06841711594212692, account_value: 914992.2182169415, action: 2, position: 0\n",
      "step: 289, reward: 0, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 290, reward: -0.05591489361807341, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 291, reward: -0.04793997539557589, account_value: 914992.2182169415, action: 0, position: -1\n",
      "step: 292, reward: -0.043928539039966616, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 293, reward: -0.032109683668564266, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 294, reward: -0.033985130341300795, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 295, reward: -0.02299510745462889, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 296, reward: -0.06352356921478611, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 297, reward: -0.034921536337089415, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 298, reward: -0.08065788542812723, account_value: 914992.2182169415, action: 1, position: -1\n",
      "step: 299, reward: -0.12923175038165924, account_value: 914992.2182169415, action: 0, position: -1\n",
      "step: 300, reward: -0.065643665034178, account_value: 918997.2213969689, action: 2, position: 0\n",
      "step: 301, reward: 0, account_value: 918997.2213969689, action: 0, position: 0\n",
      "step: 302, reward: 0, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 303, reward: 0.039118760564338335, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 304, reward: 0.020314856778823172, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 305, reward: -0.01595988108893433, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 306, reward: 0.007764644020310156, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 307, reward: 0.03430448377640986, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 308, reward: 0.03174631509149553, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 309, reward: 0.036869213476114486, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 310, reward: 0.03494504979262488, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 311, reward: 0.05566286844910465, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 312, reward: 0.002478132689412655, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 313, reward: 0.02157858466409327, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 314, reward: -0.0030890547705760894, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 315, reward: -0.011687985705559683, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 316, reward: -0.07622194298759363, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 317, reward: -0.11059889574427792, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 318, reward: -0.12106950660504862, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 319, reward: -0.0927125248620246, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 320, reward: -0.06845153564931672, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 321, reward: -0.02444931132142106, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 322, reward: -0.03525945220392584, account_value: 918997.2213969689, action: 1, position: -1\n",
      "step: 323, reward: -0.08336332304830525, account_value: 924356.29708072, action: 2, position: 0\n",
      "step: 324, reward: 0, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 325, reward: 0.03402836660029862, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 326, reward: 0.036944067268704875, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 327, reward: 0.02629447269467472, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 328, reward: -0.004990281202625653, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 329, reward: 0.033381585998770044, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 330, reward: 0.036295398709024415, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 331, reward: 0.05527975501934772, account_value: 924356.29708072, action: 1, position: -1\n",
      "step: 332, reward: 0.0516514701303785, account_value: 921217.5612551874, action: 2, position: 0\n",
      "step: 333, reward: 0, account_value: 921217.5612551874, action: 2, position: 1\n",
      "step: 334, reward: -0.021671970772378465, account_value: 921217.5612551874, action: 2, position: 1\n",
      "step: 335, reward: -0.08709546705804726, account_value: 921217.5612551874, action: 2, position: 1\n",
      "step: 336, reward: -0.11676860652431369, account_value: 927631.4996812758, action: 1, position: 0\n",
      "step: 337, reward: 0, account_value: 927631.4996812758, action: 0, position: 0\n",
      "step: 338, reward: 0, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 339, reward: 0.0266854174888994, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 340, reward: 0.04011224872344458, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 341, reward: 0.06366743176103903, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 342, reward: 0.04462822237394269, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 343, reward: 0.038611444835220846, account_value: 927631.4996812758, action: 0, position: -1\n",
      "step: 344, reward: 0.035616577440350565, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 345, reward: 0.08386042006882716, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 346, reward: 0.07565641198688547, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 347, reward: 0.09213229103077111, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 348, reward: 0.11736654583133688, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 349, reward: 0.1255124380395745, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 350, reward: 0.15539962043410074, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 351, reward: 0.18533891866283714, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 352, reward: 0.131665700785248, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 353, reward: 0.09331959236758379, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 354, reward: 0.1378570607162794, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 355, reward: 0.14242187874181436, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 356, reward: 0.11736654583133688, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 357, reward: 0.13290090993336043, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 358, reward: 0.14951784068407933, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 359, reward: 0.15455724513465458, account_value: 927631.4996812758, action: 0, position: -1\n",
      "step: 360, reward: 0.11736654583133688, account_value: 927631.4996812758, action: 0, position: -1\n",
      "step: 361, reward: 0.21575463659426025, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 362, reward: 0.24758651892738234, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 363, reward: 0.2568706074310577, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 364, reward: 0.32488995436037016, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 365, reward: 0.325389270607635, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 366, reward: 0.37452313921505487, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 367, reward: 0.35890789678858226, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 368, reward: 0.3935891019353794, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 369, reward: 0.3339160159454947, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 370, reward: 0.3797828798986271, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 371, reward: 0.37033517501819807, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 372, reward: 0.32638865167532427, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 373, reward: 0.35170339851935833, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 374, reward: 0.343532745874485, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 375, reward: 0.3558138968164389, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 376, reward: 0.3298943716908168, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 377, reward: 0.3228951788100785, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 378, reward: 0.39252029116000997, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 379, reward: 0.45933180204623736, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 380, reward: 0.5138991500405595, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 381, reward: 0.5470058492087932, account_value: 927631.4996812758, action: 0, position: -1\n",
      "step: 382, reward: 0.5864200984679718, account_value: 927631.4996812758, action: 1, position: -1\n",
      "step: 383, reward: 0.6618138022061334, account_value: 901468.8693839791, action: 2, position: 0\n",
      "step: 384, reward: 0, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 385, reward: -0.023269736125936937, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 386, reward: 0.008588420089422759, account_value: 901468.8693839791, action: 0, position: 1\n",
      "step: 387, reward: -0.08314795036606082, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 388, reward: -0.22292096911730422, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 389, reward: -0.16957446567459114, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 390, reward: -0.06687783956796309, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 391, reward: -0.27453396996366813, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 392, reward: -0.27170040798080525, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 393, reward: -0.42975107679001595, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 394, reward: -0.4645962882914138, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 395, reward: -0.2557934731027582, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 396, reward: -0.17898639006928627, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 397, reward: -0.10526158412052974, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 398, reward: -0.23557663341628682, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 399, reward: -0.49951446029577684, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 400, reward: -0.8110750636188635, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 401, reward: -0.6555940215679583, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 402, reward: -0.5210660174625886, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 403, reward: -0.5745122231259722, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 404, reward: -0.7998161974052801, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 405, reward: -0.7363016891203785, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 406, reward: -0.6215650408356089, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 407, reward: -0.595151757716172, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 408, reward: -0.1303288200780725, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 409, reward: -0.2502391313799013, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 410, reward: 0.042222963319465505, account_value: 901468.8693839791, action: 2, position: 1\n",
      "step: 411, reward: -0.22652055934659032, account_value: 906847.0165114446, action: 1, position: 0\n",
      "step: 412, reward: 0, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 413, reward: 0.19328562735228605, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 414, reward: 0.24689882949082884, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 415, reward: 0.15679914044842513, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 416, reward: 0.04474222569288661, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 417, reward: 0.23668270679338677, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 418, reward: 0.006585042099085814, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 419, reward: 0.05779184183659975, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 420, reward: 0.09237999192965335, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 421, reward: 0.07887420467844211, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 422, reward: 0.05701948524127766, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 423, reward: 0.08679667728973077, account_value: 906847.0165114446, action: 1, position: -1\n",
      "step: 424, reward: 0.12572349431847815, account_value: 903757.4426297091, action: 2, position: 0\n",
      "step: 425, reward: 0, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 426, reward: -0.03457315316336492, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 427, reward: -0.0043944582967580924, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 428, reward: -0.031174636076648315, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 429, reward: 0.051280205743570506, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 430, reward: 0.18008301620619505, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 431, reward: 0.17273165541629018, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 432, reward: 0.10500541424064791, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 433, reward: 0.12745110057023154, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 434, reward: 0.022759318800139303, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 435, reward: -0.08102623075839424, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 436, reward: -0.22802291215814469, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 437, reward: -0.04828391188919427, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 438, reward: -0.15886838036178358, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 439, reward: -0.326334015409863, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 440, reward: -0.31726007542332424, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 441, reward: -0.18754459908117702, account_value: 903757.4426297091, action: 2, position: 1\n",
      "step: 442, reward: -0.21298994248407366, account_value: 907094.945279732, action: 1, position: 0\n",
      "step: 443, reward: 0, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 444, reward: 0.050203029764617345, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 445, reward: 0.1717043631499356, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 446, reward: -0.13942384696539656, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 447, reward: 0.06315771992437566, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 448, reward: 0.20286776903758874, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 449, reward: 0.08217140129795344, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 450, reward: -0.1935384658747718, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 451, reward: -0.3402582702025738, account_value: 907094.945279732, action: 1, position: -1\n",
      "step: 452, reward: -0.1674225421884589, account_value: 909650.5187374637, action: 2, position: 0\n",
      "step: 453, reward: 0, account_value: 909650.5187374637, action: 2, position: 1\n",
      "step: 454, reward: -0.0032193767266854435, account_value: 909650.5187374637, action: 2, position: 1\n",
      "step: 455, reward: -0.02604997412772097, account_value: 909650.5187374637, action: 2, position: 1\n",
      "step: 456, reward: -0.13761744759341635, account_value: 911176.2342346171, action: 1, position: 0\n",
      "step: 457, reward: 0, account_value: 911176.2342346171, action: 1, position: -1\n",
      "step: 458, reward: 0.5476270696595573, account_value: 911176.2342346171, action: 1, position: -1\n",
      "step: 459, reward: 0.5418339617991178, account_value: 906427.4447497274, action: 2, position: 0\n",
      "step: 460, reward: 0, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 461, reward: -0.13718236812813597, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 462, reward: 0.17687807445699993, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 463, reward: 0.13717961071040724, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 464, reward: 0.2911581904774063, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 465, reward: 0.6662213317591889, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 466, reward: 0.6444401150503027, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 467, reward: 2.8567858804803477, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 468, reward: 3.0760194895782362, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 469, reward: 0.7665066251986193, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 470, reward: 0.9932293169543756, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 471, reward: 1.1407926273360143, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 472, reward: 1.5243132362111649, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 473, reward: 1.1891338648049345, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 474, reward: 0.9482226729053752, account_value: 906427.4447497274, action: 0, position: -1\n",
      "step: 475, reward: 0.40018945520524896, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 476, reward: 1.4254856548821362, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 477, reward: 1.3213196852738243, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 478, reward: 0.7951307656925654, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 479, reward: -0.10892183530925409, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 480, reward: -0.08496951248702908, account_value: 906427.4447497274, action: 1, position: -1\n",
      "step: 481, reward: 3.6011753991965048, account_value: 901507.012271408, action: 2, position: 0\n",
      "step: 482, reward: 0, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 483, reward: -1.2315565680527958, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 484, reward: -1.0070582884137307, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 485, reward: -1.4951697241101323, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 486, reward: -0.25044460904108334, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 487, reward: -0.07014354184865995, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 488, reward: 0.06491547691976408, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 489, reward: 2.182787822028672, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 490, reward: 2.0278597881028766, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 491, reward: 1.0832930600890278, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 492, reward: -0.6109917984804184, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 493, reward: -1.1935206600838497, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 494, reward: -0.6109917984804184, account_value: 901507.012271408, action: 1, position: -1\n",
      "step: 495, reward: -0.07014354184865995, account_value: 903967.2285105677, action: 2, position: 0\n",
      "step: 496, reward: 0, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 497, reward: 2.4386981755091393, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 498, reward: 2.657735388744275, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 499, reward: -2.1526758970648494, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 500, reward: -2.6782528968502906, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 501, reward: -3.556796623858979, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 502, reward: -3.2979958735622534, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 503, reward: -3.5247535646992887, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 504, reward: -3.896908660075734, account_value: 903967.2285105677, action: 2, position: 1\n",
      "step: 505, reward: -3.5222456559389266, account_value: 896147.936587657, action: 1, position: 0\n",
      "step: 506, reward: 0, account_value: 896147.936587657, action: 1, position: -1\n",
      "step: 507, reward: -0.051584611332455836, account_value: 896147.936587657, action: 1, position: -1\n",
      "step: 508, reward: -0.2374408617185089, account_value: 896147.936587657, action: 1, position: -1\n",
      "step: 509, reward: -0.4998620496192255, account_value: 899802.8728230598, action: 2, position: 0\n",
      "step: 510, reward: 0, account_value: 899802.8728230598, action: 2, position: 1\n",
      "step: 511, reward: 0.2174116717758882, account_value: 899802.8728230598, action: 2, position: 1\n",
      "step: 512, reward: 0.4342374956630551, account_value: 899802.8728230598, action: 2, position: 1\n",
      "step: 513, reward: 0.5783654606925456, account_value: 899802.8728230598, action: 2, position: 1\n",
      "step: 514, reward: 0.15459335397913831, account_value: 899802.8728230598, action: 2, position: 1\n",
      "step: 515, reward: -0.1829416300047772, account_value: 899802.8728230598, action: 2, position: 1\n",
      "step: 516, reward: -0.37322363939727027, account_value: 903103.5040152348, action: 1, position: 0\n",
      "step: 517, reward: 0, account_value: 903103.5040152348, action: 0, position: 0\n",
      "step: 518, reward: 0, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 519, reward: -0.14277912665913034, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 520, reward: 0.0657340935943999, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 521, reward: 0.041587325540373025, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 522, reward: -0.43675186959211276, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 523, reward: -0.1692498087282259, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 524, reward: -0.17260846049744574, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 525, reward: 0.15688131952288611, account_value: 903103.5040152348, action: 0, position: 1\n",
      "step: 526, reward: -0.3249447403152774, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 527, reward: -0.6618264063235688, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 528, reward: -0.6673288226214299, account_value: 903103.5040152348, action: 2, position: 1\n",
      "step: 529, reward: -2.3478320304206837, account_value: 910484.152732714, action: 1, position: 0\n",
      "step: 530, reward: 0, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 531, reward: -0.2926427985178868, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 532, reward: -1.8431003753637452, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 533, reward: -1.6638119330949428, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 534, reward: 2.0750325842074844, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 535, reward: 1.1130955922771937, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 536, reward: 1.6209538232097362, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 537, reward: 2.2419878853009374, account_value: 910484.152732714, action: 2, position: 1\n",
      "step: 538, reward: 2.1903237044883284, account_value: 915595.2996481776, action: 1, position: 0\n",
      "step: 539, reward: 0, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 540, reward: 0.0752910765501769, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 541, reward: 0.34397204447647145, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 542, reward: 0.7375760910116707, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 543, reward: 0.9566868457820299, account_value: 915595.2996481776, action: 0, position: 1\n",
      "step: 544, reward: 0.7013996667157577, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 545, reward: 0.8572768968309374, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 546, reward: 1.017862546566548, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 547, reward: 1.1708496873539258, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 548, reward: 1.1852945225496059, account_value: 915595.2996481776, action: 0, position: 1\n",
      "step: 549, reward: 1.1611025607643095, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 550, reward: 1.2623209634370205, account_value: 915595.2996481776, action: 2, position: 1\n",
      "step: 551, reward: 1.3642719864150226, account_value: 929803.5252154177, action: 1, position: 0\n",
      "step: 552, reward: 0, account_value: 929803.5252154177, action: 0, position: 0\n",
      "step: 553, reward: 0, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 554, reward: 0.0920179301466904, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 555, reward: 0.005883747387497507, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 556, reward: 0.12206186288611541, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 557, reward: 0.12206186288611541, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 558, reward: 0.19668198227659567, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 559, reward: 0.021406568038935425, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 560, reward: 0.0357435776738997, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 561, reward: 0.10538400150775044, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 562, reward: 0.13503489211637246, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 563, reward: -0.16888667415764283, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 564, reward: -0.44163541185999594, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 565, reward: -0.12224816515379393, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 566, reward: -0.05146096142028257, account_value: 929803.5252154177, action: 2, position: 1\n",
      "step: 567, reward: 0.1554479090896482, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 568, reward: -0.11449843006377816, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 569, reward: -0.08730100134222513, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 570, reward: -0.1770713539478317, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 571, reward: -0.16656044578538728, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 572, reward: -0.1805996851295527, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 573, reward: -0.6557336495524941, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 574, reward: -0.504771631390915, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 575, reward: -1.0196666013364655, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 576, reward: -0.8201175028986929, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 577, reward: -0.49021442013146743, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 578, reward: -0.5080355485064096, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 579, reward: 1.4766114191443211, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 580, reward: 0.5121672568764676, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 581, reward: 0.4167434988344891, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 582, reward: 0.5661215204458927, account_value: 929803.5252154177, action: 0, position: 1\n",
      "step: 583, reward: 0.5253853726146, account_value: 898260.2049314937, action: 1, position: 0\n",
      "step: 584, reward: 0, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 585, reward: 2.5266413171126505, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 586, reward: 3.4581465985638884, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 587, reward: 0.7363367393419663, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 588, reward: 1.5301631032283738, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 589, reward: 1.0410785028266842, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 590, reward: 0.5899776933399038, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 591, reward: 0.6851330616870935, account_value: 898260.2049314937, action: 0, position: -1\n",
      "step: 592, reward: 3.1238686754505447, account_value: 898260.2049314937, action: 0, position: -1\n",
      "step: 593, reward: 0.5835151674932691, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 594, reward: -0.27480584377330186, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 595, reward: 0.8814732517738245, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 596, reward: 1.7415447704443097, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 597, reward: 0.6061714826971146, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 598, reward: -0.1698890328567351, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 599, reward: -0.28707846557552535, account_value: 898260.2049314937, action: 0, position: -1\n",
      "step: 600, reward: -0.4324203957684787, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 601, reward: -0.5279932000711526, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 602, reward: -0.05428746991442237, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 603, reward: -0.31369268279288753, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 604, reward: -0.5279932000711526, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 605, reward: -0.695451187793812, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 606, reward: -0.9490494477225105, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 607, reward: -0.8679350176902512, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 608, reward: -0.7613601893857972, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 609, reward: -1.1680771395562564, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 610, reward: -1.3153771742491487, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 611, reward: -1.2639194475335997, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 612, reward: -1.4231691203082004, account_value: 898260.2049314937, action: 1, position: -1\n",
      "step: 613, reward: -1.5814233876177675, account_value: 867845.9141154632, action: 2, position: 0\n",
      "step: 614, reward: 0, account_value: 867845.9141154632, action: 2, position: 1\n",
      "step: 615, reward: -0.03136585194293363, account_value: 867098.7373317183, action: 1, position: 0\n",
      "step: 616, reward: 0, account_value: 867098.7373317183, action: 2, position: 1\n",
      "step: 617, reward: 0.18852925991184769, account_value: 867098.7373317183, action: 2, position: 1\n",
      "step: 618, reward: 0.3119022809680147, account_value: 867098.7373317183, action: 2, position: 1\n",
      "step: 619, reward: 0.2615775805478679, account_value: 873112.5992496642, action: 1, position: 0\n",
      "step: 620, reward: 0, account_value: 873112.5992496642, action: 2, position: 1\n",
      "step: 621, reward: 0.08748321011510718, account_value: 873112.5992496642, action: 2, position: 1\n",
      "step: 622, reward: 0.09062735028034168, account_value: 873112.5992496642, action: 2, position: 1\n",
      "step: 623, reward: 0.0943873157817276, account_value: 873112.5992496642, action: 2, position: 1\n",
      "step: 624, reward: 0.21281222570408703, account_value: 873112.5992496642, action: 2, position: 1\n",
      "step: 625, reward: 0.320184250591645, account_value: 873112.5992496642, action: 2, position: 1\n",
      "step: 626, reward: 0.26951488259313117, account_value: 881313.3200468633, action: 1, position: 0\n",
      "step: 627, reward: 0, account_value: 881313.3200468633, action: 2, position: 1\n",
      "step: 628, reward: 0.01740424208831313, account_value: 881872.7490624861, action: 1, position: 0\n",
      "step: 629, reward: 0, account_value: 881872.7490624861, action: 1, position: -1\n",
      "step: 630, reward: -0.1679482976233085, account_value: 881872.7490624861, action: 1, position: -1\n",
      "step: 631, reward: -0.2752868617029926, account_value: 881872.7490624861, action: 1, position: -1\n",
      "step: 632, reward: -0.11723001568612608, account_value: 881872.7490624861, action: 1, position: -1\n",
      "step: 633, reward: -0.1944805671459421, account_value: 874823.9434656379, action: 2, position: 0\n",
      "step: 634, reward: 0, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 635, reward: 0.009522488047786307, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 636, reward: 0.10969826220844173, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 637, reward: 0.14488068727808368, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 638, reward: 0.08363996921843404, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 639, reward: 0.2773914063768375, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 640, reward: 0.5610392276592724, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 641, reward: 0.7687933263787529, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 642, reward: 0.6892671102811873, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 643, reward: 0.8932575673621, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 644, reward: 0.9754818211781063, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 645, reward: 1.0627979765167406, account_value: 874823.9434656379, action: 0, position: 1\n",
      "step: 646, reward: 0.7179498085278647, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 647, reward: 0.6415324093338269, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 648, reward: 0.7350965327477571, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 649, reward: 0.30763613999971784, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 650, reward: 0.2479617501270817, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 651, reward: 0.5471333218801476, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 652, reward: 0.5507090948713426, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 653, reward: 0.7334761200380943, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 654, reward: 0.8758284839187741, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 655, reward: 0.8131910771366205, account_value: 874823.9434656379, action: 2, position: 1\n",
      "step: 656, reward: 0.8513864470341429, account_value: 918305.9875147865, action: 1, position: 0\n",
      "step: 657, reward: 0, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 658, reward: -0.05240690804875306, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 659, reward: 0.05374280762429851, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 660, reward: -0.18465384283582337, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 661, reward: -0.22138175552978698, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 662, reward: -0.08289745055276211, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 663, reward: -0.1264003188322688, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 664, reward: -0.3408440709054287, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 665, reward: -0.34922718867484837, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 666, reward: -0.25951021020761084, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 667, reward: -0.42528749444784525, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 668, reward: -0.17329315519629027, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 669, reward: -0.05209414035637034, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 670, reward: 0.02896411805248596, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 671, reward: 0.04781771908294292, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 672, reward: -0.12337333725885506, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 673, reward: -0.11868283617041316, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 674, reward: -0.06658367259602346, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 675, reward: -0.12270191718205722, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 676, reward: -0.24879347575990998, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 677, reward: -0.13519675598402053, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 678, reward: -0.12438131339072168, account_value: 918305.9875147865, action: 0, position: 1\n",
      "step: 679, reward: -0.017971220815646824, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 680, reward: -0.038428317954622496, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 681, reward: -0.02373010177304839, account_value: 918305.9875147865, action: 2, position: 1\n",
      "step: 682, reward: -0.11135621346191055, account_value: 918305.9875147865, action: 0, position: 1\n",
      "step: 683, reward: 0.05346145519978322, account_value: 921834.2046019536, action: 1, position: 0\n",
      "step: 684, reward: 0, account_value: 921834.2046019536, action: 0, position: 0\n",
      "step: 685, reward: 0, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 686, reward: -0.19619090608672818, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 687, reward: -0.310541820284498, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 688, reward: -0.11459587669460439, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 689, reward: -0.10211340236213806, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 690, reward: 0.019019205523691376, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 691, reward: 0.11166735648758143, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 692, reward: 0.06778742491778618, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 693, reward: -0.07559098713820082, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 694, reward: 0.003195094033571874, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 695, reward: 0.013509204498801069, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 696, reward: 0.013772275083162148, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 697, reward: 0.0, account_value: 921834.2046019536, action: 1, position: 0\n",
      "step: 698, reward: 0, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 699, reward: 0.09421647359106942, account_value: 921834.2046019536, action: 0, position: 1\n",
      "step: 700, reward: 0.11738118971278529, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 701, reward: 0.12181086423540499, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 702, reward: 0.15857919804517467, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 703, reward: 0.20244817821582914, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 704, reward: 0.194476164932578, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 705, reward: 0.21397012163633106, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 706, reward: 0.26966884301066313, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 707, reward: 0.2575566859907671, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 708, reward: 0.2403493566774373, account_value: 921834.2046019536, action: 2, position: 1\n",
      "step: 709, reward: 0.24406164934789398, account_value: 942343.2113625767, action: 2, position: 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.cla()\n",
    "testing_env.render_all()"
   ],
   "metadata": {
    "id": "G2Uaaj3k_Tpm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "outputId": "68a5917c-ca78-4978-bf72-3196fad49e0c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEVCAYAAAD91W7rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXxcVZ348c83k6Rt0pLStK5ASQIKKBAW2ciiuIqmuDxYEJ9WnRQouKHJutvi/pZV41pQ4+7qLtJdbUp0W4q9PuBaHgpUhIoK7C4SFAjPIjShPPXJpqQpTZqc3x/nTDqZ3DsPmZtkbvJ9v17zysy9d+49mbnznTPfc+45YoxBKaVUdBVNdgGUUkrlRwO5UkpFnAZypZSKOA3kSikVcRrIlVIq4jSQK6VUxE2ZQC4iRkTeOtnlGCsROUtEtk12OVT4ROSXIvKZCTjOLBHZJCI9IvITEYmLyM/H+7hq8o17IBeR3qTbkIjsT3ocD3hOqEHNfZDecMfcKSIbReSIsPY/mUTkfe5L7GtJy04Wkbvc/5r2QgER+YuU96jX7e+jbv2alHUHROT1pOfPE5GbRWSfiHSJyKeT1p0vIveLyB4ReVVEvicic1KOv0hEfuuev01EPpG07gNu3V4ReV5EGsN4zZL2vznp/xoQkf6kx2vSPC+0SoOIXO2O3etep/8RkXeNcXcfA/4EqDTGfNwY4xljPjjWcovVIiLd7j34kYgc5rPdPBHZISL3Jy07Q0TuFpHdbt1Pkj9zInKle0/3isjLIvItESn22bff+f1JEXnGfWFtF5H1fuVy2x4vIre6Mux2n4sTktan/ayIyGdFpMOd9zekrDvRrfuju90jIiembHOaiPzavb+vicjypHX3unLtFZFHReRCv/8hG+MeyI0xsxM3oBtYnLTMG+/jJ/msK8NbgdnAv03gsUfwO2HHuJ8SYBXwYMqqAeAm4PJM+zDG3JfyHn0I6AV+5tYvS1n/Q+AnSbv4DtCPDSBxoE1ETnLrKoCvAUcCbweOAr6ZVP4TgR8ALW7bPwUeTvrfbgaud+v+CrhWRP40i5cmK8aYc5P+Lw/4RtL/uiys42Thx64MC4D7gY0iIqkbiUgsw36qgWeNMQdDKtfFwBLgTOx7OAv4T5/t/hV4KmXZ4UA7UOPK9TqwLmn9bcBpxpjDgJOx7/3fJe8gzfn9AHCmMaYCOBYoxp5nfua6Y52APUd/A9yatD7TZ+Vlt++1Aes+BswD5rvj/Cip/POxn6PrgUps7En+hbQcOMK9Bo3ABhlrBdMYM2E3YCuwyN2fAVznXoyX3f0ZQDmwHxjCBpRe7El0OvC/wB7gFeDbQGnSvg3w1oDj/hL4TNLjZuCJpMdvA+4GdgPPAJ9wy49xxytyj78LbE963veBFe7+UuzJ/DrwPHBF0nZnAduAfwRedc+bBdwA/BF4EvgHYFuOr+fngW+4/XzNZ/1b7Vuc0z7XAesC1pW7/+99SY/7geNTXpN/CXj+R4DOpMc/AL4asO2fuPe0LGnZQ8CnxuncHPEaAn8NPOfOiduAI93yX7ty7XPn5l9hg9btwA73ft4OLAw6/1KOezWwIenxSW7/812Z2oA73fEWYb8Qf+nOyyeAC9zzrnHvxYAr1+XApcD9QeXO4jX5b+Afkh6/G3gj5T15N/ZzuTRxrIB9nQa8HrCuErgHWJ3L+e22mQ3cCNyZ5fs8z70Olbl8VrDB/IY064uBvwH6kpZ9Hfh+luU63b22p4/l/J3MHHkLcAZwKvbb+HTgS8aYfcC5wMvmUO3oZWAQuBJ7gr8LqMcG5JyISCU2oDznHpdjg/gPgDcBnwRWi8iJxpgXgL3AO9zT3wv0isjb3eP3Ab9y97dja7OHYU/qb4nIaUmHfjP2JKrGfvuuBN7ibn8JXJJSztUisjrN/1ENXAZ8JceXIJB7LT4GrA/Y5KPYYPVr9/h44KAx5tmkbR7FBiM/78UGn4Qz3HE7ReQVEdkgIvMAjDGvYWv/S0Uk5tIN1dgaa878arhptv0A8M/AJ4AjgC5cTcsY81632Z+6c/PH2F+261z5qrAVkW+PoYwzsMH3RWPMTrf400ArMAdbM92ErdW9CfhbwBORE4wxK7GB48euXP+VvO+AcuPSOe9JV6yU+zOA49xzY+7//Cw2OKaT+t4jIp8Wkb3ATmwMuD5pXdrzW0TeIyI92IrFR7EVwWy8F3jVGLMry+0zEpE92CD8n9j3IOEMYLdLl20X235RlfLc20XkDex7+0ugY0yFyLcmk8uNkTXyPwDnJa37S2Cru38WGWqnwArg5qTHmWrkfUCP2+4RoMqt+yvgvpTtrwdWuvvfBz6HDcTPYGsIy0iprfsc8xZgedL/0w/MTFr/PHBO0uPGTP9zyv5vxdWqCKlGjv0Z/QIgAeu3AFcnPf4L7IcieZu/Bn7p89yzsbXV5Np7vzsnjsfWrH4KeEnrFwOvAQfd7a/TlH2ue99eBJ4G/gn7s7sK+B5QneF/H34Ngf/CplkS62Zja7o1mc41t/5U4I8p51+6Gnm/O5e2A78A/iypTDemvt7J5xz2y+7qpH0l1+4vJamWnKncPmX7DPAsNj1Sgf1lYoB3ufVXAm1+x0rZzynYXzZ/EbD+OOCrwJtzOb/duqPc/318Fv/PQuAlfH7VkX+NvBxbsTw/admz7n19JzAT+A/gAZ/nlmArr5/L9r1JvU1mjfxIbE0nocst8+UaLW4X22i2F/vNNz+H4/2dsTm1U7A/hRe65dXAn7uayR737RrHBm6wNe6zsN/kv8Z+KN/nbvcZY4Zc+c4Vkf9zDSp7gPNSyrfDGPNGyv//Ysr/nxURWQzMMa5WFaJLsIHDr9GnCvs63Ji0uBf7CyTZYdhaUvJzz8D+4vmYGVl7349N4zxrjOnFvqfnuee8DVsLvhgoxdbyrxKR8wPKfg7wW+wvnA9jf67fj81RPmKMyfr1JeXcdGXbhQ0ao4hImYhcL7axdy/2PJmbRU474SZjzFxjzJuMMR8wxjyctC75HDkSW1sfSlrWFVSuEKzFflH8Elubvtct3yYiR2Jz2i3pdiC2cXUztlJzn982xpjfu/2vds/J+vw2xryEfY9/lG47EVmA/SWz2hjzw0z7zZWxmYQ1wI0i8ia3eD+2svmQ++xfA7xbRCpSnjtgjNkMfFBELhjL8UNpdBujl7FBNPFzq8otA/+faW3A77Dfpq+LyApsGiAnxphO1wL+HZf6eBH4lTHm7ICn/ArbQLfN3b8f+4a94R4nfhL/FBt0bjXGDIjILYz8WZr6P70CHM3I/z9b9UCdiLzqHlcAgyJSa4wZU8u3iByNDdRXBGyyBFubeD5p2bNAsYgc5z6MYH8iD/+EFpF3YGtylxljtqTs8zFGvi7J90/GNtzd5R4/IyJ3YGsud/iU76akAPc09hfbioD/JZPEuZn4H8qxXwwvBWz/99jGtD83xrwqIqdiz9Ws0zlpJL8mLwNHi0hR0v9ahX0fQueOsdLdEJEPYl+Dl4ALsGmnJ13WahYwy52TRxljBl165B5sO8j3MxyuGPslDLmf38nPHUVEDscG8duMMa0ZypGPIqAM+8W6nfTnt5+0/0emA0+WHwJfEpEFrnX3y8AGt+41oDLlm2sONl/d62prTXkcez22Me0CbMPU8SKyRERK3O2diTy4C1D7gQZswN/ryvdRDuXHS7G5wx3AQRE5F/gg6d0EfEFEDheRhdh8Z7b+CZuOONXdbsM2xC6F4W5jM125EJGZ7ssmnSXA/xhj/hCw/mLsT9xhrhayEfiKiJSLyJnAhdh0FCJyMra29LfGmE0++1yHzYEfKyJl2Mat29263wHHie2CKCLyFmwbxGN+hUuppeYrkZs/1b1uXwceNMZsdetfw6ZtEuZgz5E9Lse/MsSyJHsQmyK8yp2nZ2HTT2lro0lSy52W2G6Fb3Gv/4nAtcBX3Gu9GZtySZyDX8a+Z6e6IH4UNk30bWPMqK6cIvKZRM3V7fsL2NQdZD6/44lcs/uyaE16bupxDgPuwlZCPu+zPu1nRUSK3foYEHPri926s0XkHWLbcA5zr88fOdSDZx1wkTuPStz/db8xpkdE3uZ+xc9y72UD9ld/IqbkZqw5mbHcGJkjT+SMXnG3/2BkDnkt9ufsHuxPyvdia1q9wH3YRpCs8n/45CixPUg63P0TsLW8He6Yv8CekMl5yBeSHv8bNn0QS1r2N9gPyh5sIPsRh3KuZ5GS/8Z+c9/oth/VawVb61+T5et6AyN7XNS41yP5tjVp/Wbgiyn7eBq4PGD/78L2dpjjs24etj1gH7Z76aeT1q1jZO+jXpJ6C7ltrnGv+w73uh2etO4TwOPutd6G7ebm2yYRwrmZ+houw7bj7GZ0L5Rl7pzd48p4pDvHerG14yvca14cdP4l7etqkvLa6crklp2E/bD3uPPmoqB9MTpHPqLcblkvwbnr47HtQn3YFE5gDtfnWCvda5D83vemnBuvufNmK/ZX78xsXgds4N7mnrsN282xMmn98PmNTRcaDvXWSdwSbWQ1pP+sXO2z/mq37uMcikk7sDHklJSyN2F/wfwR21B9tFv+duwX8+vu/Xgo+b3M9SZup0oppSJqylyir5RS05UGcqWUijgN5EopFXEayJVSKuI0kCulVMRpIFdKqYjTQK6UUhGngVwppSJOA7lSSkWcBnKllIo4DeRKKRVxGsiVUiriNJArpVTEaSBXSqmI00CulFIRp4FcKaUiTgO5UkpF3KRMvjx//nxTU1MzGYdWSqnIevjhh3caYxakLp+UQF5TU0NHR8dkHFoppSJLRLr8luedWnGzSv9GRB4VkSdE5Jp896mUUip7YdTIDwAfMMb0ikgJcL+IbDbG/F8I+1ZKKZVB3oHcGGOAXvewxN1MvvtVSimVnVB6rYhITEQeAbYDdxtjHvTZplFEOkSkY8eOHWEcVimlFCEFcmPMoDHmVGAhcLqInOyzTbsxps4YU7dgwahGV6WUUmMUaj9yY8we4F7gnDD3q5RSKlgYvVYWiMhcd38WcDbwdL77VUoplZ0wauRHAPeKyGPAQ9gc+e0h7Fcppcbd//xhJ89t78284Rh5nR4119VQdE0RNdfV4HV6oR8jjF4rjwHvCKEsSik14T79Xds3Y+u/nB/6vr1Oj8ZNjfQN9AHQ1dPFko1LeKD7AVafvzq04+hYK0qpacv2nh4/LVtahoP48DExtHW00XxHc2jH0UCulJq29r5xcFz3393THbiuraMttDSLBnKl1LTkdXqcuPotdM1czLYZS8cldz1v1ry061u2tIRynEkZNEsppSbTiNy1wKDsoHFTIwDx2nhox9i1f1fabdLV2HOhNXKl1LTjl7vuG+gLrYYMsHzz8ozbVFVUhXIsDeRKqWknqCYcVg0ZyFgbL42V0lrfGsqxNJArpaadoJpwWDXkTIqkiLUXrg0tjaOBXCk17Zx33Hm+y986763jfvEOwI0X3RhaEAdt7FRKTUN3/v5O3+W/eGHL8BjcXT1dNN58GZB7A2imPuJhBnHQGrlSahoKyoWnXh7UZ/ppuS1zo2Wq9ofbA9dVV1TnvL9MtEaulJp2qiqq6Orxnf5ylO6B9I2Wyb533/Ps6D3AoBkM3CasBs5kWiNXSk07rfWtlJWUjVwYcLX+vD7/5X6+dsdTXP+r54lJzHe9IKGnVUADuVJqmppVPMveMRAzhzF7QPw3jOUeJhtqL/ddvqxuWc77yoamVpRS00rqiIQIDJkD9Jb6V8l3zxzKuL+WLS1093RTNGM+MXMkNz726IgafpEIV9QtC3XEw2QayJVS04rviIRyIHD7qjSNk6lfCoNFOxg0bk7ipAp+0aDhzPCuNRpFUytKqWkll6s3M1196felgE+G5mAMWp4P7smSL62RK6WmlVx6rPQP9o8YfyWRQqmqqKK1vpXuLPcD0F0e3JMlXzLeA6v7qaurMx0dHRN+XKWU8jo9lt6ylIGhgayfU0QRQ4zMlZdJKbP29bOrLOBJKap7Y2z9Zn7jn4vIw8aYutHly5OIHC0i94rIkyLyhIjk3nteKaUmSLw2zmEzDsvpOalBHOzFQhgo609Z4VM3Lh6E1mMbczpmLsLIkR8E/t4YcyJwBvA3InJiCPtVSqlxsXv/7lD2s6sM+kqgaAgwUL0H6v9g7ydus/uFG45oIt40Pj1WIJzJl18BXnH3XxeRp4CjgCfz3bdSSo2HXPLkabmGzSGB0oPQugU+vvtodn/7Wd5cMTP//Wcp1F4rIlIDvAN4MMz9KqVUmIJGP8xHfzFcchH8pOVDExrEIcRALiKzgZ8CK4wxe33WN4pIh4h07NixI6zDKqVUTrxOj/WPrh+XfQ8WQeMf14/b8LdBQum1IiIlwO3AXcaYazNtr71WlFKTpea6mnDSKmlUV1SzdcXW0Pc7nr1WBPgv4KlsgrhSSk2mMKdzm8xjJAsjtXImsAT4gIg84m7hJ6CUUioEEzGd20RNGZeQdyA3xtxvjBFjzCnGmFPdzX/6DaWUmmSt9a3MKs7yKp4xKCspG5cxx9PRsVaUUtNKvDbOv5/9HWJDCwChclYlxVKS516LwAhHlC+kfXH7uIw5nuHoSik1vZz3lo+z8MA6/vtD3ey8aiefe+d1NrCbgDHJMzh9/sepfmMTD1z69IQHcdBArpSahvYdsANYlc+wM/mcc+zHWHhgHdVvbBrTnJqvDvwvt//tezhmfnmo5cyWjn6olJp2+vrt4FWzSm0I/GX3RrbN+DKDspPK/nk57+/Fnhc5+aiKUMuYCw3kSqmpz/OgpQW6u/HeN49/eL/hlZl/5JO3HcVFb1/Mdx/+HoNFdjTEXfuzn2w5YaJ7qaTSQK6Umto8Dxoboa8PrxYa372LPgMIvLpvG20dbXntfjJ6qaTSHLlSampraRkO4pd8GPpK899l5axKBKG6onpSeqmk0hq5Umpq6+62NfHFMBgLZ5ezS2ez86qd4ewsBBrIlVJTltfp0XKl0DXH+M6lmU5pUSn9Q6mzRlgTfQl+JppaUUpNSV6nR+PNl9F12FDuQTxWytoPr2V26Wzf9ZPduJlKA7lSakpafssyOx1blqorqofz3msvXEu8Ns6aD62hrGTk5fyF0LiZSlMrSqkpx+v02DXYm3VNPCYx32FnE42YLVta6O7ppqqiitb61klv3EylgVwpNeW0bGnJKZ0yaAYD18Vr4wUXuFNpakUpNeXkOnHEWC7LLyQayJVSU8pJ3zkpp+0FKbicd640kCulpozmO5p5cueTOT1nWd2ygk+dZKI5cqXUlNB87SLa9m5JnxtPmqK4sqySVeeuinwQBw3kSqkJ5HV649IDJKsgDlT2wc7eJli9Ou9jFpJQUisislZEtovI42HsTyk19TTf0cySjUvo6unCYOjq6aJhYwOLblyU977bezIH8eKiYlYt2TDlgjiElyO/ATgnpH0ppaaY5juaaetowyTnNpwtL2yh+Y7mse/c8xjMkE4pHoQbPnzDlEij+AklkBtjfg3sDmNfSqmpxWtrpu2h9EPFtnW04XV6YzvA8uXEhoJXlx6EgRM2TNkgDtprRSk1jry2Zhpebcvq4pzLbr0s92DuebBrF40d4FPZB2BOaTnEp24QhwkM5CLSKCIdItKxY8eOiTqsUmqSNN/RTMNrbVlHmf7BfpZvXp7bQZbb7VdvDt5kt+nLbZ8RNGGB3BjTboypM8bULViwYKIOq5SaBF6nZ2feyXHUwZynWdt1aPvqHv9NCm2kwvGgqRWlVOhatrSM/0G8kWmY1i1QljLYYSGOVDgewup++EPgf4ETRGSbiFwexn6VUtGU61gnCXNKDs9+4yuuGPEw3gntm6B6D4iB6uLKgpiGbSKEckGQMeZTYexHKRV9Y+5KaODTJ3yZfQcOUlYaQyRNXqa5GfbtG7U43mlvNE29i37S0dSKUio0w7nxMfrZQ8dx0sq7+PubHg3eqLkZ2jIcYxoFcdBArpQKidfpccnNl6TdpnJWZeCQsTFzqBPEPU+95r+DbIL4NKSBXKnporkZiopA5NBt/vxRjYZjkZgfM90EDQCrzl1Fa32r7/RpDW///PDjI+fO8jmIB2vWZC5MZWVWZZ5KdNAspaY6z7MNgz45ZXbtgksvtZudMvYpzVpuW55xfszykvIR+0s91uLjPsEpj/wcgP6DPpdqtrSACbjqJ9mqVVmVeSrRQK7UVJUugCc7eJDmH1/CmueGhsdC6erponFTI0BWwbxrYFfGPuPXL75++H7Q9Gn/8al38JOOF3lue6/PQbLoCdPUNOWv4vSjqRWlpqJFi6ChYVQQ92qhZgUUrbR/vVp7azttcNSAVn0DfRn7g3ttzcz/QuYwUjmrMqsvhAv+9EiOnV9OX/+g/SKqqbHpoJoamwrKZJo1ciZojVypqaa5GbZsGbXYq4XGxdBXah93zbWPh4TA2nR3T3fgYby2Zpa+3MbAzMxFWnVu9umOmaUx6n93D3x9FfS7dE02tfFpmBtP0ECu1FQT0CDYUn8oiCf0lRI42BQwqlEy2eUvtzGQRQSpP6Y+p4tyykqK+dLP1xwK4tkoKZmWufEETa0oNZWcdFJgg2B3RcBz0mQs9g3sGzUiodfpMeOrMzgQy1yc+mPquefiezJvmGRWaRGH7389+ydUVsK6ddMyN56gNXKlpgCvrZmWZ9vo/jhU9dhxR+KdI7ep6rHplFy1rG0gfuABvKYzWb55+aGBrTKkrMtLynMO4gCzSrL4hkgQgZ07cz7GVKM1cqUizmtrpnFbG11zwcih3LdXO3I7v0GlJIvefF0V4N3fxmU3NeQ0OmFyL5VcHL9lU7psz0jZdEecBjSQKxVxLc+3++a+W+pHLot3QvtdpVQXV9pBpfbAst+MDu5+Gj4C/Tn+fh/rYFWnrP5G9oFpGjdwJtNArlTEdZf7X005KideUkL8yrVsbdnJ0PYmXrjOTsiQGDEwsBqcpldLkMpZYw+wM199aczPna40R67UBPA6PVq2tIwY3jUmMRr/rJHV52fu++x1eiPy05X7hVV3Gh5YCOZ0/+dUJU+0UFlpe3UkGgTvvHM4NidGDJSVY/jHfJQUleTU3TDV4FELKd72YnYb79apgkEDuVLjzuv0WHrLUgaGBkYsHzSDwyMFpgvmiRnok+2aZVhykc2J+9WWSw/anDjFxXDDDaN7dPj0y67sg13l2fxHwaorqnO6tN/P0HnnY9rXZPcjoGrqz/6TDTGT0FhQV1dnOjo6Jvy4Sk2G+d+Yn7GR0Kz0/xx6nR5LNi4ZddVlJpX7YOfqcuj1udQdbIAfHJmS8WptLjzXNMrM2Ey+d+H3wpvAoabG/wIgkZGNm2Vl0N4+rbodisjDxpi61OWaIy9AXqdHzXU1FF1TRM11NbnPLK4KQvMdzRR/pTirnh6J99jr9Jj99dnINYJcIzRsbMg5iAPsLgP60kw6PDg6rx7vtLXybAlCU10T+7+0P9xZeLoDriY1BqqrbUCvrp52QTwdTa0E8Tw72lp3t/351to6ISdN6s/orp4ult6yFBh7LwA18fzSIekkxjS5eOPFDOEz8l+OqnpIn3aorvat9a56qJLGs/fTN5A+opeXlNP7xYDafr6qqvxr5NXVsHXr+Bwz4rRG7sfzoLHRnkzG2L+NjaGM2xx4SHe1nN+Hf2BogOWbl4/bsVX4rn84tz7U3Xu6aLnxklCCOAZa7yuxlY8gra02NZGsrIz4Z1bRvrg9cPKHhJnFWQywMlYBZUv7/0xzYU2+fI6IPCMiz4nI5zM/o8C1tIz+WdrXZ5eHrPmO5uGf0P1DwR16c7kQQ02u5juaGTK5BeR5fcHdCMcifmWGS9bjcZua8ElVxGvjbF2xlQ0f2RD49HE9H9OUTfnLu7FTRGLAs8DZwDbgIeBTxpgng54zbo2dYaVDior8rxgTgaEQakzOSd85iSd3Br5MowQ1iKnC4XV6NGxsyPl5pQdhzoEce40YfBsmqyuq2bpia85l8BP7Ssz3SykmMQ5++WAox1DZG8/GztOB54wxzxtj+oEfAReGsN/c+KVDliyxQ3rmKii3GFJXp0QaJZcgLog2ekbAFZuuGNPz+ovhjRhpRyIcZmD2AWjyuSqzrB9a68NLQQT9ssg0pZuaWGEE8qOA5N7729yyEUSkUUQ6RKRjx44dIRw2hV86xBhYswavrTm3XiDnnef/edq1a0x5cq/TY/435o/oiZAujeLHYGjY2MCcf56jAb1ANd/RzL6BDLPxpLFvBll1/SuXUl7/RmzEVZmJS+7b/ye7CRyyFZQrz5RDVxNrwnqtGGPagXawqZWw9nvf73fw3fteYH13t+9nwDvZ0Lit7dBg+pmmsHKzdPt+nnp7ba0fsk7Z5Np7IZPe/l4uu/UyWwTtxVIwvE4v1Pc5nes/shbeCjQ2Eu/sOzTKYVkZtIc7JndrfSuNmxpH9GIpKykLtdav8hdGjfwl4OikxwvdsgnR/uvn+fWzO3hpznzf9b6D6Q/00bCx4VDtPDGllAi0ZfgwBjV6Ju2j+XyhaKUgVwttD4X/4e4f7M84BZeaWMtvWZbfDgzMzuJHWlNdk/0Cn6AGwXhtfLgXiyBUV1TTvrhdKxEFJozGzmJsY2c9NoA/BHzaGPNE0HPCauy8s/MVmr3fAnDBE/ey6vZ/H1WTLlrpLmMOUNZvf56mjt2crPlcaK+DwSKIDUFjB6y+M+l1W7QItmzBq4XLFkN/CTlfHTcW2vhZIDwP+X1D3u955T7YX5JS8XANmpWzKll17ioNoNPcuDV2GmMOAp8F7gKeAm5KF8TDsu2PfVz540c4vKyE715cx20nvd93uxEDB/nwG+4zWfO50HY6DMYAsX/bTofmaxe5DZqHg/jSC6G/lLw/0OUlmbsuxCSHwffV+AqpW+rustE57w3PnIhZadh51U4N4ipQKP3IjTF3GmOON8a8xRgzIcmzzm09HDg4xI2X/Tn1b3sTAC8dtmDUdn6D6afqCpoCC1sTHxWYBdp77OS23gNrqFlhx6jIZv7CdJrqmjArDb1f7M0YzLXXQAHp6kp7aXt5STmVsyqHUxNBQ7xW9dhfhluvg6FrYGtnPfEfjnudSE0Bkb2y85WeNwBYePgsit5zCf0AABR2SURBVIqE1otOZuCrXxu1XbwTLvld+plQhNGzqSQMBrxCgwJytdBwkbHTZ+VZC9/wkQ0jRsC7fvH1FGV4exbduGj4b6JHjFwjw8vVOGlutoNOidhrDoBVP4OS1G7Vxn45936xl51X7WRo5RBbV2xl1bmrRk1qXNbvRiusroYNG2yPq3tynyZNTU+RHf2wacPDbH78VV745/MQSYqiMjqi1qzIPFdh9R5bE0pV/E8urTKOgi7gyObikiNnH8nLvS+PWj6WSW9VFk46CZ707//v1do0XXdF0ryZjwWPatiypYXunm6qKqryHvpVTQ9BOfJIDZr18p797H1jgPmzZ7D58VcpjRWNDOJgB9DfNfLy4cDZw7PYprHD5sTHq/GyNFYa2JUrXhsfNRlBKr8gDrDlhS2hlE8lSRPE4dAEDcOqg/tax2vjGrhVaCKVWrn27mc557r7+PxP7aflyrOPH73RqlVQUjJiUaYGz3TbrN6caylTpPnBUzmrkrUXrk37gdb+ugWiuTltEPelgzypCRKpQN5whq3h3PPUawBceOqRozeKx2HdukP9a2OxjA2ew/nJALExZp/KpJSmdzaN6IO74SMbMCtN1j0R8qm16RWgIVqzJrfty8t1kCc1YSIVyE89+lCi+6QjD+PNhwUMpRmP23GLh4Zg/XriT5eM6NZVuc/ehi9rTu1HXl8/4kKLxoo0/RNTuaBfXVFN+0VrWX3+arau2Drc0DWWwDzWy6H1oqExSlzcVVRk/y5a5D+IWjrX5zaMrVL5iFxj57V3P8vA4BD/eM7bsn+S50FDmkbD6uqMIyaWfKWEgyZgtLdE8N4Lrcc1EW/KPJluLrxOb9Rl0tnSi4Zy5Hlw2WXQn9tYOCOEPEqmUglTZqq3z519fG5BHGxgDmp4Ssw6MjRk/wb8HL7hohtGX4RjYOYAbPhVJea4DWy91oQexOHQZdJjoemVHC1bll8QT+xDqQkUuUA+ZnnOOhKvjbP+ovUj890f3cD+rxni9+4c93xovDYeeCFJOhfffLEG82w1NwdPVpyNWAyammB1+F/mSqUTudRKXiZpHs6wjHnSglhpxt4x05rnwfLlo7qtZlSeZpZ6pcbBlEmt5CW5ETRNGqVQxWvjNNU15fw8HS0xgOfB7Nm2/STXIF5UpA2aqmBMr0A+Baw+fzUbPrIh5zRLuouKpiXPw/vmxdT89T6KVtqrf4OGafB1442RqwioqWt6pVamsPnfmJ92QlydY3Ek7/3zaXz3rhFDxmYzpDFgu6fqOChqEmhqZZor+NESXZrDO0WYf5WdlEOutve9UwTmzBnTNHtBlr9z1+gJRzIMaQxoEFcFSQP5FLF7/+606wtijsXUC22am22OWgQaGvCO3cfFH3YzyYu97SqHyy4E75heuPjiUIK519bMrjL/db5j7uiIhKrAaSCfIqoqqgLXCcJ5x503gaXx4XmwdCl0ddmA2NVlp9Xbd2iy4uXnwJDPSJP9xa6mPDRkL9ZJ/jLwvJFfEIkvhsQtuSa/aBGIsOzFtsBB0EaMuROL2QAewYZxNb1oIJ8iWutbR41xnWAwrH90/fj3J08XUBsaYGAg7dODaslga8peLdQ091N0aRc1yw3eYV12vw0Nh74g9qXMYt/ba9cffjhssQPq9Jb6HADAJI25U1kJ69drAFeRoIF8ikieJNdP30BfuF0QPQ/mzz8UqGfMSB9Q8zSvDxoX23Hljdi/jYtz6GmyZ09Wm8X/0aVQdo7/RV5KhSWvQC4iHxeRJ0RkSERGtaSqiRWvjbN1xVYkIG/Q3dMdzoESaZLkvtf5XtYOwdOluY5Vfo2Ty8+xXQdz6UIYNFuUiGjwVpGUb438ceAjwK9DKIsKSVC+PF0ePSctLRnTJGOx6mdQ6jdd2m/sxMR+dpXlXktf9hCjx4k3sKxOx0hR0ZRXIDfGPGWMeSaswqhwtNa3Mqt41ohlZSVl4U1S0TU+FxfFO2HtrSmzyG+0k3sETg6S8uMjqAuhV3uo5n7nCVD/B4gNAsb+bTqsfsScqUpFyYRN9SYijUAjQFVVSDVD5SteG2d//yDLbvt/DBbtpDrMOSFD7MvtJ763mnidGwNn/vzh9E3rFlvbHpFeMfj2PkntQujVjnxu11zYUQbrb3EX/1RWwk7tVqiiK2ONXETuEZHHfW4X5nIgY0y7MabOGFO3YMGCsZdYZeXSUxtYeGAdq97zzJgntPD1mc+Es59URUWju/qtWjW8Ot7JiMlBqvcE59RTa+8t9f759ZZ67AiYScdRKooyBnJjzCJjzMk+t1snooBqbIpjRcwoLmLfgRAvy29uhjfeGPvzKysPXVizYcOIWZh8xy5JeRzvhK3XwdA19u+qn42ews9v2r6gibW7K4D2dm3gVJGn3Q+nKK/T44WSS/niQydRc11N/n3IPc9ewDMW9fWju/RlOxJlZfDgYPFOaL9dqErU0gdn0/7JDcQfG9mSGZRfr5pbrUFcTQl55chF5CLgP4EFwB0i8ogx5i9DKZkaM6/TY+ktSxnA9izp6uli6S1LgTFO5ux5eN9aSssK6KqA2BAMFkF1j639Bg4yFYtBY2N+Ey2sWgVLlvjPmdnURHz1anz/o8rKtPn1MikNr/FXqUmmox9OQUEjIVbOqmTnVTtz3p/fSIEJviMGhj2wlOfBFVccusioqMg+TvcFkTJPq1drc+LdFVC1V2hd+n2daENFTtDohxrIpyC5JmAgEcY2GXPNlULX3OD11XtszjqUGniYmptHp4NKSmDdOk2pqEjSYWwVAM13NOf8nK6AxsKE7rliUx8HDxZOEAdbltRGVQ3iagrSQD4FpZs9qP3h9pz3F5P0p0loV4yOh4hP76dUNjSQT0Grzg3uFz2WCSYGGQpcVzaANhoqNck0kE9B8do4RQG16JjE8Do9aq6roeiaoqy6JgaNqBgbgvajmrTRUKlJpoF8irriz67wXX5WzVk0bmqkq6cLg6Grp4vGTY1pg/mX/uIriJkxYlnZQWH9m5uINxVQTlypaUoD+RS1+vzVNNU1ATI80t/s0tk88uoj9A2MvLY901jlpy1YzLyBz/KmsoUIQnVFNe2f+L4GcaUKxIQNmqUm3plVZ/Ldh7/HQXdhUG9/L730+m6bbqzy57b3Mnvw/fxy6TXUzC8fl7IqpcZOa+RT2PLNyzloshs33G+auEQu/a/uqOalmZdx30u3hF1EpVQINJBPYX5XdwbZN7BvOE/udXrM/vpsGjY20NXTBRgOynYuv23p+M/7qZTKmaZW1LBEnnzpLUsZGBpdkx8YGmD55uXaS0WpAqM18iks3YVBfrp6umjZ0uIbxBNyqeUrpSaGBvIpLN2FQUFsKkUpFSUayKeweG2cyv3BA2j5iUks7fpca/lKqfGngXwq8zxW3WlGzxifRqZL+MdSy1dKjS8N5FNZSwvxzuC5LXPVVKeX4ytViDSQT2Xd9iKfVT8jp1q5n/KSclafr1dyKlWINJBPZVV2eNnAqdhysG9gX/47UUqNi7wCuYh8U0SeFpHHRORmEUkzj4yacK2tUGav2IwFj0SrlIq4fGvkdwMnG2NOAZ4FvpB/kVRo4nFob4fqaho7yCu9or1VlCpceQVyY8zPjTEH3cP/AxbmXyQVKjdDzuo7DU3vbELIrTtigvZWUapwhTb5sohsAn5sjNkQsL4RaASoqqr6s64uvfBksnmdHo2bGkcNa5uq/ph67rn4ngkqlVIqSNDkyxnHWhGRe4A3+6xqMcbc6rZpAQ4CgSMqGWPagXaAurq6cL49VF4SXQkbNjak3e653c9NRHGUUmOUMZAbYxalWy8ilwIfAupNWNV7NWHitXEuv6WRA0PBtfJ0Y5UrpSZfvr1WzgGuAi4wxoR02YmaaCWx0rTrqyqqJqgkSqmxyLfXyreBOcDdIvKIiKwJoUxqgvUO7AlcVzoIrfWtE1gapVSu8hqP3Bjz1rAKoiaHnShCCOqbOOcN9LJ8pQqcXtk5zdnJJIKbNnaPngFOKVVgNJBPc5kaMqtK9EIgpQqdBvJpLl1DZpmU0nqBXgikVKHTQD7Ntda3MiM2a9TyylmVtF+0VvPjSkWATr48zcVr4zzavYdrf3MNg7KT6rlVtNa3agBXKkI0kCs+UP1RbrqvBoCtK86f3MIopXKmqRWFjG0cLaVUgdBArijSSK5UpGkgV2Mc2FYpVSg0kCuK9CxQKtL0I6zGPNmEUqowaCBX2tipVMRpIFfa2KlUxGkgV1ojVyriNJArrZErFXEayJU2dSoVcRrIFaI1cqUiTQO50hy5UhGX7+TLXxWRx9x8nT8XkSPDKpiaOJojVyra8q2Rf9MYc4ox5lTgduDLIZRJTbAijeNKRVpegdwYszfpYTnpJn9UBUsr5EpFW97jkYtIK3Ax0AO8P812jUAjQFVV8PRiauJpY6dS0ZaxRi4i94jI4z63CwGMMS3GmKMBD/hs0H6MMe3GmDpjTN2CBQvC+w9U3jSMKxVtGWvkxphFWe7LA+4EVuZVIjXhtLFTqWjLt9fKcUkPLwSezq84ajJoHFcq2vLNkf+LiJwADAFdwLL8i6QmmtbIlYq2vAK5MeajYRVEKaXU2OiVnUpr5EpFnAZypVO9KRVx+hFWOtWbUhGngVzpJfpKRZwGcqXdD5WKOA3kSi/RVyriNJArzZArFXEayJV2P1Qq4jSQKw3kSkWcBnKljZ1KRZwGcqWBXKmI00CutNeKUhGngVzpBUFKRZwGcqWX6CsVcRrIldbIlYo4DeRKrwhSKuI0kCvtR65UxGkgVxrIlYq4UAK5iPy9iBgRmR/G/tTE0jCuVLTlHchF5Gjgg0B3/sVRk0Fr5EpFWxg18m8BVwEmhH2pyaBxXKlIyyuQi8iFwEvGmEdDKo+aBNr9UKloK860gYjcA7zZZ1UL8EVsWiUjEWkEGgGqqqpyKKIab3qJvlLRljGQG2MW+S0XkVrgGOBRFwgWAr8VkdONMa/67KcdaAeoq6vTNEwB0Rq5UtGWMZAHMcZ0Am9KPBaRrUCdMWZnCOVSE0gbO5WKNu1HrpRSETfmGnkqY0xNWPtSE0tr5EpFm9bIlU4soVTEaSBXWiNXKuI0kCu9HkipiNNArjS1olTEaSBX/ODxH7BtxlK6Zi6m5roavE5vsouklMpBaL1WVDR5nR6NmxoZLOoDoKuni8ZNjQDEa+OTWTSlVJa0Rj7NtWxpoW+gb8SyvoE+Wra0TFKJlFK50kA+zXX3+I8+HLRcKVV4NJBPc1UV/gOYBS1XShUeDeTTXGt9K2UlZSOWlZWU0VrfOkklUkrlSgP5NBevjdO+uJ3qimoEobqimvbF7drQqVSEiDETP6JsXV2d6ejomPDjKqVUlInIw8aYutTlWiNXSqmI00CulFIRp4FcKaUiTgO5UkpFnAZypZSKuEnptSIiO4CuMT59PhCFeUGjUM4olBG0nGGKQhlByxmk2hizIHXhpATyfIhIh1/3m0IThXJGoYyg5QxTFMoIWs5caWpFKaUiTgO5UkpFXBQDeftkFyBLUShnFMoIWs4wRaGMoOXMSeRy5EoppUaKYo1cKaVUkkgFchE5R0SeEZHnROTzk1iOtSKyXUQeT1o2T0TuFpHfu7+Hu+UiIv/hyvyYiJw2geU8WkTuFZEnReQJEVleaGUVkZki8hsRedSV8Rq3/BgRedCV5cciUuqWz3CPn3Pra8a7jCnljYnI70Tk9kItp4hsFZFOEXlERDrcsoJ5z91x54rIf4vI0yLylIi8qwDLeIJ7DRO3vSKyotDKCYAxJhI3IAb8ATgWKAUeBU6cpLK8FzgNeDxp2TeAz7v7nwf+1d0/D9gMCHAG8OAElvMI4DR3fw7wLHBiIZXVHWu2u18CPOiOfRPwSbd8DdDk7jcDa9z9TwI/nuD3/nPAD4Db3eOCKyewFZifsqxg3nN33PXAZ9z9UmBuoZUxpbwx4FWguhDLOaEvRp4v5LuAu5IefwH4wiSWpyYlkD8DHOHuHwE84+5fD3zKb7tJKPOtwNmFWlagDPgt8OfYiyyKU9974C7gXe5+sdtOJqh8C4EtwAeA290HthDL6RfIC+Y9ByqAF1Jfj0Iqo0+ZPwg8UKjljFJq5SjgxaTH29yyQvEnxphX3P1XgT9x9wui3O6n/TuwNd6CKqtLVzwCbAfuxv7y2mOMOehTjuEyuvU9QOV4l9G5DrgKGHKPKwu0nAb4uYg8LCKNblkhvefHADuAdS5N9T0RKS+wMqb6JPBDd7/gyhmlQB4Zxn4dF0x3IBGZDfwUWGGM2Zu8rhDKaowZNMaciq3xng68bTLL40dEPgRsN8Y8PNllycJ7jDGnAecCfyMi701eWQDveTE2NdlmjHkHsA+bohhWAGUc5to9LgB+krquUMoZpUD+EnB00uOFblmheE1EjgBwf7e75ZNabhEpwQZxzxizsZDLaozZA9yLTVHMFZFin3IMl9GtrwB2TUDxzgQuEJGtwI+w6ZVVBVhOjDEvub/bgZuxX46F9J5vA7YZYx50j/8bG9gLqYzJzgV+a4x5zT0uuHJGKZA/BBznegmUYn/q3DbJZUp2G3CJu38JNh+dWH6xa9E+A+hJ+lk2rkREgP8CnjLGXFuIZRWRBSIy192fhc3hP4UN6B8LKGOi7B8DfuFqRePKGPMFY8xCY0wN9tz7hTEmXmjlFJFyEZmTuI/N7T5OAb3nxphXgRdF5AS3qB54spDKmOJTHEqrJMpTWOWcyAaDEBoczsP2vPgD0DKJ5fgh8AowgK1dXI7Nf24Bfg/cA8xz2wrwHVfmTqBuAsv5HuzPvseAR9ztvEIqK3AK8DtXxseBL7vlxwK/AZ7D/qSd4ZbPdI+fc+uPnYT3/ywO9VopqHK68jzqbk8kPieF9J67454KdLj3/Rbg8EIrozt2OfaXVEXSsoIrp17ZqZRSERel1IpSSikfGsiVUiriNJArpVTEaSBXSqmI00CulFIRp4FcKaUiTgO5UkpFnAZypZSKuP8Ptj4GLZ8pm7MAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ]
}